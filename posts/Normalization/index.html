<!DOCTYPE html><html lang="ko" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-233565867-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-233565867-1'); </script><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Normalization" /><meta name="author" content="highcloud" /><meta property="og:locale" content="ko" /><meta name="description" content="Normalization 종류 Batch normalization https://arxiv.org/abs/1502.03167 CNN Layer normalization https://arxiv.org/pdf/1607.06450.pdf RNN, Transformer Instance normalization Group normalization Normalization Standardization 표준화 왜 할까? 범위가 너무 넓어 step size를 정하기 어렵다. 보수적으로 잡게 됨 방법 평균이 0, 분산이 1이도록 만든다. Batch Normalization data들이 whitened하면 Training converges 가 빠르게 진행된다. whitened : zero mean, unit variance, decorrelated Deep Neural Networks 에 적용을 해보자! Internal Covariate Shift 처음 input은 표준화 되어있다. 그러나 다음 layer에서는 표준화 되어 있지 않다. h=∑wx+bh1=ϕ(h) h = \sum wx + b \\ h_1 = \phi(h) h=∑wx+bh1​=ϕ(h) 보통 input distrubution 이 input과 output에서 같다고 생각한다. 만약 다른 상황이라면 이를 Covariate shift라고 부른다. 지금은 layer에서 벌어진 상황이기에 Internal Covariate shift라고 부른다. Batch Normalization 이제 batch normalization에 대해 알아보자. 우선 하나의 노드를 기준으로 생각한다. batch는 입력 데이터의 개수이다. 입력 노드의 수가 아니다. batch가 10이라면 10번 feed foward가 발생한다. 이때 h1이 된 값은 10개가 존재한다. 이 값들을 가지고 normalization을 진행한다. M=size&nbsp;of&nbsp;mini-batchM = \text{size of mini-batch}M=size&nbsp;of&nbsp;mini-batch 일때 수식으로 정리해보면 다음과 같다. z~i=hi−μiσi2+ϵ \tilde z_i = {h_i - \mu _i \over \sqrt{\sigma_i^2+\epsilon}} z~i​=σi2​+ϵ​hi​−μi​​ μi=1M∑m=1Mai,m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;σi2=1M∑m=1M(ai,m−μi)2 \mu _i = {1\over M}\sum_{m=1}^M a_{i,m} \ \ \ \ \ \sigma_i^2 = {1\over M}\sum_{m=1}^M(a_{i,m}-\mu_i)^2 μi​=M1​m=1∑M​ai,m​&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;σi2​=M1​m=1∑M​(ai,m​−μi​)2 이후에는 Scale 과 Shift 과정을 지난다. 이는 하나의 layer가 추가된 것으로 볼 수 있다. zi=γiz~i+βi \bold z_i = \gamma_i \tilde z_i+\beta_i zi​=γi​z~i​+βi​ 왜 scale과 shift 과정이 필요할까? 다음 그림을 보며 이해해보자. 우선 normalization 과정은 빨간 분포를 중앙의 파란 분포로 바꾸는 과정이다. 이후 우리는 sigmoid 를 취하게 되는데 빨간색에 위치한 sigmoid의 경사는 파란색 분포보다 완만하다. 만약 빨간색에서 계속 기울기가 계산된다면 매우 느리게 converge 할 것이다. gradient vanishing 문제 이때 표준화 과정에서 항상 평균을 0으로 분산을 1로 하는 것이 의미가 있을까? 우선 표준화 과정의 장점은 빠른 converge이다. gradient vanishing 해결 하지만 모두 같은 기울기를 가지게 되고 , 이는 활성화 함수가 비선형 함수로써 의미가 없어지게 만든다. 그래서 두 개의 변수를 추가해서 scale과 shift 과정을 만든다. 랜덤성을 부여하는 것이다. 중앙이 답이 아닐 수도 있으니까 두 변수는 역전파 과정에서 학습된다. 즉 데이터가 정한다. BN in Inference phase 학습 시에는 배치 크기 기준으로 학습을 했다. 그렇다면 테스트 시에는 무엇을 기준으로 해야 될까? 이때는 단순히 마지막 결과를 사용하는 것이 아닌 평균을 이용한다. 즉 한번 배치를 돌 때마다 평균 값과 분산 값이 나오게 됨 이 값들을 다시 평균 내서 입력 값을 표준화 하는데 사용한다. 이후 학습된 γ와β\gamma \text{와} \betaγ와β 값을 이용해 scale, shift 해준다. 분산을 평균 낼 때는 MM−1M\over M-1M−1M​을 곱한다. (편향) moving avg를 구한다. 장점 step size 를 증가시킬 수 있다. speed up remove dropout reduce L2 weight regularization Layer Normalization rnn에는 BN이 잘 안 맞음 시간의 흐름이 중요한데 배치마다 평균 내버림 배치 사이즈가 작으면 BN의 문제가 있다. ( 이유는 찾아보자 ) LN average of node 말 그대로 레이어 값들의 통계량을 이용한다. BN은 Batch를 기준으로 통계량을 만들어 이용했다면 LN은 한 input에 대하여 작동하며, 같은 층의 노드들의 통계량을 사용한다. 다음과 같은 결과가 나온다. 이후 내용 CNN을 배우고 오자!" /><meta property="og:description" content="Normalization 종류 Batch normalization https://arxiv.org/abs/1502.03167 CNN Layer normalization https://arxiv.org/pdf/1607.06450.pdf RNN, Transformer Instance normalization Group normalization Normalization Standardization 표준화 왜 할까? 범위가 너무 넓어 step size를 정하기 어렵다. 보수적으로 잡게 됨 방법 평균이 0, 분산이 1이도록 만든다. Batch Normalization data들이 whitened하면 Training converges 가 빠르게 진행된다. whitened : zero mean, unit variance, decorrelated Deep Neural Networks 에 적용을 해보자! Internal Covariate Shift 처음 input은 표준화 되어있다. 그러나 다음 layer에서는 표준화 되어 있지 않다. h=∑wx+bh1=ϕ(h) h = \sum wx + b \\ h_1 = \phi(h) h=∑wx+bh1​=ϕ(h) 보통 input distrubution 이 input과 output에서 같다고 생각한다. 만약 다른 상황이라면 이를 Covariate shift라고 부른다. 지금은 layer에서 벌어진 상황이기에 Internal Covariate shift라고 부른다. Batch Normalization 이제 batch normalization에 대해 알아보자. 우선 하나의 노드를 기준으로 생각한다. batch는 입력 데이터의 개수이다. 입력 노드의 수가 아니다. batch가 10이라면 10번 feed foward가 발생한다. 이때 h1이 된 값은 10개가 존재한다. 이 값들을 가지고 normalization을 진행한다. M=size&nbsp;of&nbsp;mini-batchM = \text{size of mini-batch}M=size&nbsp;of&nbsp;mini-batch 일때 수식으로 정리해보면 다음과 같다. z~i=hi−μiσi2+ϵ \tilde z_i = {h_i - \mu _i \over \sqrt{\sigma_i^2+\epsilon}} z~i​=σi2​+ϵ​hi​−μi​​ μi=1M∑m=1Mai,m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;σi2=1M∑m=1M(ai,m−μi)2 \mu _i = {1\over M}\sum_{m=1}^M a_{i,m} \ \ \ \ \ \sigma_i^2 = {1\over M}\sum_{m=1}^M(a_{i,m}-\mu_i)^2 μi​=M1​m=1∑M​ai,m​&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;σi2​=M1​m=1∑M​(ai,m​−μi​)2 이후에는 Scale 과 Shift 과정을 지난다. 이는 하나의 layer가 추가된 것으로 볼 수 있다. zi=γiz~i+βi \bold z_i = \gamma_i \tilde z_i+\beta_i zi​=γi​z~i​+βi​ 왜 scale과 shift 과정이 필요할까? 다음 그림을 보며 이해해보자. 우선 normalization 과정은 빨간 분포를 중앙의 파란 분포로 바꾸는 과정이다. 이후 우리는 sigmoid 를 취하게 되는데 빨간색에 위치한 sigmoid의 경사는 파란색 분포보다 완만하다. 만약 빨간색에서 계속 기울기가 계산된다면 매우 느리게 converge 할 것이다. gradient vanishing 문제 이때 표준화 과정에서 항상 평균을 0으로 분산을 1로 하는 것이 의미가 있을까? 우선 표준화 과정의 장점은 빠른 converge이다. gradient vanishing 해결 하지만 모두 같은 기울기를 가지게 되고 , 이는 활성화 함수가 비선형 함수로써 의미가 없어지게 만든다. 그래서 두 개의 변수를 추가해서 scale과 shift 과정을 만든다. 랜덤성을 부여하는 것이다. 중앙이 답이 아닐 수도 있으니까 두 변수는 역전파 과정에서 학습된다. 즉 데이터가 정한다. BN in Inference phase 학습 시에는 배치 크기 기준으로 학습을 했다. 그렇다면 테스트 시에는 무엇을 기준으로 해야 될까? 이때는 단순히 마지막 결과를 사용하는 것이 아닌 평균을 이용한다. 즉 한번 배치를 돌 때마다 평균 값과 분산 값이 나오게 됨 이 값들을 다시 평균 내서 입력 값을 표준화 하는데 사용한다. 이후 학습된 γ와β\gamma \text{와} \betaγ와β 값을 이용해 scale, shift 해준다. 분산을 평균 낼 때는 MM−1M\over M-1M−1M​을 곱한다. (편향) moving avg를 구한다. 장점 step size 를 증가시킬 수 있다. speed up remove dropout reduce L2 weight regularization Layer Normalization rnn에는 BN이 잘 안 맞음 시간의 흐름이 중요한데 배치마다 평균 내버림 배치 사이즈가 작으면 BN의 문제가 있다. ( 이유는 찾아보자 ) LN average of node 말 그대로 레이어 값들의 통계량을 이용한다. BN은 Batch를 기준으로 통계량을 만들어 이용했다면 LN은 한 input에 대하여 작동하며, 같은 층의 노드들의 통계량을 사용한다. 다음과 같은 결과가 나온다. 이후 내용 CNN을 배우고 오자!" /><link rel="canonical" href="https://highcloud100.github.io/posts/Normalization/" /><meta property="og:url" content="https://highcloud100.github.io/posts/Normalization/" /><meta property="og:site_name" content="highcloud100" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-07-18T23:10:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Normalization" /><meta name="twitter:site" content="@highcloud100" /><meta name="twitter:creator" content="@highcloud" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"highcloud"},"dateModified":"2022-07-18T23:10:00+09:00","datePublished":"2022-07-18T23:10:00+09:00","description":"Normalization 종류 Batch normalization https://arxiv.org/abs/1502.03167 CNN Layer normalization https://arxiv.org/pdf/1607.06450.pdf RNN, Transformer Instance normalization Group normalization Normalization Standardization 표준화 왜 할까? 범위가 너무 넓어 step size를 정하기 어렵다. 보수적으로 잡게 됨 방법 평균이 0, 분산이 1이도록 만든다. Batch Normalization data들이 whitened하면 Training converges 가 빠르게 진행된다. whitened : zero mean, unit variance, decorrelated Deep Neural Networks 에 적용을 해보자! Internal Covariate Shift 처음 input은 표준화 되어있다. 그러나 다음 layer에서는 표준화 되어 있지 않다. h=∑wx+bh1=ϕ(h) h = \\sum wx + b \\\\ h_1 = \\phi(h) h=∑wx+bh1​=ϕ(h) 보통 input distrubution 이 input과 output에서 같다고 생각한다. 만약 다른 상황이라면 이를 Covariate shift라고 부른다. 지금은 layer에서 벌어진 상황이기에 Internal Covariate shift라고 부른다. Batch Normalization 이제 batch normalization에 대해 알아보자. 우선 하나의 노드를 기준으로 생각한다. batch는 입력 데이터의 개수이다. 입력 노드의 수가 아니다. batch가 10이라면 10번 feed foward가 발생한다. 이때 h1이 된 값은 10개가 존재한다. 이 값들을 가지고 normalization을 진행한다. M=size&nbsp;of&nbsp;mini-batchM = \\text{size of mini-batch}M=size&nbsp;of&nbsp;mini-batch 일때 수식으로 정리해보면 다음과 같다. z~i=hi−μiσi2+ϵ \\tilde z_i = {h_i - \\mu _i \\over \\sqrt{\\sigma_i^2+\\epsilon}} z~i​=σi2​+ϵ​hi​−μi​​ μi=1M∑m=1Mai,m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;σi2=1M∑m=1M(ai,m−μi)2 \\mu _i = {1\\over M}\\sum_{m=1}^M a_{i,m} \\ \\ \\ \\ \\ \\sigma_i^2 = {1\\over M}\\sum_{m=1}^M(a_{i,m}-\\mu_i)^2 μi​=M1​m=1∑M​ai,m​&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;σi2​=M1​m=1∑M​(ai,m​−μi​)2 이후에는 Scale 과 Shift 과정을 지난다. 이는 하나의 layer가 추가된 것으로 볼 수 있다. zi=γiz~i+βi \\bold z_i = \\gamma_i \\tilde z_i+\\beta_i zi​=γi​z~i​+βi​ 왜 scale과 shift 과정이 필요할까? 다음 그림을 보며 이해해보자. 우선 normalization 과정은 빨간 분포를 중앙의 파란 분포로 바꾸는 과정이다. 이후 우리는 sigmoid 를 취하게 되는데 빨간색에 위치한 sigmoid의 경사는 파란색 분포보다 완만하다. 만약 빨간색에서 계속 기울기가 계산된다면 매우 느리게 converge 할 것이다. gradient vanishing 문제 이때 표준화 과정에서 항상 평균을 0으로 분산을 1로 하는 것이 의미가 있을까? 우선 표준화 과정의 장점은 빠른 converge이다. gradient vanishing 해결 하지만 모두 같은 기울기를 가지게 되고 , 이는 활성화 함수가 비선형 함수로써 의미가 없어지게 만든다. 그래서 두 개의 변수를 추가해서 scale과 shift 과정을 만든다. 랜덤성을 부여하는 것이다. 중앙이 답이 아닐 수도 있으니까 두 변수는 역전파 과정에서 학습된다. 즉 데이터가 정한다. BN in Inference phase 학습 시에는 배치 크기 기준으로 학습을 했다. 그렇다면 테스트 시에는 무엇을 기준으로 해야 될까? 이때는 단순히 마지막 결과를 사용하는 것이 아닌 평균을 이용한다. 즉 한번 배치를 돌 때마다 평균 값과 분산 값이 나오게 됨 이 값들을 다시 평균 내서 입력 값을 표준화 하는데 사용한다. 이후 학습된 γ와β\\gamma \\text{와} \\betaγ와β 값을 이용해 scale, shift 해준다. 분산을 평균 낼 때는 MM−1M\\over M-1M−1M​을 곱한다. (편향) moving avg를 구한다. 장점 step size 를 증가시킬 수 있다. speed up remove dropout reduce L2 weight regularization Layer Normalization rnn에는 BN이 잘 안 맞음 시간의 흐름이 중요한데 배치마다 평균 내버림 배치 사이즈가 작으면 BN의 문제가 있다. ( 이유는 찾아보자 ) LN average of node 말 그대로 레이어 값들의 통계량을 이용한다. BN은 Batch를 기준으로 통계량을 만들어 이용했다면 LN은 한 input에 대하여 작동하며, 같은 층의 노드들의 통계량을 사용한다. 다음과 같은 결과가 나온다. 이후 내용 CNN을 배우고 오자!","headline":"Normalization","mainEntityOfPage":{"@type":"WebPage","@id":"https://highcloud100.github.io/posts/Normalization/"},"url":"https://highcloud100.github.io/posts/Normalization/"}</script><title>Normalization | highcloud100</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="highcloud100"><meta name="application-name" content="highcloud100"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" class="mx-auto"> <img src="https://avatars.githubusercontent.com/u/80192345?v=4" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">highcloud100</a></div><div class="site-subtitle font-italic">One of the comforting things about old memories is their tendency to take on a rosy glow.</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/highcloud100" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/highcloud100" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['highcloud100','inha.edu'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Normalization</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 data-toc-skip>Normalization</h1><div class="post-meta text-muted"> <span> Posted <em class="" data-ts="1658153400" data-df="ll" data-toggle="tooltip" data-placement="bottom"> Jul 18, 2022 </em> </span><div class="d-flex justify-content-between"> <span> By <em> baekbumsung </em> </span><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1037 words"> <em>5 min</em> read</span></div></div></div><div class="post-content"><h1 id="normalization">Normalization</h1><hr /><h2 id="종류"><span class="mr-2">종류</span><a href="#종류" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><hr /><ol><li>Batch normalization<ul><li><a href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a><li>CNN</ul><li>Layer normalization<ul><li><a href="https://arxiv.org/pdf/1607.06450.pdf">https://arxiv.org/pdf/1607.06450.pdf</a><li>RNN, Transformer</ul><li>Instance normalization<li>Group normalization</ol><h2 id="normalization-1"><span class="mr-2">Normalization</span><a href="#normalization-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><hr /><ul><li>Standardization 표준화<li>왜 할까?<ul><li>범위가 너무 넓어 step size를 정하기 어렵다.<ul><li>보수적으로 잡게 됨</ul></ul><li>방법<ul><li>평균이 0, 분산이 1이도록 만든다.</ul></ul><h1 id="batch-normalization">Batch Normalization</h1><hr /><ul><li>data들이 whitened하면 Training converges 가 빠르게 진행된다.</ul><blockquote><p>whitened : zero mean, unit variance, decorrelated</p></blockquote><ul><li>Deep Neural Networks 에 적용을 해보자!</ul><h2 id="internal-covariate-shift"><span class="mr-2">Internal Covariate Shift</span><a href="#internal-covariate-shift" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><hr /><p><img data-src="https://user-images.githubusercontent.com/80192345/179454886-a2df93f1-962e-41b1-8120-44b34d2abec4.png" alt="" width="500" data-proofer-ignore></p><ul><li>처음 input은 표준화 되어있다.<ul><li>그러나 다음 layer에서는 표준화 되어 있지 않다.</ul></ul><p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>h</mi><mo>=</mo><mo>∑</mo><mi>w</mi><mi>x</mi><mo>+</mo><mi>b</mi><mspace linebreak="newline"></mspace><msub><mi>h</mi><mn>1</mn></msub><mo>=</mo><mi>ϕ</mi><mo stretchy="false">(</mo><mi>h</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex"> h = \sum wx + b \\ h_1 = \phi(h) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.60001em; vertical-align: -0.55001em;"></span><span class="mop op-symbol large-op" style="position: relative; top: -5e-06em;">∑</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathnormal" style="margin-right: 0.02691em;">w</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathnormal">b</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height: 0.84444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal">h</span><span class="mclose">)</span></span></span></span></span></span></p><ul><li>보통 input distrubution 이 input과 output에서 같다고 생각한다.<ul><li>만약 다른 상황이라면 이를 Covariate shift라고 부른다.<li>지금은 layer에서 벌어진 상황이기에 Internal Covariate shift라고 부른다.</ul></ul><h2 id="batch-normalization-1"><span class="mr-2">Batch Normalization</span><a href="#batch-normalization-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><hr /><ul><li>이제 batch normalization에 대해 알아보자.<li>우선 하나의 노드를 기준으로 생각한다.</ul><p><img data-src="https://user-images.githubusercontent.com/80192345/179466661-f362ae19-b00d-488a-959b-44ec0b030ec1.png" alt="" width="500" data-proofer-ignore></p><ul><li><p>batch는 입력 데이터의 개수이다.</p><ul><li>입력 노드의 수가 아니다.</ul><li><p>batch가 10이라면 10번 feed foward가 발생한다.</p><ul><li>이때 h1이 된 값은 10개가 존재한다.<li>이 값들을 가지고 normalization을 진행한다.</ul><li><p><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>=</mo><mtext>size&nbsp;of&nbsp;mini-batch</mtext></mrow><annotation encoding="application/x-tex">M = \text{size of mini-batch}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathnormal" style="margin-right: 0.10903em;">M</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord text"><span class="mord">size&nbsp;of&nbsp;mini-batch</span></span></span></span></span></span> 일때 수식으로 정리해보면 다음과 같다.<br /> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mover accent="true"><mi>z</mi><mo>~</mo></mover><mi>i</mi></msub><mo>=</mo><mfrac><mrow><msub><mi>h</mi><mi>i</mi></msub><mo>−</mo><msub><mi>μ</mi><mi>i</mi></msub></mrow><msqrt><mrow><msubsup><mi>σ</mi><mi>i</mi><mn>2</mn></msubsup><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac></mrow><annotation encoding="application/x-tex"> \tilde z_i = {h_i - \mu _i \over \sqrt{\sigma_i^2+\epsilon}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.81786em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.66786em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.04398em;">z</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.04398em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.50144em; vertical-align: -1.13em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em;"><span class="" style="top: -2.16548em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.944522em;"><span class="svg-align" style="top: -3.2em;"><span class="pstrut" style="height: 3.2em;"></span><span class="mord" style="padding-left: 1em;"><span class="mord"><span class="mord mathnormal" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.795908em;"><span class="" style="top: -2.42314em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.0448em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.276864em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord mathnormal">ϵ</span></span></span><span class="" style="top: -2.90452em;"><span class="pstrut" style="height: 3.2em;"></span><span class="hide-tail" style="min-width: 1.02em; height: 1.28em;"><svg width="400em" height="1.28em" viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119 c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120 c340,-704.7,510.7,-1060.3,512,-1067 l0 -0 c4.7,-7.3,11,-11,19,-11 H40000v40H1012.3 s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232 c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1 s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26 c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z M1001 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.295478em;"><span class=""></span></span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.13em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></span></p></ul><p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>μ</mi><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><msub><mi>a</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>m</mi></mrow></msub><mtext>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</mtext><msubsup><mi>σ</mi><mi>i</mi><mn>2</mn></msubsup><mo>=</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mo stretchy="false">(</mo><msub><mi>a</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>m</mi></mrow></msub><mo>−</mo><msub><mi>μ</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex"> \mu _i = {1\over M}\sum_{m=1}^M a_{i,m} \ \ \ \ \ \sigma_i^2 = {1\over M}\sum_{m=1}^M(a_{i,m}-\mu_i)^2 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 3.09545em; vertical-align: -1.26711em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.10903em;">M</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.82834em;"><span class="" style="top: -1.88289em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05001em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.30001em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.26711em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace">&nbsp;</span><span class="mspace">&nbsp;</span><span class="mspace">&nbsp;</span><span class="mspace">&nbsp;</span><span class="mspace">&nbsp;</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -2.453em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 3.09545em; vertical-align: -1.26711em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.10903em;">M</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.82834em;"><span class="" style="top: -1.88289em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05001em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.30001em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.10903em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.26711em;"><span class=""></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.11411em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span></p><ul><li><p>이후에는 Scale 과 Shift 과정을 지난다.</p><ul><li>이는 하나의 layer가 추가된 것으로 볼 수 있다.<br /> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">z</mi><mi>i</mi></msub><mo>=</mo><msub><mi>γ</mi><mi>i</mi></msub><msub><mover accent="true"><mi>z</mi><mo>~</mo></mover><mi>i</mi></msub><mo>+</mo><msub><mi>β</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex"> \bold z_i = \gamma_i \tilde z_i+\beta_i </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.59444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathbf">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.8623em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.05556em;">γ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.05556em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.66786em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal" style="margin-right: 0.04398em;">z</span></span><span class="" style="top: -3.35em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.19444em;"><span class="mord">~</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.04398em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.05278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></ul><li><p>왜 scale과 shift 과정이 필요할까?</p><ul><li>다음 그림을 보며 이해해보자.</ul></ul><p><img data-src="https://user-images.githubusercontent.com/80192345/179464592-0ba67664-62ab-44f1-b5e6-9bcbc81810d6.png" alt="" data-proofer-ignore></p><ul><li><p>우선 normalization 과정은 빨간 분포를 중앙의 파란 분포로 바꾸는 과정이다.</p><ul><li>이후 우리는 sigmoid 를 취하게 되는데 빨간색에 위치한 sigmoid의 경사는 파란색 분포보다 완만하다.<li>만약 빨간색에서 계속 기울기가 계산된다면 매우 느리게 converge 할 것이다.<ul><li>gradient vanishing 문제</ul></ul><li><p>이때 표준화 과정에서 항상 평균을 0으로 분산을 1로 하는 것이 의미가 있을까?</p><ul><li>우선 표준화 과정의 장점은 빠른 converge이다.<li>gradient vanishing 해결<li>하지만 모두 같은 기울기를 가지게 되고 , 이는 활성화 함수가 비선형 함수로써 의미가 없어지게 만든다.</ul><li><p>그래서 두 개의 변수를 추가해서 scale과 shift 과정을 만든다.</p><ul><li>랜덤성을 부여하는 것이다.<ul><li>중앙이 답이 아닐 수도 있으니까</ul><li>두 변수는 역전파 과정에서 학습된다. 즉 데이터가 정한다.</ul></ul><h2 id="bn-in-inference-phase"><span class="mr-2">BN in Inference phase</span><a href="#bn-in-inference-phase" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><hr /><ul><li><p>학습 시에는 배치 크기 기준으로 학습을 했다.</p><li><p>그렇다면 테스트 시에는 무엇을 기준으로 해야 될까?</p><ul><li>이때는 단순히 마지막 결과를 사용하는 것이 아닌 평균을 이용한다.</ul><li><p>즉 한번 배치를 돌 때마다 평균 값과 분산 값이 나오게 됨</p><ul><li>이 값들을 다시 평균 내서 입력 값을 표준화 하는데 사용한다.<li>이후 학습된 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mtext>와</mtext><mi>β</mi></mrow><annotation encoding="application/x-tex">\gamma \text{와} \beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord mathnormal" style="margin-right: 0.05556em;">γ</span><span class="mord text"><span class="mord hangul_fallback">와</span></span><span class="mord mathnormal" style="margin-right: 0.05278em;">β</span></span></span></span></span> 값을 이용해 scale, shift 해준다.</ul></ul><blockquote><p>분산을 평균 낼 때는 <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>M</mi><mrow><mi>M</mi><mo>−</mo><mn>1</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">M\over M-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.27566em; vertical-align: -0.403331em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.872331em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.10903em;">M</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.403331em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>을 곱한다. (편향)</p></blockquote><blockquote><p>moving avg를 구한다.</p></blockquote><h2 id="장점"><span class="mr-2">장점</span><a href="#장점" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><hr /><ul><li>step size 를 증가시킬 수 있다.<ul><li>speed up</ul><li>remove dropout<li>reduce L2 weight regularization</ul><p><img data-src="https://user-images.githubusercontent.com/80192345/179531135-86ba13d6-69e6-4957-8a4b-d2b581f20aaa.png" alt="" data-proofer-ignore></p><h1 id="layer-normalization">Layer Normalization</h1><hr /><ul><li>rnn에는 BN이 잘 안 맞음<ul><li>시간의 흐름이 중요한데 배치마다 평균 내버림</ul><li>배치 사이즈가 작으면 BN의 문제가 있다.<ul><li>( 이유는 찾아보자 )</ul></ul><h2 id="ln"><span class="mr-2">LN</span><a href="#ln" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><hr /><ul><li>average of node<li>말 그대로 레이어 값들의 통계량을 이용한다.<li>BN은 Batch를 기준으로 통계량을 만들어 이용했다면<li>LN은 한 input에 대하여 작동하며, 같은 층의 노드들의 통계량을 사용한다.</ul><p><img data-src="https://user-images.githubusercontent.com/80192345/179529794-eb06e753-e9af-4f41-bfa5-13f06761be00.png" alt="" width="500" data-proofer-ignore></p><ul><li>다음과 같은 결과가 나온다.</ul><p><img data-src="https://user-images.githubusercontent.com/80192345/179530862-2a262354-f28e-46c2-862a-888963b843d0.png" alt="" data-proofer-ignore></p><h1 id="이후-내용">이후 내용</h1><hr /><ul><li>CNN을 배우고 오자!</ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/cs/'>CS</a>, <a href='/categories/ai/'>AI</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/cs/" class="post-tag no-text-decoration" >cs</a> <a href="/tags/ai/" class="post-tag no-text-decoration" >AI</a> <a href="/tags/ml/" class="post-tag no-text-decoration" >ML</a> <a href="/tags/summer/" class="post-tag no-text-decoration" >summer</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Normalization+-+highcloud100&url=https%3A%2F%2Fhighcloud100.github.io%2Fposts%2FNormalization%2F" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Normalization+-+highcloud100&u=https%3A%2F%2Fhighcloud100.github.io%2Fposts%2FNormalization%2F" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fhighcloud100.github.io%2Fposts%2FNormalization%2F&text=Normalization+-+highcloud100" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div><script src="https://utteranc.es/client.js" repo="highcloud100/blog-utterances" issue-term="pathname" crossorigin="anonymous" async> </script> <script type="text/javascript"> $(function() { const origin = "https://utteranc.es"; const iframe = "iframe.utterances-frame"; const lightTheme = "github-light"; const darkTheme = "github-dark"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } addEventListener("message", (event) => { let theme; /* credit to <https://github.com/utterance/utterances/issues/170#issuecomment-594036347> */ if (event.origin === origin) { /* page initial */ theme = initTheme; } else if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); } else { return; } const message = { type: "set-theme", theme: theme }; const utterances = document.querySelector(iframe).contentWindow; utterances.postMessage(message, origin); }); }); </script></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/xv6%EB%B0%B1%EC%97%85/">xv6 백업</a><li><a href="/posts/gpuServerSetting/">gpu 서버 세팅</a><li><a href="/posts/winter/">2023 Winter Vacation</a><li><a href="/posts/%EB%85%B8%ED%8A%B8%EB%B6%81-%EC%84%B8%ED%8C%85/">노트북 세팅</a><li><a href="/posts/plan240508/">추후 계획과 현 상황?</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/cs/">cs</a> <a class="post-tag" href="/tags/summer/">summer</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/ml/">ML</a> <a class="post-tag" href="/tags/os/">os</a> <a class="post-tag" href="/tags/network/">network</a> <a class="post-tag" href="/tags/distributed-systems/">Distributed_Systems</a> <a class="post-tag" href="/tags/tcp/">tcp</a> <a class="post-tag" href="/tags/%EC%8B%A4%EC%8A%B5%EA%B3%BC-%EA%B7%B8%EB%A6%BC%EC%9C%BC%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%A6%AC%EB%88%85%EC%8A%A4-%EA%B5%AC%EC%A1%B0/">실습과 그림으로 배우는 리눅스 구조</a> <a class="post-tag" href="/tags/life/">life</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/logistic/"><div class="card-body"> <em class="small" data-ts="1657267200" data-df="ll" > Jul 8, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Logistic Regression</h3><div class="text-muted small"><p> Logistic Regression Classification Linear regression은 값을 예측하는 모델이다. 추정 값이 −∞&amp;lt;y^&amp;lt;∞-\infin &amp;lt; \hat y &amp;lt;\infin−∞&amp;lt;y^​&amp;lt;∞ 의 범위를 가진다. Logistic Regression은 이진 분류 모델이다. 추정 값이 0 혹은 1...</p></div></div></a></div><div class="card"> <a href="/posts/loss/"><div class="card-body"> <em class="small" data-ts="1657330200" data-df="ll" > Jul 9, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Loss & Cost Function</h3><div class="text-muted small"><p> 손실함수와 비용함수 개념 Loss function은 모델이 실제 값과 어느 정도 차이가 나는지 수치화하는 함수이다. 차이를 손실이라 부른다. Cost function은 Loss function과 달리 데이터 셋 전체를 대상으로 손실을 구한다. Loss function은 특정 데이터에 대해 손실을 구한다. L1 손실함수 L1&amp;nbs...</p></div></div></a></div><div class="card"> <a href="/posts/perceptrons/"><div class="card-body"> <em class="small" data-ts="1657377900" data-df="ll" > Jul 9, 2022 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Perceptron</h3><div class="text-muted small"><p> Artificial Neuron 매컬러와 피츠가 제안한 매우 단순한 신경망 모델 입력이 일정 개수만큼 활성화되면 출력을 내보냄 논문에서 어떤 논리 명제도 계산할 수 있다는 것을 증명함 MCP뉴런이라 부른다. 뉴런은 행렬 계산의 일부이다. 특별하거나 심오한걸로 생각하지 말자. Perceptron 1957년 로젠블라트(Frank Rosen...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Dropout/" class="btn btn-outline-primary" prompt="Older"><p>Dropout</p></a> <a href="/posts/memory/" class="btn btn-outline-primary" prompt="Newer"><p>Physical memory management</p></a></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://github.com/highcloud100">baekbumsung</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"></p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/cs/">cs</a> <a class="post-tag" href="/tags/summer/">summer</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/ml/">ML</a> <a class="post-tag" href="/tags/os/">os</a> <a class="post-tag" href="/tags/network/">network</a> <a class="post-tag" href="/tags/distributed-systems/">Distributed_Systems</a> <a class="post-tag" href="/tags/tcp/">tcp</a> <a class="post-tag" href="/tags/%EC%8B%A4%EC%8A%B5%EA%B3%BC-%EA%B7%B8%EB%A6%BC%EC%9C%BC%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%A6%AC%EB%88%85%EC%8A%A4-%EA%B5%AC%EC%A1%B0/">실습과 그림으로 배우는 리눅스 구조</a> <a class="post-tag" href="/tags/life/">life</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/ko.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-233565867-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-233565867-1'); </script>
