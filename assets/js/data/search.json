[ { "title": "Buffer Pool Manager 과제", "url": "/posts/buffer-pool-manager/", "categories": "CS, DB", "tags": "", "date": "2024-09-22 23:21:00 +0900", "snippet": "0. bustup vscode setting우분투 환경은 기본적으로 gcc, g++이 잡혀있다. 이를 clang14로 바꾸어야한다.// clang-14 선택해준다. sudo update-alternatives --config c++ sudo update-alternatives --config cc// make시에 simple test 안되면sudo apt install libstdc++-12-dev https://stackoverflow.com/questions/26380407/cmake-clang-is-not-able-compile-a-simple-test-program-fedora-20vscode extension에서 clangd를 설치해 사용한다. 이때 include 폴더가 따로 위치하기에, 컴파일 db 정보를 만들어서 컴파일러가 확인하게 만들어야한다.https://clang.llvm.org/docs/JSONCompilationDatabase.htmlbear를 이용해 compile_commands.json을 만들고, 프로젝트 루트 디렉토리로 이동시킨다.cd /buildbear -- makemv compile_commands.json ~/bustub1. 구현구현은 3 파트로 나뉜다. replacer decide which page to evict disk scheduler execute disk i/o buffer pool manager interface of pages and frames 2. ReplacerCS에서 작은 공간에 모든 데이터를 담아둘 수 없을 때, 늘 나오는 주제이다. 핵심은 공간과 시간 요소를 활용하여 최대한 하위 레이어로 내려가지 않도록 만드는 것이다. 대표적인 알고리즘으로 LRU나 clock 방법이 있다.이런 알고리즘을 선택할 때는 접근 패턴을 고려해야 한다.데이터베이스에서 특히 OLAP 작업 패턴에서는 순차적으로 scan하는 작업을 많이 하게 된다. 이 경우 LRU나 clock을 사용하면 sequential flooding 문제를 야기할 수 있다. https://stackoverflow.com/questions/20464198/what-is-sequential-flooding most recently used page is often the best page to evict.이는 LRU나 clock이 last access 정보만 관리하기 때문이다. 얼마나 자주 접근 되었는지는 따지지 않는다.이런 문제를 다루는 여러 방법이 있지만, 과제에서는 LRU-K를 구현한다. https://www.cs.cmu.edu/~natassa/courses/15-721/papers/p297-o_neil.pdftime stamp를 사용해 page에 접근 할 때마다, time stamp를 기록한다.이때 page마다 K 개의 history까지 누적한다. 쫓아낼 후보를 결정할 때는 $\\text{current time stamp} - \\text{k th time stamp}$ 가 가장 큰 page로 정한다. 만약 history의 개수가 k개보다 작다면 (적어도 k번 참조되지 않음) 무한대의 값으로 계산한다. tie가 발생하면 최신의 time stamp가 가장 오래된 page를 쫓아낸다.그대로 구현해준다. 중요한 점은 pin되어 있는 page는 쫓아내면 안된다는 점이다.여담 DBMS는 query execution의 context를 알기 때문에, 페이지 우선순위에 대한 힌트를 제공할 수 있다. mysql은 old, young list를 사용해 LRU-K를 근사하여 사용한다. 핵심은 순간의 접근인지, 빈번한 접근인지를 가려내기 위함이다. 3. Disk scheduler 최적화를 할 부분이 많겠지만, 간단히 fifo queue로 구현하였다. Sequential vs Random I/O Critical Path Task vs Background Task Table vs Index vs Log vs Ephemeral Data Transation Information User-Based SLAsOS는 이런 걸 알기 어렵다. 고로 최대한 DBMS가 다루어야 한다.OS는 file cache(page, buffer cache)를 가지고 있다.대부분의 DBMS는 이를 bypass한다. (O_DIRECT) redundant copies of pages different eviction policies. loss of control over file I/O DIRECT IO in PostgreSQL and double bufferinghttps://www.linkedin.com/posts/krishnakumar-r-bb7b949_postgres-postgresql-kernel-activity-7191224981924552705-i-7R?utm_source=share&amp;utm_medium=member_desktopOS 관련한 문제로는 fsync가 있다. fsync를 실패했을 때, linux는 dirty page를 clean하다고 mark한다.fsync 재 호출시 flush가 정상적으로 되었다고 반환하지만, 실제로는 아닐 수 있다. https://wiki.postgresql.org/wiki/Fsync_Errorshttps://learn.microsoft.com/ko-kr/archive/blogs/bobsql/sql-server-linux-fsync-and-buffered-i-o4. Buffer Pool ManagerDB 전체의 흐름은 다음과 같다. buffer pool manager에서는 page table을 관리해주어야 한다. page id와 framed idx 간의 연결이다.중요한 점은 latch와 pin의 처리이다.누군가 write을 하고 있다면, 그 페이지에 대한 다른 접근은 block되어야 한다.반대로 read 작업은 여러 곳에서 병렬적으로 이루어질 수 있다.Pin은 page가 사용 중인지 알려준다. 즉 Pin 상태라면 evict해서는 안된다. Latch는 OS의 mutex이다. Lock은 다른 개념에서 사용된다.구현은 latch를 어떻게 사용할지 생각해보고 접근하면 된다. 실수했던 점은 frame id를 찾고서, 해당 frame이 잠겨 있다면 block하게 만들었다. 이 문제를 인지 못해 어지러운 디버깅 과정을 겪을 수 있었다. 테스트는 통과하는데, 벤치마크 10초 돌리니까 간혹 consistency가 깨졌다.핵심은 frame의 latch를 잡았을 때, 그 frame idx가 기존의 page와 맵핑된 상태가 아닐 수 도 있다. 즉 다시 page table을 참조해야 했다.최적화는 하지 않았다.5. mmap I/O problemsOS를 최대한 사용하지 말아야한다.다음의 문제가 있다. transaction safety OS can flush dirty pages at any time I/O stalls DBMS는 어떤 page가 메모리에 있는지 모른다. OS는 page fault시 thread를 stall한다. Error Handling Difficult to validate pages. Any access can cause a SIGBUS Performance Issues OS는 DB를 목적으로 만들어지지 않았다. madvise, mlock, msync등을 이용하여 문제를 완화할 수 있다. 되도록 DBMS는 온전히 자신이 control하기를 바란다. https://db.cs.cmu.edu/mmap-cidr2022/6. Buffer Pool Optimization Multiple buffer pools Pre-fetching Scan sharing synchronized scans Buffer Pool Bypass Light scans sequntial scan 같은 경우, buffer pool에 fetch를 안해버린다. replacer를 어지럽히지 않음 " }, { "title": "HyperLogLog 과제", "url": "/posts/HyperLogLog/", "categories": "CS, DB", "tags": "CS, DB, CMU_DB", "date": "2024-09-01 19:17:00 +0900", "snippet": "개요이번 학기에 cmu의 db강의를 따라 들으려 한다.c++ 연습을 위한 과제가 바로 올라왔는데, HyperLogLog를 구현하는 과제이다. 이것도 못 풀면 강의 드랍하라는 것 같다.과제 나오자마자 풀었는데, test를 계속 틀렸었다. 머리 박고 있었는데, test code의 값이 잘 못 올라와 있던 것이었다.test 업데이트와 동시에 task2도 추가되었는데, primer의 HLL 구현을 비스무리하게 만드는 것이다. 다만 이번에도 test case 병크를 터트려놔서 머리를 박았다.구현이 깔끔하지는 않은 것 같다.배열에 접근할 때 인덱스마다 락을 주면 좋을 거 같은데, 배열이 상당이 커서 mutex 범위를 정해야 할 거 같다.귀찮아서 업데이트 전체를 mutex로 묶었다.아래는 HLL과 Presto’s에 관한 meta의 글의 정리이다.문제 정의set의 cardinality를 구하는 문제이다. 단순히 해시를 사용할 수 있지만, 이는 다음과 같은 문제가 있다. computationally intensive demand too much memory이를 해소하기 위해 정확도를 포기하고, 추정을 한다.확률을 이용하자우선 입력되는 값들을 uniform distribution으로 바꿀 필요가 있다. 이를 위해서 hash를 이용한다.hash의 결과로 bit pattern을 뽑아낸다. 이후 오른쪽으로부터, 0이 연속으로 몇 개 나왔는지 센다. 모든 input에 대해 $p(x_i)$(연속된 0의 개수)을 구하면, cardinality를 $2^{max(p(x_1), p(x_2), … p(x_M))}$ 로 예측할 수 있다.이렇게 예측하는 이유는 직관적으로 설명해보면 다음과 같다. k개의 연속된 0이 나올 확률은 $1/2^k$ 이다. 이상적으로 uniform한 분포면, k개의 연속된 0은 $2^k$개의 distinct entries를 주기로 나오게 된다. 그래서 max연산으로 가장 큰 k를 구하고, $2^k$를 cardinality로 추정하는 것이다.다만 두 가지 문제점이 존재한다. 추정된 값은 $2^n$이다. 분산이 매우 크다. 예로 처음 입력의 hash값이 0으로만 이루어진 경우를 생각하자. 하지만 메모리 사용량은 매우 줄어들었다. maximum 값만 유지한다. (연속된 0이 32개까지 일 때, 5비트만 유지하면 된다.)정확도를 올리자추정을 여러 번 시도한다. 이후 이들의 평균 값을 구한다.이를 위해 독립된 hash함수가 필요하다. (다른 결과를 뱉어내는)하지만 이 경우 computationally expensive하다.Durand and Flajolet 들이 하나의 hash함수만을 이용하는 방법을 제시했다. m개의 독립된 추정을 구하기 위해, m개의 bucket 배열을 만든다.bit pattern의 앞 부분을 bucket을 indexing하는데 사용한다.이 방법은 정확도 손실 없이 m개의 hash를 사용할 computing을 줄여준다.이 절차를 stochastic averaging이라고 한다. 이 부분의 디테일은 논문을 봐야할 것 같다. 다른 방식으로 생각해보면, 큰 값에 민감한데, 이를 평균을 이용해 robust하게 만든다.위 방법의 cardinality는 다음과 같이 계산된다. \\(\\mathrm{CARDINALITY_{LogLog}} = \\mathrm{constant} \\cdot m \\cdot 2^{{1\\over m}\\sum_{j=1}^N{R_j}}\\)통계적 분석에 의하면 값을 크게 추정하는 bias가 있어,constant=0.79402로 두고 사용한다.이 알고리즘 방식을 LogLog(Durand-Flajolet)라고 부른다.이때 standard error는 $1.3 \\over \\sqrt m$ 이다. m은 bucket의 수5비트 크기의 bucket을 2048개 사용했을 때, 최대 $2^{27}$개의 ardinalities를 측정할 수 있다. (조정된 값이다.) 사용된 메모리는 2048*5 = 1.2KB이다.HLL두 가지의 추가 개선 방법이 있다. 작은 70% 값들만 이용하는 방법 조화 평균을 이용하는 방법후자의 방법이 HLL이며, standard error가 $1.04\\over \\sqrt m$ 까지 줄어든다. \\(\\mathrm{CARDINALITY_{LogLog}} = \\mathrm{constant} \\cdot m \\cdot {{m\\over {\\sum_{j=1}^N{2^{-R_j}}}}}\\)presto의 cardinality 구현은 두 가지 layer를 이용한다. sparse cardinality가 작다면, 이를 이용해서 계산한다. 정확하게 측정하기 위해, 모두 카운팅한다고 생각하면 된다. dense sparse로 작동하다가, 메모리 임계를 넘으면 dense로 변경된다. HLL을 이용한다. dense에서 HLL을 구현할 때 두 가지 자료구조를 이용한다. bucket과 overflow entries다.단순히 오른쪽부터 연속된 0의 길이를 구하고, bucket에 저장하면 됐었다.하지만, presto에서는 bucket 크기에 4비트를 할당했고, 만약 그 이상의 비트를 사용하면 overflow entries에 상위 비트들을 저장한다. Based on the statistical properties of the HLL algorithm, 4-bits is sufficient to encode the majority of the values in a given HLL structure.예로 길이가 32라면, bucket 하나의 크기가 4비트이기에, 하위 4비트를 저장한다. 이후 앞의 3비트는 overflow entries에 저장된다.이러면 조금이나 메모리를 더 아낄 수 있다. 주의할 점은 위의 방법은 저장하는 방법이다. 기존의 업데이트 방법이(max)나 비교하는 값은 HLL 그대로이다. 즉 값을 업데이트할 때는 overflow entries와 buckets을 합쳐 복원해야한다.REF, 읽어볼 글들메타 글https://engineering.fb.com/2018/12/13/data-infrastructure/hyperloglog/위키https://en.wikipedia.org/wiki/Flajolet%E2%80%93Martin_algorithmhttps://en.wikipedia.org/wiki/HyperLogLog논문https://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf영상https://www.youtube.com/watch?v=lJYufx0bfpwhttps://en.wikipedia.org/wiki/HyperLogLog" }, { "title": "추후 계획과 현 상황?", "url": "/posts/plan240508/", "categories": "Blogging, life", "tags": "life", "date": "2024-05-08 23:44:00 +0900", "snippet": "0. 현황, 듣고 있는 수업 토익 원트에 받을 만한 점수 받았다. 유튭 팁만 보다가 기출도 3회분 정도 풀고 간거 같다. 빨갱이 책은 산거 아까워서 다 풀었고, 파랭이 책도 아까워서 뒷부분만 다 풀어봤다. 컴파일러 솔직히 그냥 그렇다. 그냥 무미 건조하다. 아직 백엔드 부분을 다루지 않아서 그런지, 수업이 얕은 건지 감명 깊지는 않다. 보안 첨에는 재밌었는데 슬슬 물린다. 암호학만 다루다 보니, 뭔가 내용을 당연하다는 느낌으로 듣고 있다. 교수님이 이것저것 썰을 많이 알려주시는데, 대부분 알아서 입이 근질근질하다. 프로그래밍 언어 음 처음에는 어지러웠는데, 지금도 어지럽다. software foundation 읽기가 귀찮다. 사실상 독학인듯 근데 재밌다. 딱딱 맞아 떨어진다. OS 튜터링 튜티들이 좋은 점수 받아서 좋은거 같다. 내용들을 복습하는데, 공부했던 기억들이 새록새록하다. 그땐 정리가 잘 안된거 같았는데, 시간이 지나니 명확해지는 것 같다. 짬이 찬거 같다.( ? ) 1. 공부 계획 CS specifying systems 읽다가 pluscal먼저 배우는게 좋을 것 같아 Learn TLA+를 보기 시작했다. 공부하면서 막히거나 애매한 부분들을 기록으로 남겨두려고 한다. 학기 중이라 많은 시간을 내지는 못할 것 같긴하다. 분산 시스템을 공부하기 위한 내 로드맵은 다음의 글을 참고하고 있다. https://muratbuffalo.blogspot.com/2020/06/learning-about-distributed-systems.html MIT 분산 시스템 기말 범위도 빨리 보고 싶지만, 참고있다. 데이터베이스도 공부하고 싶은데, 애매하게 건들이기 싫어서 방학으로 미루었다. CMU의 수업이 오픈되어 있어, 과제를 하며 따라갈 것 같다. https://github.com/paulosman/database-systems 강화학습 튜토리얼도 공부하고 싶다. https://github.com/alessiodm/drl-zh CUDA 공부도 방학때 못해서 하고 싶다. GPU 공부도 하고 싶다. 재밌어보인다. https://github.com/adam-maj/tiny-gpu 교육용으로 가볍게 만들어놓은 repo 같은데, 댓글 보니까 그래픽 처리는 일절 없어 GPU가 아니라고 까이는 것 같다. (?) ML compilation 재밌어보인다. https://mlc.ai/index.html English speak 무료체험 중이다. 회화 수업은 좋은 것 같다. gpt 대화는 아쉽다. 내가 못해서 그런것 같기도 하다. 독해는 독해 책을 보려다가, 그냥 CS공부 자료보면서 하려한다. 따로 시간내기 어렵다. 텝스 단어장 봐야겠다. Hobby 탁구 주기적으로 치고 있다. 배우고 싶으나 학교 주변에는 탁구장도 무인으로 최근에 생겼다… 기타 배우고 싶다. 기숙사에 가져와 치기는 무리다. 피아노 치고 싶다. 학교에 피아노 치는 강의실 있었는데, 하필 기부로 강의실이 리워크 되면서 피아노는 사라졌다. (아니 …) 블로그 뭔가 스냅샷 느낌으로 남기는게 좋다고 생각되 다시 써보려한다. 이외에도 쓸 말이 많지만, 현재 배가 아프다. 밤 공복 상태에서 물 많이 마시면 꼭 아픈거 같다. 이게 물 때문인지 저녁을 매운걸 먹어서 그런지는 모르겠다.정리 : 하고 싶은 것은 많다." }, { "title": "tla+ vscode setting", "url": "/posts/tla+-setup/", "categories": "CS, Distributed_Systems, tla+", "tags": "Distributed_Systems, tla", "date": "2024-05-07 22:24:00 +0900", "snippet": "1. Install vscode-tlaplushttps://github.com/tlaplus/vscode-tlaplus/wiki/How-to-Install install extension install java sudo pacman -Syuyay jdk17-openjdk 2. Getting startedhttps://github.com/tlaplus/vscode-tlaplus/wiki/Getting-Started squares.tla 파일을 만든다. snippet이 있다. module pluscal pluscal을 사용하고, 다음의 스펙을 적는다.---- MODULE squares ----EXTENDS TLC, Integers(*--algorithm squaresbegin skip;end algorithm; *)==== 이후 TLA+: Parse module 명령을 쓴다. pluscal을 tla+로 바꿔준다. vscode에서 ctrl + p 누르고 &gt; 치고 검색하면 된다. TLA+: Check model 명령을 쓴다. tlc model checker를 이용한다. 아래의 그림과 같이 결과를 볼 수 있다. .out 파일에서 TLA+: Visualize TLC output을 치면 결과창을 다시 볼 수 있다. pdf로 spec을 뽑고 싶다면 pdflatex를 설치한다. 이후 Export ~~ pdf 명령을 실행한다. yay texlive-latex3. Eval 아래와 같이 특정 식이나 값을 eval 할 수 있다. 다만 ==== 아래에 (module 정의 아래에) 위치해야 잘 작동한다. 4. Invariant spec을 검증하기 위한 방법 중 하나이다. 어떤 프로그램이 실행됨에 따라 유지되는 성질을 말한다. 예) lamport clock에서 “인과 관계라면 time stamp 값이 크다” define이라는 block안에 variable definition과 algorithm proper를 적는다.아래와 같이 spec이 있다.---- MODULE invariant ----EXTENDS TLC, Integers, Sequences, FiniteSetsS == 1..10(*--algorithm invariantvariable seq \\in S \\X S \\X S \\X S; index = 1; seen = {}; is_unique = TRUE; define IsUnique(s) == Cardinality(seen) = Len(s) IsCorrect == pc = \"Done\" =&gt; is_unique = IsUnique(seq)end define;begin Iterate: while index &lt;= Len(seq) do if seq[index] \\notin seen then seen := seen \\union {seq[index]}; else is_unique := FALSE; end if; index := index + 1; end while;end algorithm; *)만약 IsCorrect 라는 invariant를 이용해 spec을 검증하고 싶다면 다음과 같이 한다. pluscal을 parse한다. (vscode 명령) ????.cfg 파일을 연다. INVARIANT IsCorrect를 적어준다. tlc checker를 부른다. (vscode 명령)일부로 invariant를 깨지게 하면, 다음과 같은 결과를 얻을 수 있다." }, { "title": "노트북 세팅", "url": "/posts/%EB%85%B8%ED%8A%B8%EB%B6%81-%EC%84%B8%ED%8C%85/", "categories": "tools", "tags": "life", "date": "2024-05-05 12:57:00 +0900", "snippet": "동기이번 학기에는 mac mini m1을 사용했었다. 적응도 했고, 이래저래 꾸미고 잘 섰다. 다만 프로그래밍 언어 수업때 opam으로 coq 설치과정에서 gmp관련 컴파일 에러로 고생을 했다. 근본적으로는 해결을 하지 못했다. 대신 NIX를 이용해서 vscoq을 설치해 사용했다. 처음에는 잘 썼는데 다른 파일들을 모듈로 불러오는 부분이 작동을 안해 결국 coq에서 기본으로 주는 툴을 썼다. 생각해보니 열받아서 그냥 맥은 폐기했다.시험기간이었어서 임시로 윈도우로 복귀했다. 시험이 끝나 endeavour OS를 세팅하여 쓰고 있다. 학교 교양 수업때나 인증작업 때문에 듀얼부팅으로 윈도우는 살려두었다.endeavour OS는 arch 계열이다. 3학년 초에 verilog로 cpu 설계할 때 궁금해서 써봤었다.우분투 계열은 뭔가 무거운 느낌이었고, ARCH를 쓰고 싶었다. 다만 ARCH 자체를 쓰기는 설치가 귀찮아서 endeavour를 설치했다.마침 최근 업데이트가 있었다.https://endeavouros.com/news/plasma-6-with-wayland-or-x11-option-and-qt-6-ported-calamares-meet-gemini/KDE plasma를 사용하였다. 다른 옵션도 많았는데, 이게 그냥 깔끔했다.테마kde 테마를 사용했다. https://github.com/catppuccin/kdegrub 는 Dark Eos grub theme로 해놨다. https://www.gnome-look.org/p/2138019 https://gitlab.com/VandalByte/darkmatter-grub-theme개인적으로 https://github.com/xenlism/Grub-themes 이 테마가 예쁜거 같은데 endeavour OS는 이미지가 없다.한글 입력기보고 따라했다. https://www.youtube.com/watch?v=InvQCjWIFKQ uim, 벼루 Kakaotalk lutris를 사용했다. 설치파일을 실행자로 게임 하나 만든다. 설치완료 후 실행파일 경로를 찾아서 게임을 하나 더 만든다.다만 문제는 한글 입력이 안된다…폰트는 안깨지는 것 같다. ( 광고 폰트는 깨진다. ? )설정을 좀 건드리면 될거 같은데 귀찮아서 그냥 영어로 쓰려한다.간단한 세팅들 vscode 설치 pacman으로는 oss 밖에 설치가 안된다. 예) ms의 c++ 익스텐션이 스토어에 안뜬다. https://www.nemonein.xyz/2022/03/6476/ chrome은 aur로 설치해야한다. obsidian과 폰트 설정 듀얼부팅시 블루투스 문제 연결시 블루투스 디바이스는 mac 주소와 key를 맵핑시켜놓는데, OS가 바뀌면 mac은 같은데 key가 같아 연결이 안되는 문제가 생긴다. 디바이스는 pair를 하나만 가지고 있기 때문이다. 아래의 방법으로 해결할 수 있다. 다만 나는 윈도우를 사용할 일이 거의 없기에, 그냥 pass했다. https://github.com/spxak1/weywot/blob/main/guides/bt_dualboot.md 깃 credential, project 파일들 clone obsidian 세팅 폰트 세팅 git 확장 설치 vault 연결 블로그 글 편집을 obsidian으로 한다. daily note template세팅 이미지 붙일 때, 특정 폴더에 저장되게 만들었다. 경로 또한 절대경로로 해야 잘 보인다. 다만 문제가 이미지 링크 맨 앞에 /를 붙여야 했던거 같다. use wikilinks 이것도 꺼야한다.이런 모습이다.할만한거, 다만 귀찮다. zsh multitouch operation https://github.com/iberianpig/fusuma 배터리 tlp https://pstudio411.tistory.com/entry/Ubuntu-2004-%EB%85%B8%ED%8A%B8%EB%B6%81%EC%97%94-%ED%95%84%EC%88%98-%EC%A0%84%EC%9B%90-%EA%B4%80%EB%A6%AC " }, { "title": "SLS sat solver 서칭", "url": "/posts/paper-searching/", "categories": "CS, algortihm", "tags": "sls, 연구실, sat", "date": "2023-12-18 10:46:00 +0900", "snippet": "Improving two-mode algorithm via probabilistic selection for solving satisfiability problem Sattime : i C, Li Y. Satisfying versus falsifying in local search for satisfiability. In: Proceedings of the 15th International Conference on Theory and Applications of Satisfiability Testing–SAT 2012, Trento, Italy, 2012, 477-478. dimetheus : https://scholar.google.com/scholar_lookup?title=Sat%20solving%20with%20message%20passing&amp;author=O.%20Gableske&amp;publication_year=2016 CCAnr : S . Cai, C. Luo, K. Su, CCAnr: A configuration checking based local search solver for non-random satisfiability. InProceedings of the 18th International Conference on Theory and Applications of Satisfiability Testing–SAT 2015, USA, 2015, 1-8. CCAnr + CNC : . Cai, C. Luo, X. Zhang, J. Zhang, Improving local search for structured SAT formulas via unit propagation based construct and cut initialization (short paper). In: Proceedings of the 27th International Conference on Principles and Practice of Constraint Programming (CP 2021), Saarland, 2021, 5:1-5:10.SLS algorithm은 두 가지로 나뉜다. two-mode SLS solvers : greedy mode and diversification mode focused local searchfocused local search WalkSAT, WalkSATlm, ProbSAT walkSATlm : S. Cai, C. Luo, K. Su, Improving walksat by effective tie-breaking and efficient implementation, Comput. J. 58 (11) (2015) 2864 –2875.Two mode greedy mode : select the flipping variable in a global local search diversification : explores the search space, evade local optima typically combination of deterministic, stochasticA survey of SAT solver : Weiwei Gong and Xu Zhou sparrow probSATIncomplete Algorithms parallelismPGSAT is a parallel version of GSAT. In this algorithm, the variables are divided into subsets, which are assigned to different processors. “A. Roli, “Criticality and parallelism in structured sat instances,” in International Conference on Principles and Practice of Constraint Programming (Springer, 2002), pp. 714–719.”PGWSAT improves PGSAT, which randomly selects a variable to be flipped in an unsatisfiable clause with a certain probability during PGSAT execution. “A. Roli, M. Blesa, and C. Blum, (2005).”Proceedings of SAT Competition 2023 : Solver, Benchmark and Proof Checker DescriptionsYallin A Linear Weight Transfer Rule for Local Search , Md Solimul Chowdhury , Cayden R. Codel , and Marijn J.H. Heule “We implemented our modifications to ddfw on top of the solver yalsat.” “Dynamic local search (DLS) algorithms are SLS algorithms that assign a weight to each clause.”정리 Improving stochastic local search for uniform k-SAT by generating appropriate initial assignment, Huimin Fu, Wuyang Zhang, Guanfeng Wu, Yang Xu, Jun Liurandom track of SAT competitions Sparrow : 2011 // 19 Balint A, Fröhlich A. Improving stochastic local search for SAT with a new probability distribution. Paper presented at: Proceedings of the SAT-10,Edinburgh, Scotland; 2010:10-15. ProbSat : 2013 // 20, 21 CCASat : 2012 // 6 Cai S, Su K. Local search for boolean satisfiability with configuration checking and subscore. Artif Intell. 2013;204:75-98. FrwCB // 15 Luo C, Cai S, Wu W, Su K. Focused random walk with configuration checking and break minimum for satisfiability. Paper presented at: Proceedings of the International Conference on Principles and Practice of Constraint Programming,Berlin, Heidelberg; 2013:481-496. WalkSATlm // 22 Cai S, Luo C, Su K. Improving WalkSAT by effective tie-breaking and efficient implementation. Comput J. 2015;58:2864-2875. DCCASat // 16 Luo C, Cai S, Wu W, Su K. Double configuration checking in stochastic local search for satisfiability. Paper presented at: Proceedings of the AAAI-14,Québec City, Québec, Canada; 2014:2703-2709. CSCCSat : silver 2016 // 23 Luo C, Cai S, Wu W, Su K. CSCCSat2014: Solver description. Paper presented at: Proceedings of the SAT-2014,Vienna, Austria; 2014:25-26. dimetheus : 2016 // 10 Gableske O. Dimetheus: solver description. Paper presented at: Proceedings of the SAT- 2016,Bordeaux, France; 2016:37-38. Score_2 SAT : bronze 2017 // 24 - Cai S, Luo C. Score2SAT: solver description. Paper presented at: Proceedings of the SAT-2017,Melbourne, Australia; 2017:34. yalsat : 2017 // 25 CSCCSat combination of two SLS solvers FrwCB DCCASat Based on the clause-to-variable ratio of the instance, pick from 2 to solve It won the “3rd Place Award” in the random SAT track of SAT Competition 2014 the “2nd Place Award” in the random SAT track of SAT Competition 2016. Score_2 SAT combination of two SLS solvers DCCASat WalkSATlm won the “3rd Place Award” in the random SAT track of SAT Competition 2017. Sparrow winner of the SAT Competition 2011 category random SAT. based on gNovelty+ SLS on H/w A. McDonald, Parallel walksat with clause learning. data analysis project papers, 2009 WalkSAT을 스레드로 병렬화한 논문, 각 스레드는 다른 초기 값을 가진다. Accelerating an FPGA-Based SAT Solver by Software and Hardware Co-design https://ietresearch.onlinelibrary.wiley.com/doi/pdfdirect/10.1049/cje.2019.06015 H. Deleau, C. Jaillet, and M. Krajecki, “Gpu4sat: solving the sat problem on gpu,” in PARA 2008 9th International Workshop on State–of–the–Art in Scientific and Parallel Computing, Trondheim, Norway (2008). https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=807f4b8069782bba68ca2bfb4ad77ef56f8cf30f SAT problem instance를 행렬로 표현한 뒤 incomplete methods를 이용하여 푼 논문 " }, { "title": "2023 Winter Vacation", "url": "/posts/winter/", "categories": "Blogging, life", "tags": "plan", "date": "2023-12-12 19:14:00 +0900", "snippet": " 인턴 시작 전까지 할 것들 Database internals 읽기 프로젝트 문서 읽기 rust 공부 - 방학 할 것들 \t- 텝스\t- 연구- 방학 하고 싶은 것들\t- rust 공부\t- 컴파일러 공부 \t- cuda 공부\t- llm 공부 \t- 코테 - 계획적인 삶\t- 잠자고 일어나는 시간 고정\t- 운동\t- 시간 관리" }, { "title": "gpu 서버 세팅", "url": "/posts/gpuServerSetting/", "categories": "tools", "tags": "", "date": "2023-10-30 22:38:00 +0900", "snippet": " tmux로 gpu 세션 받아 유지함 아나콘다 설치# 설치 파일을 다운로드할 경로로 이동(to home directory)cd ~# Anaconda 설치 파일 다운로드wget https://repo.anaconda.com/archive/Anaconda3-2023.03-1-Linux-x86_64.sh# 설치 파일 실행bash Anaconda3-2020.11-Linux-x86_64.sh# Anaconda 설치 후 재접속exit# conda 환경 생성 예시conda create -n &lt;환경 이름&gt; python=&lt;파이썬 버전&gt;# conda 환경 실행conda activate &lt;환경 이름&gt; 파이썬 버전 붙여서 환경 만들면 pip 도 설치돼서, pip 경로가 가상환경 하위 디렉토리로 잡힌다. 격리된다. 주피터에서 conda 환 쓰기 위해서 다음을 작업pip install jupyter notebookpython -m ipykernel install --user 이름 --display-name \"주피터에 보일 이름\" python 12버전은 torch가 아직 지원 안 한다.이후 실행jupyter-notebook --no-browser --ip=&lt;165.***.***.***&gt; --port=&lt;port number&gt;or jupyter-lab python 12버전은 torch가 아직 지원 안 한다. 낮춰서 설치 " }, { "title": "xv6 백업", "url": "/posts/xv6%EB%B0%B1%EC%97%85/", "categories": "mit6.1810, xv6", "tags": "cs, xv6, os", "date": "2023-10-23 20:53:00 +0900", "snippet": "2장 systemcallos의 3가지 multiplexing isolation interaction응용프로그램은 믿지 못하고 버그가 있으며 강한 고립을 원할 수 있다. 직접 자원을 사용하기보다 파일 시스템으로 추상화하는 것이 강한 고립의 도움이 된다.cpu 전환시 레지스터 값 등이 저장되기 때문에 프로세스는 시분할에 대해 몰라도 된다.2-2. 모드os가 다른 응용프로그램이 오류를 일으켜도 잘 돌아가길 원한다.이를 위해서는 프로세스들이 다른 프로세스에 침범하거나 os를 건들이지 못하게 만들어야한다.이를 위해 cpu에서 도움을 준다. machine mode supervision mode user modexv6는 부팅 시 일부 코드를 머신모드에서 돌리고 감독모드로 전환한다.2-3. 커널감독 모드에서 어떤 코드를 돌릴지는 매우 중요하다. 이에 따라 두가지로 나뉜다. monolithic kernel micro kernel2-5. 프로세스  ( xv6에서 ) 고립의 단위는 프로세스이다.  프로세스 추상화는 다른 프로세스를 망가뜨리거나 접근하지 못하게 막으며 커널 또한 접근하지 못하게 만든다. 이는 커널에서 다음 같은 기술들로 만들어진다. user/supervision mode flag address spaces time-slicing of threads고립성을 강화하기 위해 프로세스 추상화는 자신만의 머신을 가진다고 착각 고유의 메모리와 주소를 가지며 전체를 사용한다고 착각 자신의 cpu 가 있다고 착각프로세스는 프로세스의 명령을 실행시키는  실행 스레드를 가지고 있다.두가지 스택을 가지고 있다. user stack kernel stackRISC-V의 ecall이 실행되면 하드웨어 특권 레벨이 올라간다. pc를 커널의 엔트리로 욺긴다 엔트리에서 커널 스택으로 바꾸고 커널 명령어를 실행한다.시스템 콜이 완료되면 유저 스택으로 바꾸고 sret명령으로 유저 공간으로 돌아간다 하드웨어 특권 레벨이 내려가고 이전 명령어를 실행한다. 2-6. booting 3. page table3.1 paging hwRISC-V 명령어는 가상 주소를 조작한다.RISC-V 페이지 테이블 하드웨어가 물리 주소와 가상주소를 매핑해 연결한다.xv6는 39비트 주소를 사용한다.  그중 앞의 27비트를 PTE를 찾는데 사용한다.PTE / PAGE TABLE ENTRIES $ 2^{27}$ 크기의 배열이다. PPN / Physical page number     - 44bit some flags가상 주소의 12(39-27) 비트가 남는다. PTE의 PPN 44비트를 56비트 물리주소에 복사하고 남은 12비트에 가상주소의 남은 12비트를 복사한다.64비트 체계지만 가상 주소는 앞 25비트가 사용되지 않았고, PTE 포맷 또한 10비트 늘려서 (54 + 10) 사용할 수 있다. ( 물리적 페이지 번호를 늘릴 수 있다. )$2^{39} = 512GB$ 로 프로세스에게 충분한 공간이다. $2^{56}$ 의 크기또한 I/O 디바이스와 DRAM에게 충분하다.translate가상 주소는 물리 주소로 3 단계로 변경된다.  페이지 테이블은 물리 주소에 3 level 트리로 저장된다. 루트는 512개의 PTE를 가지고 있는4096byte 크기의 페이지 테이블이다. $2^9 * 2^9 * 2^9=2^{27}$  ( 전체 페이지 개수를 쪼갠 것이다. ) 페이지를 쪼개는 것의 이점은 전체 페이지 디렉토리를 생략할 수 있다는 것이다.0번 페이지만 사용된다면 1번부터 511번까지의 페이지는 invalid 된다. 그들의 두번째 페이지 테이블과 3번째 테이블은 무시된다.하지만 cpu가 3 PTE를 메모리에서 불러와야하는 문제가 있다. 이에 PTE 캐시를 사용한다. 이를 TLB라고 부른다.각각의 페이지 테이블은 flag bits가 있다.  TLB / translation Look aside Buffer3.3 CODEpagetable_t 자료구조는 말 그대로 root page table page의 포인터이다. walk    - 가상 주소의 PTE를 찾는다. mappages    - 새로운 매핑을 위해 PTE를 설치한다. KVM m    - kernel page table 조작 UVM m    - user page table 조작 copyout, copyin    - 유저 가상 주소로 / 에서 데이터를 복사한다.    - vm.c에 정의 됨 - 물리 주소 변환때문에부팅 되면 main에서는 kvminit을 부른다. 커널 페이지를 만들기 위해 kvmmake를 사용한다.kvmmake는 paging 전에 발생한다. 주소가 직접 매핑된다.물리적 메모리 페이지를 할당받아 첫번째 루트 페이지 테이블을 잡아준다.kvmmap을 불러 변환을 설치한다 / 매핑한다.  ( 커널의 명령어, 데이터, 물리 메모리, 장치 메모리 범위 ) 직접 매핑proc_mapstacks로 각 프로세스들을 위해 커널 스택을 할 당한다. (“proc_mapstacks” (Cox 등, p. 36) )kvmmap은 mappages를 사용한다.  mappages는 가상주소와 물리주소를 사이즈 크기만큼 맵핑해서 pte에 집어 넣는다. 이때 페이지 간격으로 이 작업을 진행한다.가상주소에 대응되는 PTE를 찾는다. 이후 물리 주소로 pte를 초기화한다. pte valid 설정도 해준다.walk 시 9비트씩 3레벨 페이지 테이블을 탐색한다. PTE가 valid하지 않으면 해당 page가 allocated 되지 않은 것이다. alloc이 설정되어 있으면 페이지 테이블을 만들어주며 진행한다. 마지막에는 3번째 페이지 테이블 엔트리의 주소를 반환한다.위의 코드는 물리 메모리가 커널 가상 주소와 직접 매핑 되어 있어야 작동한다.main은 knminithart를 부른다.  satp에 root page table page를 저장한다.  &gt; 이후 가사 주소가 활성화 된다.cpu 가 페이지 테이블을 바꾸면 TLB를 무효화 해야한다.“sfence.vma” (Cox 등, p. 36) 를 이용해 현재 cpu의 TLB를 flush 한다.3.6 process address space4장 trap / systemcall4.0cpu에는 3가지 특수한 명령이 있다. systemcall    - ecall 로 실행    - 커널이 무엇인가 해야됨 exception    - user나 kernel이 illegal한 행동을 할 때 발생 interrupt    - 디바이스에서 시그널을 보냄책에서는 trap으로 위 상황들을 이야기한다.trap은 transparent 해야한다. 이전 실행되던 코드들은 resume 되야한다. special happened를 알 필요가 없다. 이는 특히 코드가 예상하지 못하는 디바이스 인터럽트에 특히 중요하다.trap은 kernel에서 handling한다. 이는 systemcall에 있어서 자연스럽다. 커널만이 디바이스에 접근 가능하도록 격리 멀티 프로세서간 디바이스를 공유하기 편하다. 잘못된 프로그램을 종료하여 모든 예외에 응답 trap의 4단계 하드웨어 작업이 cpu에 의해 얻어짐 어셈블리는 커널 c 코드를 위해 준비 c 함수는 트랩을 어떻게 할지 정함 시스템 콜이나 드라이버 서비스 루틴 실행 4.1 trap machineryRISC-V의 레지스터 stvec : trap handler의 주소를 담는다. sepc : pc를 저장해 놓는다.     - sret 명령으로 pc에 sepc를 대입해 복구한다. scause : trap 이유를 담는 번호 저장 sscratch : 레지스터 오버라이팅을 피하는데 도움준다. sstatus     - SIE 비트는 디바이스 인터럽트가  가능한지 나타낸다.    - clear 하면 인터럽트를 미룬다.    - SPP 비트는 trap이 어디서 왔는지 나타낸다. ( 유저인지 super인지 )        - 즉 무슨 모드로 sret 해야하는지 알려준다.트랩 진행과정 / RISC-V 하드웨어 만약 trap이 디바이스 인터럽트이고 SIE가 clear하면 기다린다. SIE 비트를 clear한다. pc를 sepc에 복사한다. 현재 모드를 SPP 비트에 저장한다. scause 설정한다. supervisor 모드로 설정 stvec -&gt; pc로 복사 새로운 pc에서 실행 cpu는 커널 페이지 테이블로 스위치 하지 않는다. 커널 스택으로 바꾸지 않는다. pc 외 어떤 레지스터도 건들이지 않는다.   위 작업은 커널이 해줘야한다. 유연성 확보4.2 Traps from user space uservec usertrap usertrapret userret xv6 트랩 처리의 제약은 트랩시 페이지 테이블을 전환하지 않는다는 점이다. ( 트랩 처리 코드가 시작되는 지점에서 유저 모드 페이지 테이블이 사용됨 ) 이를 위해서는 trap handler 주소 ( stvec )가  유저 페이지 테이블에 valid mapping 되야한다.??? 또한 trap handling code는 kernel page table로 교체가 필요할 수 있다. 이 경우에서도 돌아가기 위해서는 커널 페이지 테이블에도 trap handler 주소가 valid mapping 되어야 한다.두가지 모두를 만족시키기 위해 trampoline page를 사용한다.trampoline page uservec 을 포함한다.    - trap handling 코드이다. 모든 프로세서의 TRAMPOLINE에 매핑된다.    - 이는 가상 주소의 최상단이다. 커널 페이지 테이블에도 TRAMPOLINE 영역에 매핑된다.    - 같은 주소에 매핑되므로 switch 후에도 계속 실행가능 유저 페이지 테이블에 PTE_U 없이 매핑되어 supervisior에서 실행가능하다.uservec uservec 이 실행될때 32개의 레지스터를 저장해야한다.    1. 메모리 어딘가에 저장된다.    2. 이를 위해 주소를 담을 레지스터가 필요하다. sscratch 레지스터를 사용 ( RISC-V ) csrw 명령어로 a0를 sscratch에 저장한다. 커널은 프로세서마다 trapframe 구조를 만들어 32개의 레지스터를 저장하게 한다. TRAPFRAME ( 유저 페이지 테이블에 있는 가상주소 ) 에 커널의 trapframe이 매핑된다. TRAPFRAME의 주소를 a0에 욺기고 레지스터들을 그곳에 저장한다.     1. 유저의 a0 또한 sscratch에서 가져와 저장한다. uservec은 초록 정보들을 트랩프레임에 가져오고    1. satp을 커널 페이지 테이블로 바꾼다.    2. usertrap을 호출한다.usertraptrap의 원인을 결정하고 실행하고, 반환한다. stvec을 바꾼다.    1. kernelvec 에 의해 핸들링 되도록    2. 커널 안에서 실행중이므로 만약 인터럽트가 발생하면 커널 벡터가 핸들링 해야하기 때문이다. sepc 저장한다.    1. 다른 프로세서로 스위치되거나, sepc를 수정하고도 유저 공간으로 return할 수 있다. 원인에 따라…    1. syscall        1. add 4 pc            1. 돌아와서 다음 문장 실행하기 위해            2. RISC-V는 ecall명령어의 포인터를 pc에 남김    2. devintr    3. ex-ception        1. killusertrapret유저 공간으로 돌아가기 위한 과정이다. stvec이 uservec을 가르키게 만든다. sepc 를 저장된 pc 값으로 설정 userret 부른다.     1. trapoline page에 존재하는    2. switch page tables4.3 systemcall 호출 과정 a7에 시스템콜 번호가 들어간다. a0와 a1에 인자가 들어간다. ecall을 통해 커널에 trap을 건다. uservec, usertrap, syscall이 실행된다. sys_exec 함수가 실행된다. return 값은 a0에 들어간다. 4.4 인자시스템 콜의 구현은 user 코드에서 인자를 찾아와야한다.유저는 시스템콜 wrapper 함수를 부른 것이다. 레지스터에 argument가 저장됨커널이 찾을 수 있도록, 커널 트랩 코드는 user 레지스터를 현재 프로세스의 트랩 프레임에 저장한다.exec 예시를 보면 문자열 인수를 지정하는 포인터 배열을 커널 공간으로 넘긴다. 두가지 문제점이 있다. invalid 포인터를 넘겨 이상한 짓을 할 수 있다. 커널 페이지 테이블과 유저 테이블이 일치 하지 않는다. 커널은 넘겨 받은 주소에 명령어를 실행할 수 없다. 이를 위해 copyinstr 명령어를 사용한다.“A” (Cox 등, p. 48)" }, { "title": "네트워크 읽어볼만한 글", "url": "/posts/read/", "categories": "CS, network", "tags": "cs, network", "date": "2023-10-12 12:48:00 +0900", "snippet": "https://blog.naver.com/goduck2/221112593320https://blog.naver.com/PostView.naver?blogId=goduck2&amp;logNo=221113532619&amp;parentCategoryNo=&amp;categoryNo=&amp;viewDate=&amp;isShowPopularPosts=false&amp;from=postView" }, { "title": "McgrawHill TCP, IP suit practice set", "url": "/posts/tcpPracticeSet/", "categories": "CS, network", "tags": "cs, network, tcp", "date": "2023-10-10 19:58:00 +0900", "snippet": " 머리도 아프고 시험 공부도 잘 안돼서 책에 연습문제를 풀어보려 한다.An IP datagram is carrying a TCP segment destined for address 130.14.16.17. The destination port address is corrupted and it arrives at destination 130.14.16.19. How does the receiving TCP react to this error? checksum을 이용해 detect한다.\\[\\text{checksum} = \\text{pseudo header} + \\text{tcp header + payload}\\] 이기에 pseudo header에서 ip 값이 다른 것을 확인한다. 패킷은 버린다.What is the maximum size of the TCP header? What is the minimum size of the TCP header? 헤더의 HLEN field는 4비트이다. 헤더 사이즈 % 4 값을 담는다. 이에 표현 가능한 범위는 20(default) ~ 60이다. 고로 60byte가 최대다.If the value of HLEN is 0111, how many bytes of option are included in the segment? 7x4 = 28, default가 20byte이기에 옵션은 8byteWhat can you say about the TCP segment in which the value of the control field is one of the following: a. 000000 b. 000001 c. 010001 d. 000100 e. 000010 f. 010010 URG / ACK / PSH / RST / SYN / FIN a : 그냥 패킷 전송, ack 없음 b : FIN 종료 요청 c : FIN+ACK / server가 보통 passive close할 때 -&gt; 3way handshake d : RST 요청 e :  SYN 요청 f : SYN + ACKThe following is a dump of a TCP header in hexadecimal format.(0532_0017 0000_0001 0000_0000 5002_07FF 0000_0000)_16_a. What is the source port number? 1330b. What is the destination port number? 23c. What the sequence number? 1d. What is the acknowledgment number? 0e. What is the length of the header? 5x4 = 20f. What is the type of the segment? SYNg. What is the window size? 2,047To make the initial sequence number a random number, most systems start the counter at 1 during bootstrap and increment the counter by 64,000 every half second. How long does it take for the counter to wrap around? 2^32-1 = 4,294,967,295 1 + 6400 x Time = 4,294,967,295 TIME / 2 = 335,544 sIn a TCP connection, the initial sequence number at the client site is 2,171. The client opens the connection, sends only one segment carrying 1,000 bytes of data, and closes the connection. What is the value of the sequence number in each of the following segments sent by the client?a. The SYN segment? 2171b. The data segment? 2172 / syn에서 1byte 소모c. The FIN segment? 3172 / 1000byte 보냈기에 그 다음 3172In a connection, the value of cwnd is 3000 and the value of rwnd is 5000. The host has sent 2,000 bytes, which have not been acknowledged. How many more bytes can be sent? window = 3000 1000byte 가능 / 윈도우는 ack이 와야 왼쪽 벽이 오른쪽으로 이동한다.TCP opens a connection using an initial sequence number (ISN) of 14,534. The other party opens the connection with an ISN of 21,732.a. Show the three TCP segments during the connection establishment. SYN : 14534 / - SYN + ACK : 21732 / 14535 ACK : - / 21733b. Show the contents of the segments during the data transmission if the initiator sends a segment containing the message “Hello dear customer” and the other party answers with a segment containing “Hi there seller.” Hello-dear-customer = 19글자 19 x 1byte -&gt; 20byte (1 byte padding 16비트의 배수로 만듬 ) segment : 14535 / 21733 Hi there seller = 15글자 15byte -&gt; 16byte ( 1byte padding ) segment : 21733 / 14555c. Show the contents of the segments during the connection termination. FIN : 14555 / 21749 FIN + ACK : 21749 / 14556 ACK : - / 21750A TCP connection is using a window size of 10,000 bytes and the previous acknowledgment number was 22,001. It receives a segment with acknowledgment number 24,001 and window size advertisement of 12,000. Draw a diagram to show the situation of the window before and after.A window holds bytes 2001 to 5000. The next byte to be sent is 3001. Draw a fig[1]ure to show the situation of the window after the following two events. a. An ACK segment with the acknowledgment number 2500 and window size advertisement 4000 is received. b. A segment carrying 1,000 bytes is sent.A TCP connection is in the ESTABLISHED state. The following events occur one after another:a. A FIN segment is received.b. The application sends a “close” message.What is the state of the connection after each event? What is the action after each event? a : CLOSE WAIT b : LAST ACK ( server ) , FIN-WAIT1 ( client )A TCP connection is in the ESTABLISHED state. The following events occur one after another:a. The application sends a “close” message.b. An ACK segment is received.What is the state of the connection after each event? What is the action after each event a : FIN-WAIT1 b : FINE WAIT2Show a congestion control diagram like Figure 15.37 using the following scenario. Assume a maximum window size of 64 segments. a. Three duplicate ACKs are received after the fourth RTT. b. A time-out occurs after the sixth RTT." }, { "title": "Flow Control in TCP", "url": "/posts/flowcontrol/", "categories": "CS, network", "tags": "cs, network, tcp", "date": "2023-09-30 17:24:00 +0900", "snippet": "reference : Tcp/IP Protocol Suite/Forouzan, Behrouz A.Flow Control flow control balances the rate a producer creates data with the rate a consumer can use the data TCP seperates flow control from error control we assume that tcp is error free flow control feedback receiving TCP -&gt; sending TCP -&gt; sending process most implements of TCP don’t provide flow control feedback from the receving process to receiving TCP sending TCP -&gt; sending process achieved through simple rejection of data by sending TCP when its window is full so we will focus on “receiving TCP -&gt; sending TCP”Opening and Closing window TCP forces the sender and receiver to adjust their window sizes receive window close : more bytes arrive from the sender open : more bytes are pulled by the process send window close : when new ack allows it to do so open : when rwnd(from revceiver) aloow it to do so receive window size Shrinking of window send window can shrink if the receiver defines a value for rwnd but receive window can’t shrink some implementations don’t allow the shrinking of the send window so the receiver needs to keep the following relationship \\[\\text{new ackNO} + \\text{new rwnd} \\ge \\text{last ackNO} + \\text{last rwnd}\\] so does not allow the right wall ofr the send window to move to the left the left side of the inequality represents theh new position of the right wall the right side shows the old position of the right wall if you violate this mandate, it causes the following problem\\[210 \\text{ (new ack) } + 4 \\text{ (new rwnd) } &lt; 206 \\text{ (last ack) } + 12 \\text{ (last rwnd) }\\] ackNo = 216 seems to be typo sender sent bytes 206~214 206~209 are acked and purged but new rwnd value is 4. shrink! byte 214 has been already sent is outside the window the receiver does not know which of the bytes 210 to 217 has already been sent one way to prevent this situation receiver should wait until more bytes are consumed by its process to meet the relationship above Silly Window Syndrome this problem can arise in the sliding window op when either sending application creates data slowly receiving application consumes data slowly or both if TCP sends segments containing only 1byte of data it needs 41byte datagram 20bytes - tcp header 20bytes - ip header … overhead 41/1 The inefficiency is even worse after accounting for the data link, physical layer overheadSyndrome created by the sender when the sender creates data slowly, it cause the silly window syndrome The solution is to prevent the sending TCP from sending the data byte by byte TCP must be forced to wait and collect data to send in a larger block How long wait? too long -&gt; delay system not enough -&gt; syndrome again Nagle’s Algorithm TCP send the first piece of data it received from the app even if it is only 1 byte After sending the first segment, TCP accumulates data in the output buffer. wait until receiving ACK for first segment enough data has accumulated to fill maximum size segment repeatSyndrome create by the receiver Suppose the sending program create data in blocks of 1kb receving program consumes data 1byte at a time receving buffer of reveving TCP is 4kb the sender sends the 4kb of data the receving buffer is full it advertises a window size of zero sender should stop the 1 byte consumed by receiver now there is 1 byte of space in the receving buffer announce window size of 1 byte sending TCP which is eagerly waiting to send data sends a segment carrying 1byte silly window syndrome again…Clark’s Solution send an ack as soon as the data arrive but set rwnd to “zero” untile either there is enough space to accommodate a seg of max size or least half of the receive buffers is empty Delayed Ack delay sending the ack when a segment arrives, not ack immediately wait until there is a decent amount of space in its incoming buffer delaying ack prevents the sending TCP from sliding its window also has another advantage reduces traffic however there also disadvantage sender unnecessarily retransmitting the unacknowledged segment TCP balances the adv, disadv should not be delayed by more than 500ms " }, { "title": "tcp 3WHS in linux kernel 이것저것", "url": "/posts/network3WHS/", "categories": "CS, network", "tags": "cs, network, socket, linux", "date": "2023-09-24 22:06:00 +0900", "snippet": "Socket 프로그래밍에서 3WHS는 어떻게 작동하는가? 혼자 삽질하다 좋은 글을 찾았다. https://levelup.gitconnected.com/deep-dive-into-tcp-connection-establishment-process-f6cfb7b4e8e1 https://stackoverflow.com/questions/63232891/confusion-about-syn-queue-and-accept-queue이해가 안됨 강의를 듣던 도중 아래 그림이 이해 가지 않았다. 연결 요청을 대기하는 큐에서 accept을 받으면 연결을 수락하고 새로운 소켓을 반환한다는 내용이었다. 내가 잘 못 들었을 수도? 궁금했던 점 sin+ack을 보내주고 큐에 넣어두면 마지막 ack을 보내주지 않은 상태의 연결 요청이 큐에 존재 accept은 큐에서 마지막 ack를 받으면 연결 요청을 가져와 반환해준다는 데 큐의 여러 요청 중, 어떤 요청이 마지막 ack을 보냈는지 구분하는가? 스캔하면 굳이 큐를? ack을 받으면 accept이 sleep하다 깨는 것인가? 즉 큐가 비어있으면 sleep하는 것이 아닌, ack을 받은 연결 요청이 없을 때 sleep하는 것인가? 이에 리눅스 커널 코드를 찾아보았다. 다만 이해가 가지 않았다. 그러던 도중 다음 블로그를 참고했다. 그래도 설명이 부족했다. tfo, syn cookie등 모르는 개념이 튀어 나옴 다음 사진을 찾게 되었다. Addison Wesley : UNIX Network Programming 의 책의 listen 파트 부분이다. 두 가지 큐로 관리되는 것이다. 이를 보고 이해가 갔다. 즉 syn 요청이 오면 syn queue에 대기 시키고 마지막 ack이 오면 ack queue로 욺긴다. 이후 accept이 불리면 ack queue에서 가져온다. 큐가 2개 였다. 이를 커널 코드에서 찾기 위해 다시 들여다 봤다. 근데 syn queue는 보이지 않았다. 다음 블로그를 보며 코드를 봤는데 정리가 잘되어 있는 것 같았다. 다만 아직 syn queue ( request queue )에 대한 설명이 이해가 안 갔다. ehash와 qlen으로 큐의 역할을 대체한다는데 … ? ?? ? ? ?? 스택 오버 플로우나와 같이 혼란에 빠진 의문의 사람을 찾았다. 그렇다. ehash에 request들을 저장하고, qlen으로 이들의 크기를 관리한다. ehash는 syn queue로만 사용되지 않는다. request_sock_queue는 위 블로그의 말처럼 accept queue이다. 이들의 길이는 sk_ack_backlog로 관리된다. 즉 개념 상 큐 느낌의 것이 존재하는 것이다.밑은 이것저것 적어 놓은 것이다.ack 이 도착 listen 소켓이 있는지 찾아본다. looked up __inet_lookup __inet_lookup_established ehash를 look up한다. 일시적인 request_sock을 sock으로 cast TCP_NEW_SYN_RECV 상태이기에 이 if문으로 분기 tcp_check_req 가 child socket만듬 ( cloning listening socket) TCP_SYN_RECV상태 이후 __inet_lookup_skb가 찾을 수 있도록 ehash에 넣어준다. mini socketehash에서 삭제, normal 소켓이 ehash에 추가됐기에… listen은 단순히 listen상태로 만들어준다. 이후 connect 요청이 오면 대기 큐에 어떻게 관리가 되는가? accept에서는 큐에서 어떻게 가져와 사용하는가? ( 마지막 ack의 처리는 어떻게? ) tcp_v4_rcv 에서 -&gt; tcp_v4_do_rcv를 불러서 tcp요청 처리 tcp_rcv_state_process가 불림 listen 상태일 때 /* This function implements the receiving procedure of RFC 793 for all states except ESTABLISHED and TIME_WAIT. It’s called from both tcp_v4_rcv and tcp_v6_rcv and should be address independent. */ conn_request 함수를 부름 구조체에 정의되어 있음 구조체는 ipv4_specific으로 구현 tcp_v4_conn_request 라는 함수로 맵핑됨 ( tcp_ipv4.c) tcp_conn_request로 움겨감 tcp_input.c 에 구현됨 fastopen 은 tfo 방법을 위한 것 같다. else 구문을 보면 syn ack 보내는 것 확인 가능 accept은 다음 함수에서 처리 그림에는 없지만 reqsk_put 함수가 accept 마지막에 불린다. req을 free해준다. 다만 tfo 설정이면 null 값으로 만들어 살려주고 reqsk_fastopen_remove가 지우는 것 같다. https://charsyam.wordpress.com/2018/01/09/%ec%9e%85-%ea%b0%9c%eb%b0%9c-ipv4-tcp-socket-listen-%ec%97%90%ec%84%9c-accept-%ea%b9%8c%ec%a7%80/Yes, the 3-way handshake can be performed at any time after listen() exits. But how the handshake is managed depends on the kernel. When a new connection arrives, some kernels complete the 3-way handshake immediately and put the connection into a separate queue for accept() to pull from. Some kernels only perform a partial handshake and then finish it only when accept() is actually called. – Remy Lebeau Jan 12, 2021 at 19:20 이걸로 어느 정도 의문이 해결됨 백로그 큐가 두 개로 관리된다. incomplete connection queue complete connection queuehttps://notes.shichao.io/unp/ch4/ &lt;- 책이 좋긴하다https://levelup.gitconnected.com/deep-dive-into-tcp-connection-establishment-process-f6cfb7b4e8e1 근데 사실 큐가 2개 구현되지는 않는다!! 맨 위 링크 참고 inet_csk_accept 함수에서 가져오는 큐의 struct 정의 이다. established 된 소켓들을 가지고 있는다. " }, { "title": "Network time wait", "url": "/posts/Network-time-wait/", "categories": "CS, network", "tags": "time_wait, socket", "date": "2023-09-21 22:13:00 +0900", "snippet": "https://tech.kakao.com/2016/04/21/closewait-timewait/ 다음 상황은 hserver에서 소켓을 열고 hclient에서 접속한 뒤,hclient는 close, hserver는 close하고 대기하는 장면이다. 오른쪽 위를 보면 tcp 소켓이 fd에 저장되어 있다가, close 이후 삭제된 모습이다. 하지만 netstat -tonp 명령어를 보면 10223 포트의 소켓은 time waitg하는 상태이다. 커널로 넘어간 것인가? tcp 상태 = 소켓의 상태 어쩌면 당연한 거 포트의 상태 아니다 포트가 사용되고 있을 뿐이다. netstat -antplFo-&gt; tcp 소켓 정보 모두 출력 10777 포트를 가지는 소켓 3개 존재 한쪽 client가 close를 실 서버에서 accept를 받은 뒤, 먼저 close를 불러 time wait 상태로 보내버림 다만 이후 새로운 연결을 만들 수 있었다. 포트 밴 ? 소켓이 닫히는데 시간이 필요한 것이다. 다른 프로세스가 10888포트를 요구한다면 당연히 에러 생김 다만 같은 프로세스에서 바로 재 연결을 한다면? 클라이언트에서 10888서버에 연결하고 close를 불러 연결을 종료하고, 다시 연결한 상태이다. 기존 소켓이 time wait에 걸려 새로운 포트를 받은 것을 볼 수 있다. " }, { "title": "socket programming in c", "url": "/posts/network_3/", "categories": "CS, network", "tags": "network, tcp, cs", "date": "2023-09-17 20:36:00 +0900", "snippet": "저 수준 파일 입출력과 FD 저 수준 파일 입출력 ANSI 표준 함수가 아닌 OS가 제공하는 함수 기반의 파일 입출력 표준이 아니기에 운영체제 호환성이 없다. 리눅스는 소켓도 파일로 간주한다. 고로 저 수준 파일 입출력 함수로 소켓 기반 데이터 통신 가능 파일 디스크립터 (FD) 열어둔 파일을 구분하기 위한 숫자 저 수준 파일 입출력 함수는 fd를 이용해 파일을 지정함 0, 1, 2는 default로 지정 표준 입력, 표준 출력, 표준 에러 이후 파일이 열릴 때마다 +1 생성 #include &lt;stdio.h&gt;#include &lt;sys/socket.h&gt;#include &lt;stdlib.h&gt;#include&lt;fcntl.h&gt;// socket 1 2 3 default// standard in out error// 파일과 소켓을 동일하게 취급 in linuxint main(){    int fd1, fd2, fd3;    fd1 = socket(PF_INET, SOCK_STREAM, 0);    fd2 = open(\"test.dat\",O_CREAT|O_WRONLY|O_TRUNC);    fd3 = socket(PF_INET, SOCK_DGRAM, 0);    printf(\"%d\", fd1);    printf(\"%d\", fd2);    printf(\"%d\", fd3);     close(fd1);    close(fd2);    close(fd3);}소켓의 생성#include &lt;sys/socket.h&gt;int socket(int domain, int type, int protocol);sock=socket(PF_INET, SOCK_STREAM, 0);// PF_INET -&gt; IPv4 프로토콜\t// protocol family// SOCK_STREAM 연결 지향형 TCP// SOCK_DGRAM 비 연결 지향형 UDP// IPPROTO_TCP or UDP -&gt; 굳이 지정 안해도 앞의 정보로 결정됨 고로 0보냄 소켓을 생성함 성공 시 fd, 실패 시 -1 domain : 프로토콜 체계(protocol family) 정보 PF_INET : IPv4 PF_INET6 : IPv6 등등 type : 데이터 전송 방식 IPv4는 두 가지 방식 존재 SOCK_STREAM // tcp 데이터 소멸이 안되는 것처럼 만듬 받을 때 순서 섞이나 순서대로 올려줌 데이터 경계 존재하지 않는다. 소켓은 1대 1의 구조 ( 지금은 이렇게 배움 ) SOCK_DGRAM // udp 데이터 손실 및 파손의 우려가 있다. 데이터의 경계가 존재한다. protocol : 통신에 이용되는 프로토콜 정보 전달 이미 위의 정보를 통해 정해짐 그래서 그냥 0으로 던짐 tcp, udp 써주는 거임 sockaddr_in으로 주소 전달하기// 해당 주소의 서버로 연결if(connect(sock, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr))==-1)        error_handling(\"connect() error!\");        // 특정 ip 와 port로 들어오는 정보는 나에게 보내라if(bind(serv_sock, (struct sockaddr*) &amp;serv_addr, sizeof(serv_addr))==-1 )\terror_handling(\"bind() error\"); 두 함수 모두 sockaddr_in 이용함 이는 IPv4 전용으로 범용적인 sockaddr로 형변환해서 사용 struct sockaddr_in{    sa_family_t sin_family; // 주소 체계    uint16_t sin_port; // 포트 주소    struct in_addr     {        in_addr_t s_addr; // in_addr_t = uint32_t    } sin_addr; // 32비트 IP주소    char sin_zero[8]; // 형변환을 위한 값};struct sockaddr{    sa_family_t sin_family; // 주소 체계 (Adress Family)    char        sa_data[14]; // 주소 정보};    memset(&amp;serv_addr, 0, sizeof(serv_addr));    serv_addr.sin_family=AF_INET; // address family    // AF_INET, AF_INET | IPv4, 6    // AF_LOCAL | 로컬 통신을 위한 unix 주소체계        serv_addr.sin_addr.s_addr=inet_addr(argv[1]);    // 32bit IP 주소    // 네트워크 바이트 순서로 저장 / Big endian    // sin_addr는 구조체 자료형 in_addr, 사실상 u32비트 정수    // struct in_addr    // {    //  in_addr_t s_addr; // in_addr_t = uint32_t    // };    // inet_addr은 \"211.214.142.09\" 같이 10진수로 표현된 문자열을 u32비트 정수형으로 반환        // in_addr_t inet_addr(const char* string);    // int inet_aton(const char* string, struct in_addr* addr)    // inet_addr과 동일, 다만 구조체에 저장해줌 그리고 성공 결과(t f) 반환      // inet_aton(addr, &amp;addr_inet.sin_addr)        // char* inet_ntoa(struct in_addr adr); 반대로 정수형으로 주소를 보여줌        serv_addr.sin_port=htons(atoi(argv[2]));    // uint16_t , 16비트 포트 번호 저장    // 네트워크 바이트로 저장해야함 -&gt; htons(host to networks) 이용    // hostns는 바이트 변환 함수이다. s는 short를 의미, l(long)도 있다.        // sin_zero는 sockadd_in 을 sockaddr로 바꾸기 위한 패딩으로 이용됨    // 반드시 0으로 초기화    // sockadd_in은 ipv4만을 위함    // sockadd는 다양한 주소체계의 주소 정보를 담게 정의됨    // 클라이언트는 연결할 서버의 정보를 저장    if(connect(sock, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr))==-1)        error_handling(\"connect() error!\");    str_len=read(sock, message, sizeof(message)-1); // fd, void*buf, 수신할 최대 바이트 수    if(str_len==-1) // 읽은 바이트수 반환, 파일의 끝 = 0 , 실패 시 -1        error_handling(\"read() error!\");    printf(\"Message from server: %s \\n\", message);      close(sock);    return 0;}serv_addr.sin_addr.s_addr=htonl(INADDR_ANY);// any는 모든 ip를 의미한다. 127.0.0.1 or 213.133.412.13// 현재 실행중인 pc의 ip// 127.0.0.1 루프백 주소// 내려온 패킷을 받은 것 처럼 다시 올려줌 서버는 ip주소를 적을 때 INADDR_ANY 이용한다.빅엔디안, 리틀엔디안 네트워크 통신은 빅엔디안이 기준이다. 높은 주소로 마지막 바이트가 저장된다. 즉 주소에 바이트가 순서대로 저장된다. 인텔은 리틀엔디안을 이용한다. 고로 ip, port 주소를 적어주려면 체계를 바꿔야 한다. inet_addr 문자열로 전달된 ip 주소를 32비트로 변환해준다. 네트워크 기준인 빅엔디안으로 바꾸어 반환한다.#include &lt;arpa/inet.h&gt;#include &lt;stdio.h&gt;int main(){    char*addr1=\"1.2.3.4\";    char*addr2 = \"1.2.3.256\"; // 256이라서 에러    unsigned long conv_addr = inet_addr(addr1);    if(conv_addr==INADDR_NONE){        printf(\"Error occured!\\n\");    }    else{        printf(\"%#lx\\n\", conv_addr);    }    conv_addr = inet_addr(addr2);    if(conv_addr==INADDR_NONE){        printf(\"Error occured!\\n\");    }    else{        printf(\"%#lx\\n\", conv_addr);    }\tstruct sockaddr_in addr;    addr.sin_addr.s_addr = inet_addr(addr1); // 구조체를 받음    printf(\"%s\", inet_ntoa(addr.sin_addr)); // 역변환 } 역순으로 출력되는 이유는 인텔에서 돌려서 그렇다. 리틀엔디안으로 저장된 것을 보기 좋게 출력해주는데, 빅엔디안으로 저장되어 뒤집혀 보이는 것이다. 즉 출력 시 역순으로 읽어서 보여주는 것 (인텔은 리틀 엔디안이 기준이니까) htons host to network short 호스트의 바이트 순서를 네트워크 기준으로 바꿔줌 ntohs도 존재 #include &lt;arpa/inet.h&gt;#include &lt;stdio.h&gt;int main(){    unsigned short host_port = 0x1234;    unsigned short net_port;    unsigned long host_addr = 0x12345678;    unsigned long net_addr;        net_port = htons(host_port);    net_addr = htonl(host_addr);        printf(\"host_port : %#x\\n\", host_port);    printf(\"host_addr : %#lx\\n\", host_addr);    printf(\"net_port : %#x\\n\", net_port);    printf(\"net_addr : %#lx\\n\", net_addr);}" }, { "title": "Protocol Buffers install", "url": "/posts/protobuf/", "categories": "CS, Distributed_Systems", "tags": "Distributed_Systems, Go", "date": "2023-09-09 23:50:00 +0900", "snippet": "프로토콜 버퍼 분산 서비스는 네트워크로 통신한다. 이때 구조체 같은 데이터를 전송하기 쉽게 인코딩한다. 보통 JSON을 사용한다. public API, 클라이언트 통제 불가능한 경우 사람이 읽기도 좋고 파싱하기도 좋다. 다만 빠르고 기능도 많고 버그 적은 인코딩 방식이 있다. 프로토콜 버퍼이다. 구글에서 만든 protobuf는 언어 독립적이다. 장점 자료형 안정성 보장 ( type safety ) 스키마 위반 방지 빠른 직렬화 하위 호환성 제공 gRPC에 사용됨 ????.proto 라는 파일을 만들고 원하는 언어로 컴파일해서 사용한다. 다음의 사진처럼 만든다. 왜 쓰냐? 일관된 스키마 protobuf로 스키마를 인코딩하고 전체 서비스에서 사용하면 일관성을 가져갈 수 있다. 전체 서비스가 protobuf에 의존하게 만듬 -&gt; 일관성 golang의 자료 검사를 통한 일관성 문제 체크 가능 버전 관리 제거 message의 필드마다 번호가 붙는다. 이는 변경이나 업데이트 시 하위 호환성 관리 목적으로 사용된다. 파싱하고 전달하는 중간 서버는 모든 필드를 알 필요가 없다. ( ? ) reserved라고 사용하지 않는 필드에 표시하면 컴파일할 때 해당 필드를 사용하는 코드가 있는지 체크한다. 보일러플레이트 코드 컴파일된 protobuf 라이브러리는 인코딩 디코딩 메서드가 만들어져 있다! 확장성 자신만의 컴파일 로직으로 컴파일 가능하다. 여러 구조체가 공통의 method 가지게 만들도록 시킬 수 있다. 언어 불가지론 언어를 바꿔도 컴파일만 해주면 된다. 서로 다른 언어를 사용해도 별도의 작업 필요 없다. 성능 고성능, 페이로드 적다. 직렬화 속도 6배 빠름 protoc 컴파일러 설치 wsl에서 진행하고 있다. 우선 빌드 된 파일을 받고 unzip한다.wget https://github.com/protocolbuffers/protobuf/releases/download/v24.3/protoc-24.3-linux-x86_64.zipunzip protoc~~.zip -d ~/.local/protobufrm ./protoc~~.zip 환경 변수에 추가해준다. ~/.bashrc 마지막에 적어주자. PATH=$PATH:$HOME/.local/protobuf/bin 체크해준다.프로토콜 버퍼로 자료형 정의하기 log.proto 파일을 만들고 다음과 같이 쓴다.//go 언어가 아니다.syntax = \"proto3\"; // 최신 버전 proto3 사용한다 명시 package log.v1; // 패키지명을 통해 메시지 자료형의 충돌을 막아줌option go_package = \"./github.com/highcloud100/api/log_v1\"; // golang의 패키지명으로 사용 // 만약 이를 안쓰면 위의 package명이 사용됨// 책과는 다르게 ./ 을 붙여주어야 한다. 아래 참고message Record{    bytes value = 1; // 자료형 이름 고유 필드 번호    uint64 offset = 2;}// 필드는 바꿀 수 없고, 이전 필드의 사용을 멈추고 새로운 필드를 사용하자.// 필드 번호는 고유값으로 직렬화시 ID로 사용된다.// 호환성을 깨려면 디렉토리 v2를 만들어 메이저 버전을 바꾸자 책과는 다르게 패키지명에 ./ 을 붙여주어야 한다. https://stackoverflow.com/questions/70586511/protoc-gen-go-unable-to-determine-go-import-path-for-simple-proto 컴파일하기 protobuf를 컴파일하려면 해당 언어의 런타임이 필요하다. protoc-gen-go는 go언어를 만들어주는 컴파일러의 플러그인이다.go install google.golang.org/protobuf/...@v1.27.1 go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28 이후 make 파일을 만들어준다.compile:    protoc  api/v1/*.proto \\        --proto_path=. \\        --go_out=. \\        --go_opt=paths=source_relativetest:    go test -race ./... 다음과 같은 결과가 나온다." }, { "title": "XV6 OS Overview", "url": "/posts/XV6_OS_Overview/", "categories": "mit6.1810, xv6", "tags": "os, xv6", "date": "2023-08-29 22:42:00 +0900", "snippet": "https://pdos.csail.mit.edu/6.828/2022/lec/l-overview.txtOverview O/S 디자인과 구현에 대한 이해를 목표함OS의 목적이 무엇인가? 하드웨어를 추상화하여 편리하고 이식성있게 만듬 여러 어플리케이션간 하드웨어 다중화 버그 가질 수도 있는 어플리케이션을 고립시킴 보안을 위한 제어 공유 어플리케이션간 공유 허용 여러 어플 지원OS 커널이 일반적으로 제공하는 것들 프로세스 메모리 할당 파일 , 디렉토리 접근 권한 ( 보안 ) IPC, network, time, terminals …App과 커널 간 인터페이스는 무엇인가? 시스템 콜 fd = open(\"out\", 1);write(fd, \"hello\\n\", 6);pid = fork(); OS 디자인과 구현이 어렵고 흥미로운 이유? 여러 등가 교환이 있다. 효율 vs 추상화/이식성/범용성 Powerful vs 간단한 인터페이스 유연성 vs 보안 기능 간 상호 작용 여러 곳에서 사용Introduction to UNIX system calls App은 시스템 콜을 통해 OS와 연결된다. 첫번째 과제에서 쓰게됨 xv6에서 예제를 보여주겠다. xv6는 간단한 UNIX 시스템과 비슷한 구조를 가지고 있다. 간단하여 대부분 책에 설명이 되어있다. 왜 UNIX인가? 오픈소스다. 문서화 잘되어있다. 깔끔한 디자인과 널리 사용되고 있다. xv6는 RISC-V 에서 돌아간다. Ex) copy.c : copy input to output// copy.c: copy input to output.#include \"kernel/types.h\"#include \"user/user.h\"intmain(){ char buf[64]; while(1){ int n = read(0, buf, sizeof(buf)); if(n &lt;= 0) break; write(1, buf, n); } exit(0);} input에서 바이트를 읽어 output에 쓴다. read( ) , write( )는 시스템 콜이다. 두 함수의 첫 인자는 FD (file descriptor)이다. 커널은 FD로 어떤 열린 파일에 쓸지 판단함 read, write는 열린 파일에만 가능하다. FD는 파일/디바이스/소켓 등에 연결됨 UNIX 컨벤션 0 : standard input 1 : standard output Read의 두 번째 인자는 포인터이다. 읽을 메모리의 위치 세번째 인자는 읽을 크기이다. 반환 값은 읽은 크기 or -1 (for error) FD는 어디서 온 것인가?Ex) open.c : create a file// open.c: create a file, write to it.#include \"kernel/types.h\"#include \"user/user.h\"#include \"kernel/fcntl.h\"intmain(){ int fd = open(\"out\", O_WRONLY | O_CREATE | O_TRUNC); write(fd, \"ooo\\n\", 4); exit(0);} open( )은 파일을 만들고 FD를 반환한다. FD는 작은 숫자이다. FD는 프로세스별 테이블에 인덱싱되어 있다. 이는 커널이 관리한다. 즉 다른 프로세스는 다른 FD name-spaces를 가진다.open( ) 같은 시스템 콜을 부르면 무슨 일이 벌어지나요? 함수 콜로 보이지만 사실 특별한 명령이다. 하드웨어는 사용자 레지스터 값들을 저장한다. 하드웨어는 접근 권한을 높인다. 하드웨어는 예약된 entry point 로 점프한다. ( 커널 안에 있음 ) 커널 안에서 C code가 돌아가는 상태가 됨. 커널은 시스템 콜의 구현을 부른다. sys_open( )은 파일 시스템의 이름을 살펴본다. disk 기다림 커널의 자료구조 수정 ( 파일 블럭 캐시, FD table ) 유저 레지스터를 복구한다. 접근 권한을 낮춘다. 프로그램의 calling point로 돌아가 재개한다.shell command line interface이다. shell은 “$”를 프린트한다. shell은 UNIX command-line Utilities를 돌리게 해준다. ls, ls &gt; out, grep x &lt; out … Ex) fork.c : create a new process shell은 새로운 프로세스를 사용자가 타이핑한 명령마다 만든다. fork( ) 시스템콜이 프로세스를 만든다. 커널은 프로세스의 복제본을 만든다. 명령어, 데이터, 레지스터, FD, 현재 디렉토리,,, 유일하게 다른 것은 fork가 반환하는 값이다. pid 는 부모에게 0 은 자식에게 즉 프로세스가 복제되고 fork 시점에서 두 프로세스 모두 실행됨 Ex) exec.c : replace calling process with an executable file$ echo a b c shell은 어떻게 프로그램을 돌리나? 프로그램은 파일에 저장되어 있다. 링커와 컴파일러에 의해 만들어짐 echo라 불리는 파일이 저장되어 있음 exec( )은 현재 프로세스를 실행 가능한 파일로 교체함 기존 명령과 메모리를 버리고 새로운 명령과 메모리를 file로부터 읽어옴 다만 FD는 유지된다. exec ( filename, argument array ) Ex) forkexec.c : fork() a new process, exec() a program #include \"kernel/types.h\"#include \"user/user.h\"// forkexec.c: fork then execintmain(){ int pid, status; pid = fork(); if(pid == 0){ char *argv[] = { \"echo\", \"THIS\", \"IS\", \"ECHO\", 0 }; exec(\"echo\", argv); printf(\"exec failed!\\n\"); exit(1); } else { printf(\"parent waiting\\n\"); wait(&amp;status); printf(\"the child exited with status %d\\n\", status); } exit(0);} fork는 복사하고 exec은 복사된 메모리를 날린다. 이는 새로운 프로그램을 돌리는 방법이지만 낭비가 심하다. copy-on-write lab에서 해결할 것이다. Ex) redirect.c : redirect the output of a command$echo hello &gt; out shell은 위 명령에 대해 무슨 행동을 할까? fork , 자식의 FD 1을 바꾼다. exec echo open( )은 항상 사용되지 않은 가장 낮은 FD를 사용한다. fork와 exec의 분리는 exec 직전에 자식의 FD를 바꿀 수 있게 만들어준다. exec은 FD를 유지한다. 명령어는 단순히 FD 0과 1을 사용할 뿐, 무엇이 0과 1에 연결되었는지 상관 안 쓴다. 고로 shell은 프로그램에 대해 신경 쓸 필요 없이 I/O redirection이 가능하다.Ex) pipe1.c : communicate through a pipe// pipe1.c: communication over a pipe#include \"kernel/types.h\"#include \"user/user.h\"intmain(){ int fds[2]; char buf[100]; int n; // create a pipe, with two FDs in fds[0], fds[1]. pipe(fds); write(fds[1], \"this is pipe1\\n\", 14); n = read(fds[0], buf, sizeof(buf)); write(1, buf, n); exit(0);} 그렇다면 위의 redirect 명령을 어떻게 구현했을까? pipe( )를 이용한다. pipe 시스템 콜은 두개의 FD를 만든다. 첫번째 - 읽기전용 두번째 - 쓰기전용 커널은 각 파이프들을 위한 버퍼를 유지한다. Ex) pipe2.c : communicate between processes#include \"kernel/types.h\"#include \"user/user.h\"// pipe2.c: communication between two processesintmain(){ int n, pid; int fds[2]; char buf[100]; // create a pipe, with two FDs in fds[0], fds[1]. pipe(fds); pid = fork(); if (pid == 0) { write(fds[1], \"this is pipe2\\n\", 14); } else { n = read(fds[0], buf, sizeof(buf)); write(1, buf, n); } exit(0);}$ ls | grep x pipe는 fork와 함께 이용된다. shell은 pipe를 만들고 fork한다. ls의 FD 1번을 pipe의 write로 연결한다. grep의 FD 0번을 pipe의 read로 바꾼다. 위의 코드는 standard input, output을 바꾸지 않는 간단한 코드이다. standard i/o를 바꾸면 프로그램의 수정 없이 redirect 가능하다. " }, { "title": "Chain_replication", "url": "/posts/chain_replication/", "categories": "mit6.5840, Distributed_Systems", "tags": "chain_replication, Distributed_Systems", "date": "2023-08-28 16:01:12 +0900", "snippet": "Chain Replication for Supporting High Throughput and Availabilityhttps://pdos.csail.mit.edu/6.824/papers/cr-osdi04.pdf1. Intro One challenge when building a large scale storage service is maintaining “high availability” and “high throughput” despite failures and concomitant changes to the storage service’s configuration Consistency guarantees also can be crucial but … large-scale storage service are not incompatible with high throughput and availability. ex) GFS declined to support strong consistency \\[\\text{Strong consistency} \\propto {1 \\over \\text{System throughput or availability}}\\] new chain replication coordinating fail-stop servers simultaneously supports high throughput, availability, and strong consistency. 2. Storage service interface T1 : pending T2 : ignore T3 : processing $\\text{Hist}_{objID}$ : updates that have been performed on objID $\\text{Pending}_{objID}$ : a set of unprocessed requests3. Chain Replication Protocol Server assumed to be fail-stop each server halts in response to a failure rather than making erroneous state transitions. 잘못된 상태가 아닌 실패에 대한 응답으로 정지함 server’s halted state can be detected by the environment. With an object replicated on t servers, as many as t - 1 of the servers can fail without compromising the object’s availability So we assume that at most t - 1 of the servers replicating an object fail concurrently Server composition Reply Generation : All replies are generated and sent by the TAIL Query Processing : Each query request is directed to the TAIL, processed atomically Update Processing : Each update req is directed to the HEAD, processed atomically and forwarded along a reliable FIFO link to next server.3.1 Protocol Details When chain replication is used to implement the Figure 1 $\\text{Hist}{objID} \\rightarrow \\text{Hist}^{T}{objID}$ the value of $\\text{Hist}$ stored by tail T $\\text{Pending}_{objID}$ is set of client requests recieved by any server in the chain not yet processed by the taill $T1 = \\text{ (i) Server in the chain receiving a req from a client}$ $T3 = \\text{ (ii) Tail processing a client request}$ storage interface의 no-op, T1, 2, 3이 체인의 작동과 일치함을 보여 체인이 interface의 사양을 충족하는지 보임 두 $\\text{i, ii}$ 만이 $\\text{Hist, Pending}$에 영향을 미친다. 나머지 작동은 no-op와 동일 Coping with Server Failures master server detects failures of servers informs each server in the chain of ist new predecessor or new successor when the chain obatained by deleting the failed server. informs clients which server is the head and tail we assume master is single process and that never fail In practical replicates a master process Update Propagation Invariant\\(\\text{Hist}^j_{objID} \\le \\text{Hist}^i_{objID}\\) for server labeled i and j such that $i &lt;= j$ i is a predecessor of j in the chain $\\text{Hist}^j_{objID}$ is prefix of $\\text{Hist}^i_{objID}$ \t- Failure of the Head Master removing H from the chain and making the successor to H the new head of the chain. Deleting server H from the chain has the effect of removing from Pending objID those requests received by H but not yet forwarded to a successor. is consistent with transition T2 Failure of the Tail remove tail T from the chain and making predecessor T− of T the new tail of the chain. consistent with repeated T3 transitions Peding decreases and Hist is increased commited 기준은 tail이다. T- 는 Hist가 더 크기에 증가 된다. Failure of Othre servers Update Propagation Invariant is preserved $\\text{Sent}_i$ : update requests that i has forwarded to some successor but that might not have been processed by the tail Whenever server i forwards an update request r to its successor, server i also appends r to $\\text{Sent}_i$ The tail sends an acknowledgement ack(r) to its predecessor when it completes the processing of update request r. And upon receipt ack(r), a server i deletes r from $\\text{Sent}_i$ and forwards ack(r) to its predecessor.Improcess Requests Invariant\\(\\text{Hist}^i_{objID} = \\text{Hist}^j_{objID} \\oplus \\text{Sent}_i\\) Thus, the Update Propagation Invariant will be maintainedLecture notechain (or p/b) versus Raft/Paxos/Zab (quorum)? p/b can tolerate N-1 of N failures, quorum only N/2 p/b simpler, maybe faster than quorum p/b requires separate CFG, quorum self-contained p/b must wait for reconfig after failure, quorum keeps going p/b slow if even one server slow, quorum tolerates temporary slow minority p/b CFG’s server failure detector hard to tune: any failed server stalls p/b, so want to declare failed quickly! but over-eager failure detector will waste time copying data to new server. quorum system handles short / unclear failures more gracefullyfor a long time p/b (and chain) dominated data replication Paxos was viewed as too complex and slow for high-performance DBs recently quorum systems have been gaining ground due to good toleration of temporarily slow/flaky replicaswhat if you have too much data to fit on a single replica group? e.g. millions of objects you need to “shard” across many “replica groups”conclusion Chain Replication is one of the clearest descriptions of a ROWA scheme it does a good job of balancing work it has a simple approach to re-syncing replicas after a failure influential: used in EBS, Ceph, Parameter Server, COPS, FAWN. it’s one of a number of designs (p/b, quorums) with different properties" }, { "title": "Computer System Overview2", "url": "/posts/overview2/", "categories": "CS, CSE3206_OS", "tags": "os", "date": "2023-04-09 09:07:23 +0900", "snippet": "Computer’s Memory데이터와 프로그램을 저장함디자인 제한 capacity cost(per bit) access time 좋은 성능을 위해 프로세서와 속도가 비슷해야한다. 두가지 메모리 SRAM 쟉고, 비쌈, 하지만 빠름 DRAM 크고, 쌈, 하지만 느림 특징에 맞게 계층 구조로 사용한다.메모리 계층 빠른 것과 느린 것이 같이 일하면, 느린 속도에 크게 영향을 받는다. cpu를 최상위 계층으로 두고, 속도가 비슷한 순서대로 하위 계층을 구성한다. 가격과 크기 문제로 계층 구조를 가지게 된다. 크기가 커지면 빠르게 하드웨어를 만들기 쉽지 않다. 설계 의도는 최대한 하위 계층에서 메모리를 접근하지 않게 만드는 것이다. 다른 말로 최대한 상위 계층에서 작업을 하는 것이다. 전략상위 계층에서 일을 하려면 자주 접근되는 데이터가 상위 메모리에 존재해야한다. 이를 완벽히 예측하기 힘들지만 지역성을 이용하면 어느정도 가능하다.Localtiy프로그램은 최근 접근한 데이터를 다시 접근하거나, 근처 데이터를 접근하는 경향이 있다. 이를 두가지 타입의 지역성으로 정의할 수 있다. Temporal locality ( time ) 했던거 또 ( 반복문에서 i 같은거 ) Spatial locality ( space ) 했던거 근처 ( 배열 ) Cache Memory 빠른 sram에 지역성을 이용해 미리 데이터를 가져다 두자!전략 Spatial locality 큰 캐시 블록과 prefetching을 이용하자. 근처 데이터 접근시 hit 증가 Temporal locality 이전에 사용한 명령어를 캐시에 최대한 가지고 있는다. replace 문제 고려 Design Impact of associativity 유연하다. 블럭을 여러 군데 저장할 수 있다. 이로 인해 hit rate 증가 가능 복잡한 회로 구조가 필요하다. 여러 블럭 중 무엇을 교체할지나 서칭할때 이는 시간과 가격 증가로 이어짐 Impact of cache size 커지면 hit rate 증가 커지면 빠르게 만들기 쉽지 않다. 트레이드 오프 Impact of block size 처음에는 증가하나 항상 좋은 퍼포먼스를 보여주지 않는다. Cache write operation cache hit 했을 때 write-through 메모리에 써버림 write-back dirty bit를 이용해서 캐시에만 쓰고, 이후 replace될 때 메모리에 반영 반영 전까지 메모리는 obsolete 상태로 남음 멀티 프로세서간 동기화 문제로 문제 발생 cache miss 했을 때 write-allocate 캐시에 가져오고 업데이트 no-write-allocate 메모리에 써버리고 캐시 업데이트 안함 I/O device OverviewI/O 컨트롤러는 I/O 디바이스의 인터페이스 역할을 한다.컨트롤러는 3가지 버스의 주소를 가지고 있다. 각 버스는 상응하는 컨트롤러의 레지스터에 연결되어 있다. address bus data bus control bus status reg : 디바이스의 상태를 읽을 수 있다. command reg : 디바이스에 일을 부여한다. data reg : 디바이스에 데이터를 전달하거나 가져온다.I/O address space port-mapped I/O I/O 디바이스가 분리된 주소 공간을 가지고 있음 전용 명령어를 사용 x86 / in out memory-mapped I/O 메모리와 같은 주소 공간을 사용 실제 메모리 공간을 사용함 기존 명령어를 이용 가능 I/O Communication Techniques Programmed I/O 프로세서가 I/O 요청 이후 I/O 모듈의 상태를 계속 확인한다. I/O 모듈이 완료되면 프로세서는 작업을 한다. Interrupt-driven I/O I/O 모듈이 완료되면 인터럽트를 발생 시킨다. Direct Memory Access 위 작업들은 워드 단위로 큰 데이터를 이동하기에 오버헤드가 크다. I/O 디바이스와 메모리가 DMA를 이용해 직접 데이터를 주고 받는다. 이때 명령과 완료 처리 이외에 cpu 간섭은 필요하지 않다. Sysmmetric Multiprocessors 대칭적 멀티 프로세서 비슷한 프로세서들이 대등하게 존재 메인 메모리와 I/O 자원을 공유한다. 버스를 통해 Advanced PIC APIC은 cpu를 고른다. 인터럽트 시그널을 해당 cpu의 local APIC에 전달한다.큰 APIC과 프로세서마다 local APIC을 가지는 구조로 설계" }, { "title": "Scheduling1", "url": "/posts/scheduling1/", "categories": "CS, CSE3206_OS", "tags": "os", "date": "2023-04-06 18:46:00 +0900", "snippet": "Term w : 실행을 기다린 시간 s : 실행 완료까지 필요한 cpu 시간 e : 지금까지 cpu 사용한 시간FIFO / first in first out Selection funciton max[w] Decision mode Non preemptive 작업이 끝나거나, I/O 요청시 다음 프로세서 실행먼저 큐에 온 순서대로 실행한다. 장점 간단하다. 오버헤드가 없다.단점 convoy 효과가 있다. 긴 job이 앞에 오면 짧은 job이 반환 시간이 긴 job에 영향을 받는다. 프로세서를 많이 사용하는 job이 유리하다. I/O를 자주 사용하는 잡은 뒤로 밀리게된다. I/O utilization에 좋지 않다. SPN / Shortest Process Next Selection function min[s] Decision mode Non preemptive 짧은 job이 먼저 수행된다면 반환시간을 줄일 수 있다. 도착시간이 같을 때 SPN은 최적이다.장점 개선된 반환시간 convoy 완화 그러나 긴 job이 수행 중일때 짧은 job이 오면 convoy again 단점 starvation 긴 job이 영원히 실행 안될 수 있다. 실행시간을 예측하기란 쉽지 않다. 누적 평균을 이용해 이전 데이터를 가지고 예측한다. SRT / Shortest Remaining Time Selection function min[s-e] Decision mode Preemptive 새로운 job이 도착하면 선점 판단 필요한 수행 시간에서 실행한 시간을 빼 기준으로 사용한다.장점 반환시간이 spn보다 좋다. 기존에는 도착시간이 같을때 최적이었지만, 이제는 달라도 된다. 단점 선점으로 인한 오버헤드 switch 빈번 starvation 긴 job이 손해를 본다. 실행 시간 예측 어려움 HRRN / Highest Response Ration Next Selection function min[(w+s) / s] Decision mode Non preemptive 기아 현상을 해결해보자!오래 대기한 프로세서들 보상하기 위한 기준 w가 크면 우선시 s가 작으면 우선시 경쟁하게됨 장점 긴 job들도 짧은 job들과 경쟁해서 수행 가능단점 수행 시간 예측 어떻게 할건데? 긴 job이 먼저 사용하고 있으면 convoy againRound-Robin Selection function contant / fifo Decision mode preemptive 주어진 시간을 다 사용하면 다음 프로세스를 실행 반응시간을 짧게하기 위해서기존 FIFO에서 짧은 job에게 어드밴티지를 주기위해서 타임 슬라이스가 커지면 반응 시간은 작아진다. 반환 시간은 늘어진다.각 프로세스는 (n-1)*q 초과의 시간을 기다리지 않는다. q : time slice오버헤드 무시장점 짧은 반응 시간 starvation x I/O utilization I/O가 쉬지 않게 바로 굴려줄 수 있다. 단점 cpu bound 된 job은 시간을 다 사용하나 I/O bound된 job은 시간을 다 못씀 반환 시간이 느려진다.타임 슬라이스의 선택 최소 interaction 시간보다는 충분해야 한다. 하나의 interaction을 두 번에 나누면 현저히 느려진다. 오버헤드를 고려해야 한다. 스왑 시간보다는 길어야한다. 긴 작업은 긴 시간 슬라이스가 유리하고 짧은 작업은 작은 슬라이스가 유리하다.VRR / virtual Round RobinI/O 작업을 하는 프로세스들에게 어드밴티지를 준다. 타임슬라이스를 다 사용하지 못한 프로세스는 임시 큐로 이동한다. 임시 큐에 있는 프로세스가 먼저 실행된다. 이때 남은 시간씩만 수행 가능하다.Multi-Level Feedback Queues 큐가 여러개 존재한다. 타임 슬라이스를 다 사용하면 낮은 단계의 큐로 강등당한다. 높은 단계의 큐에는 짧은 작업이 남게된다. 높은 큐부터 수행해주며 큐가 비면 다음 단계의 큐를 수행시킨다. 큐가 내려갈 수록 타임 슬라이스가 보통 2배가 된다. 긴 job은 기아 현상을 겪는다. 이를 위해 일정 시간마다 위 큐로 승급시켜준다. " }, { "title": "Process Description and Control 2", "url": "/posts/ProcessAndControl2/", "categories": "CS, CSE3206_OS", "tags": "os", "date": "2023-04-04 22:25:00 +0900", "snippet": "Process Description and Control 21. Modes of Execution 2개의 모드를 지원한다. mode bit 이용 일부 명령어들은 커널에서만 실행가능하다. 인터럽트 관리 I/O 명령 메모리 관리 / page table, TLB load mode bit 변경 2. Mode switch유저모드와 커널모드간 변경을 이야기한다. 프로세스의 상태 변경 없이 수행한다. context를 저장하고 복구하는데 오버헤드가 있다. 커널 스택에 저장 system call, exception, interrupt 가 발생시 커널 모드로 변경된다.Mode of Execution system call이나 exception 실행 커널이 프로세스 대신하여 실행중이다. process context에 존재한다. interrupt handler 실행 프로세스와 관련이 없다. 즉 방해하는 것이다. 빠르고 간단하게 수행되어야 한다. 커널이 interrupt context에 존재한다. sleep 하면 안된다. 복잡해진다. in_interrupt() 함수로 인터럽트 컨텍스트에 있는지 확인가능 정리하면 프로세서는 3가지 중 하나를 하고 있다. 유저 공간에서 유저 코드 실행 커널 공간에서 프로세스 문맥 대신 실행 커널 공간에서 인터럽트 문맥 실행3. Execution Model of OS기존에는 모든 프로세스 외부에서 커널을 수행했다. 하지만 요즘에는 프로세스 문맥에서 운영체제를 실행한다. 장점 현재 프로세스에서 커널 기능이 수행된다. 프로세스 스위치 없이 모드 스위치하면 된다. Execute all OS function in the context of a current process 프로세스 이미지가 커널의 스택, 데이터, 코드를 포함한다. data, text는 유저 프로세스간 공유된다. 커널 스택이 분리되어 존재한다. 멜트다운과 KPTI에 관해 추가로 알아보자4. Process Switch언제 발생하냐? 인터럽트 이벤트가 완료되어 ready 상태 프로세스를 실행시키거나 우선순위가 높은 프로세스가 선점할때 타이머 인터럽트로 인해 time slice를 모두 사용했을때 예외 문제가 생겼을 때 종료 시킨다. exit state로 전환 시스템 콜 write나 read 같은 I/O 요청 명령으로 blocked 됬을때 어떻게 작동하냐?모드 스위치보다 많은 노력이 필요하다. 현재 프로세서의 문맥을 현재 프로세스 PCB에 저장한다. PCB에 프로세스 상태를 업데이트 한다. ( ready, blocked, exit ) PCB를 적절한 큐로 이동한다. 다른 프로세스를 선택한다. ( schedule ) 선택된 PCB의 프로세스 상태를 running으로 바꾼다. 프로세서 문맥을 선택된 프로세스의 저장된 문맥으로 복구한다.캐시 지역성을 날려버린다.5. 프로세스 생성 (Directed)프로세스 생성 이유 새로운 일괄 처리 작업 대화형 로그온 (?? 아마 터미널로 유저가 실행하는 듯) 서비스 제공을 위해 운영체제가 생성 기존 프로세스가 생성 (모듈화, 병렬성을 위해)생성 방법 새로운 메모리 공간 할당 PCB와 a.out을 위한 공간 코드와 데이터를 메모리로 가져온다. call stack을 만든다. PCB 초기화 새로운 프로세스 실행 프로세스를 ready list에 넣는다. 처음 프로세스를 만들때만 직접 만든다. 이후부터는 clone한다. /sbin/init systemd5.1. 프로세스 생성 (cloning)cloning 부모 프로세스를 완전히 복사한다. 환경변수가 비슷함을 볼 수 있다. (bash -ps) fork를 이용한다. text, data, stack, PCB를 복사 data, stack은 별도로 만듬 text 같이 read only는 공유한다. pid랑 일부 관계 데이터를 수정 새로운 PCB를 ready list에 추가 replacing pid는 유지되나 code, data, heap, stack을 바꿔버림 execve 이용한다.5.2. Copy on Write 초기 부모의 페이지는 자식에게 공유된다. 둘 중 누군가 공유된 페이지를 바꾸면 OS는 copy한다. 더 이상 그 페이지를 공유하지 않는다. 6. Process TerminationVoluntary termination : exit(status) main에서 return 되면 발생 ( 아마 exit 자동호출 ) exit 를 불러서 종료한다. output data가 부모로 간다. (wait 이용) 프로세스의 자원이 해제된다.Involuntary termination 다른 프로세스(부모)나 OS에 의해 수행 kill, abort 특정 시그널 받으면 종료 SIGTERM, SIGINT 왜 죽이냐? 불필요 잘못 실행 논리, 자원, 시스템적인 이유 OS 정책 ex) 부모 죽으면 밑에 자식도 죽이자. 6.1. Zombie 프로세스가 exit으로 종료된 후, 커널은 해당 프로세스의 PCB를 바로 지우지 않는다. 이후 당연히 run은 안됨 reaped 될 때까지 존재 좀비 모드임 Reaping exit status가 부모에게 전달된다. wait(&amp;state) 에서 state에 exit status가 담김 이후 커널은 좀비 자식을 죽인다. 부모가 wait을 이용해 수행한다.실행 옵션 wait을 사용하면 부모는 기본적으로 blocked된다. 안쓰면 동시에 돌아가나 좀비가 남는다. 커널 reaper가 회수하고 다니기도 한다. waitpid(-1, &amp;status, WNOHANG) 같은 옵션을 사용하면 동시에 작업을 하며 주기적으로 reaping할 수 있다.7. Orphan (Unix like OS)고아 자식보다 부모가 먼저 죽음 first process에 입양된다. /sbin/init프로세스 종료 과정 cleanup handlers가 자동으로 call됨 Zombie 상태로 바꾸고 exit status가 커널에 저장됨 프로세스가 잡고있는 시스템 자원을 해제한다. 부모에게 시그널을 보냄 고아 자식들을 부모에게 입양시킨다." }, { "title": "Process Description and Control 1", "url": "/posts/ProcessAndControl1/", "categories": "CS, CSE3206_OS", "tags": "os", "date": "2023-04-04 17:44:54 +0900", "snippet": "Process Description and Control 11. 프로세스란 무엇인가?프로세스의 정의 실행 중인 프로그램 프로세서에 할당되고 실행되는 것 명령어의 실행 흐름과 현재 상태, 관련된 시스템 자원으로 특징되는 활동의 단위2. 프로세스와 프로그램의 차이 “프로그램”은 디스크에 바이너리 형태로 저장된 상태이다. “프로세스”는 활동하는 상태로 이는 실행 흐름이 있다는 뜻이다. 실행 파일이 메모리에 올라왔을 때 프로그램에서 프로세스가 된다. 프로세스는 두가지 중요한 요소가 있다. 코드 코드에 관련된 데이터 Stack 실행 흐름을 만들기 위해 스택이라는 저장 공간이 필요하다. call stack ( stack in OS ) procedure calls를 tracking하거나 parameter를 전달하는데 stack을 사용 프로세서가 call을 하면 return address를 스택에 저장한다. parameters를 스택에 저장해 called procedure에 전달 가능하다. call stack은 stack frames로 구성되어 있다.3. PCB OS에서 가장 중요한 자료구조이다. struct로 구현됨 main purpose interrupt가 발생시 프로세스를 교환하여 실행 가능하게 만든다. 즉 interrupt 이후에도 interrupt가 발생 안한 것 같이 실행된다. 이를 위해 interrupt시 pc나 registers 같은 context data를 PCB에 저장한다. multiple processes와 multiprocessing을 지우너하기 위함이다.Elements of a Process control block Identifiers PID, PPID … Processor State Information 각종 레지스터들 PC, condition codes status information : interrupt enabled flag, execution mode Stack pointer Process Control Information 프로세스 상태 running, ready, blocked … 우선순위, 각종 스케줄 관련 정보 Event 프로세스가 기다리는 이벤트 Memory Management 페이지 테이블 관련한 포인터들 자료구조 다른 프로세스간 연결 리스트 같은 것들 PCB는 모든 OS 모듈에서 읽고 수정할 수 있다. OS는 PCB의 링크드 리스트로 구현된 큐를 이용해 프로세스 관리한다.4. Process Imageos가 프로세스를 컨트롤하고 관리하기 위한 정보들 user level context user program, data, stack 프로그램 요소들 ( text, data …)과 실행시 사용하는 stack system level context PCB os가 프로세스를 관리하기 위해 필요한 정보 프로세스를 실행하기 위해서 프로세스 이미지가 메인 메모리에 반드시 올라와야한다. 프로세스 이미지 user data user program stack PCB 5. 프로세스의 실행 흐름 process switch를 통해 번갈아 실행됨 mode switch가 선행되고 이후 process switch 언제 process switch 발생하는가? timer interrupt system call ( I/O ) Exception 인터럽트가 반드시 process switch를 발생 시키지 않는다.5-1. Two-State Process Model geeksforgeeks time out된 process와 I/O 연산을 기다리는 process가 같은 큐에 저장된다. 대기 큐에 바로 실행 가능한 프로세스와 그렇지 않은 프로세스가 섞여있어 오버헤드가 발생한다. I/O 기다리는 프로세스는 dispatch되고 바로 pause될 것이다. 5-2 Five-State Process Model Not running state를 Ready와 Blocked로 나눔 Blocked에 있는 프로세스들은 event를 받으면 Ready 상태로 이동함 geeksforgeeks Ready: 바로 실행 가능한 프로세스들을 모아둠 New : 아직 실행 풀에 들어가지 못함 ( admit 받으면 입장함) Blocked: 이벤트가 발생할 때까지 기다리는 프로세스 Exit : 종료된 프로세스들큰 OS에서는 Blocked를 이벤트 종류 별로 여러 큐를 만들어 사용하는 것이 효율적이다. ( 이벤트 서칭에서 이득 )5-3 Seven-State Process ModelSwapping 메인메모리의 프로세스를 디스크로 욺겨야 할 상황이 있다. blocked, ready 상태에서 디스크로 옮겨지면 suspend 상태가 된다. chegg" }, { "title": "DRDA", "url": "/posts/DRDA/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-08-17 19:30:00 +0900", "snippet": "DRDAmotor imagery / MI task개인이 주어진 행동을 연습하거나 시뮬하는 정신적 과정이런 의미가 맞는 지?nonstationarity애매하게 알고 있음adversarial learning적대적 기계학습느낌만 알고 있음주변 분포 / 조건부 분포복습 필요state-of-the-art generalization / 최첨단 일반화Generalization in Deep Learning (2019)Quantifying the generalization error in deep learning in terms of data distribution and neural network smoothness (2019)선행 연구들BiDANNfine-tuned a convolutional neural network ( CNN )" }, { "title": "daSPDnet", "url": "/posts/daSPDnet/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-08-14 19:30:00 +0900", "snippet": "daSPDnet선행 연구TCAKPCATSVMTPTADFM적은 수의 딥러닝 논문만 BCI 필드의 DA 문제의 강점을 보임\\key 선행 연구SPD matrix on the Riemannian manifold 관련 17~20MDM / 21번congruence invariance transformation / 18번parallel transport on the SPD manifold / 19, 18 번recentred matrices / equalized the dispersions, rotated geometric mean 20번ker wordprototype learningfeature level, sample level어떻게 나누고 적용했는지marginal distribution divergence주변 분포의 발산geometry-aware algorithmslow-dimensional, high-dimensional 의미?DREAMER데이터 셋" }, { "title": "PPDA", "url": "/posts/PPDA/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-08-13 19:30:00 +0900", "snippet": "PPDAattention bases poolingattention mechanism 방식이랑 관련 있는 건가요?선행 연구 참고?calibration phase어떻게 하는 건지?private 인코더를 비교?DG 와 DA 명확한 차이?user experience사용자가 알고리즘을 사용할 때 느끼는 경험인가요?기존 알고리즘은 calibration time이 너무 long term 이어서 user experience가 구림auto encoder ?아직 공부 못함서론EEG data는 subject에 매우 의존적이다.subject 간의 변동이 크다.이는 모델을 구축하는데 어려움을 가져온다.기존 모델 학습법은 새로운 주제에서 많은 양의 데이터를 수집하고, 레이블을 붙이고 학습을 하는 방법이다.이는 많은 시간 소요와 사용자 경험 저하를 만든다.모델의 실용성이 떨어지게 된다.이런 개인별 차이를 다루기 위해 transfer learning이 도입된다.크게 DA(domain adaptation), DG(domain generalization)로 나눌 수 있다.DA모든 target data 사용으로 인해 비효율적이다.DGtarget subject의 의존하지 않기에 generalization ability에 어려움을 겪는다.short-term calibration stage 가 도입되는 것이 필요하다.before the real-time recognition starts제한된 타겟 트레이닝 데이터에서 좋은 DA 결과를 이끄는 것은 어렵다.제안PPDA는 적은 unlabeled target data를 가지고 조절 가능하다.정확도의 희생 없이EEG 표현을 보편적인 감정 요소와 각 subject의 개인적인 요소로 나눈다.개인적인 요소를 나누기 위해 LSTM Auto-Encoder Neural Net woek와 loss 함수를 사용했다.그 과정에서 감정 인식에 의미 있는 표현을 생성한다.그러나 공유된 감정 공간에서 만들어진 단일 공유 분류기는 새로운 피험자에게 한계가 있다고 생각한다.이에 개별적인 피험자들의 분류기를 추가로 만들었다.이는 새로운 피험자에 대해 레퍼런스를 제공하기 위함이다.소수의 교정 데이터를 이용해 trained shared encoder와 decoder enforced가 적용된 새로운 피험자의 private encoder를 빠르게 구성할 수 있다.즉 개인적인 요소의 유사성을 이용해 기존 individual classifiers의 정보를 가지고 target subjects의 감정 예측을 강화할 수 있다." }, { "title": "Few shot, Transfer, Domain adaptation", "url": "/posts/TransferLearning/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-08-12 19:30:00 +0900", "snippet": "Few shot learningDef여러 해석 중 가장 인정되고 있는 정의를 소개한다.2020년 다음 survey에서 FSL의 디테일한 정의가 언급된다.Yaqing Wang, Quanming Yao, James T Kwok, and Lionel M Ni. Generalizing from a few examples: A survey on few-shot learning. ACM Computing Surveys (CSUR), 53(3):1–34, 2020.어떤 데이터 E를 통해 사용하여 예측 결과를 만들었을 때 E가 매우 작다면 FSL이라 부른다.FSL을 잘 이해하기 위해서는 두 가지 컨셉이 필요하다.N-way-K-shot problemcross-domain FSLN-way-K-shot problemFSL 에서 발생하는 특정 문제를 설명하는데 사용된다.support set 은 학습하는데 사용되는 작은 dataset을 말한다.N은 support set의 카테고리 종류 수이다.K는 support set의 각 카테고리의 샘플 수이다.query set은 모델이 예측할 데이터들을 의미한다.모델은 전체적으로 N * K 개의 샘플을 가지게 된다.N categories and K samples per categoryCross-domain FSLcross-domain originates from transfer learningsource domain에서 target domain으로 knowledge가 transfer 되는 것이때 두 domain에는 차이가 있다.cross-domain FSL은 cross-domain과 FSL을 합친 것이다.최근의 발생한 도전적인 방향이다.Different from Machine learning전통적 ML은 큰 데이터 셋에 의존적이다.적은 샘플로 수행되기 어렵다.반면 FSL은 data scarcity scenario를 처리할 방법을 제공한다.중요한 차이점은 support set과 query set이 disjoint 하다는 것이다.즉 분리되어 있다.기존 ML은 훈련 데이터에 예측할 클래스가 포함되어 있다.unseen task를 마주하면 기존 ML은 큰 데이터를 필요로 하지만 FSL은 적은 훈련 데이터와 자원을 통해 튜닝 가능하다.Different from Transfer Learning만약 다른 task나 domain에서의 사전 훈련을 통해 사전 지식을 얻은 경우 FSL은 전이 학습에 속할 수 있다.즉 전이 학습을 거치고 downstream task 에서 few 데이터를 사용하는 경우다.FSL을 위한 방법으로 Transfer Learning이 사용된다.Different from Meta-Learning특정 작업에서 학습하는 방법을 모델에 가르치기 위해 사전 지식을 사용하는 경우 메타 학습은 FSL의 변종으로 간주 할 수 있다.하지만 메타 학습은 FSL과 동일하지 않다.FSL은 궁극적인 목표로 봐야 한다.Transfer learning특정 태스크를 학습한 모델을 다른 태스크 수행에 재사용하는 방법이다.학습 데이터가 적어도 효과적, 학습 속도도 빠르다.upstream taskpretrain : upstream task를 학습하는 과정downstream task풀어야 하는 구체적인 과제이를 학습하는 방법은 다음과 같다.fine-tuning다운스트림 태스크 데이터 전체 사용모델 전체를 업데이트prompt tuning다운스트림 태스크 데이터 전체 사용다운스트림 데이터에 맞게 모델 일부만 업데이트in-context learning-\t 다운스트림 태스크 데이터 일부 사용-\t모델을 업데이트 하지 않는다.In-context learning 의 3가지 방식zero shot learning다운 스트림 태스크 데이터를 전혀 사용하지 않음one shot learning다운 스트림 태스크 데이터를 1 건만 사용few shot learning다운스트림 태스크 데이터 일부 사용네트워크가 보편적 특징을 학습했기 때문에 전이 학습이 가능하다.논문을 통해 전이학습이 학습 속도에서 효과 있음을 볼 수 있다.Domain adaptationsource, target domain 이 다른 경우 문제가 생긴다.domain shift가 발생한다.이를 해결하기 위한 robust한 모델을 만드는 것한 쪽을 다른 쪽으로 조정하거나 맞추려는 것이 목적이다.가정source domain은 class label이 있다고 가정target domain은 class label이 없어도 됨DANN참고Domain Discriminator가 구별하지 못하게 만듬https://stats.stackexchange.com/questions/260272/what-is-difference-between-transfer-learning-and-domain-adaptationhttps://lhw0772.medium.com/study-da-domain-adaptation-알아보기-기본편-4af4ab63f871" }, { "title": "아두이노 + ESP8266 + MQTT", "url": "/posts/esp8266/", "categories": "Blogging, life", "tags": "HW, arduino, esp8266, rsp, summer", "date": "2022-08-07 20:50:00 +0900", "snippet": "아두이노 + ESP8266 + MQTT 정말 삽질의 연속이었다. 다음을 위해 기록을 해둔다.목적 다음과 같이 아두이노 우노에 esp8266을 연결하여 라즈베리에 깔린 브로커를 통해 통신하는 것이 목적이다. 다음 블로그를 변형해 실행시키는 것이다. https://randomnerdtutorials.com/raspberry-pi-publishing-mqtt-messages-to-esp8266/ 이 블로그는 esp8266 보드를 사용했다. 다만 나는 방법을 바꿔야 했다. 문제점 영 번째로 ESP8266 사용 방법의 문제이다. 첫 번째로 ESP8266 펌웨어 관련 문제들이다. 두 번째로 ESP8266 라이브러리의 문제이다.0. 사용 방법 문제 보통 인터넷의 자료는 ESP8266 모듈을 연결해 사용하는 방법이 아닌 만들어진 보드를 이용하는 글이 대부분이다. 라이브러리나 예제 또한 이를 가정한다. 그래서 esp8266 라이브러리 설치를 찾아보면 보드 매니저 관련 내용이 나오는데 이는 esp8266 에 직접 올려 사용하겠다는 뜻이다. ESP8266은 두 가지 방법으로 사용된다. 모듈을 아두이노에 연결해 시리얼 통신으로 모듈을 제어한다. 보드(모듈)에 직접 프로그램을 올린다. 나는 아두이노 와이파이 실드나 EPS8266 보드가 없었고, ESP8266 01 ( ESP-01 모듈이다. ) 만 있었다. 가격이 저렴했다. 나는 아두이노를 통해 모듈을 제어하는 방식으로 사용해야 했다. 하지만 이런 방식의 문제는 대부분은 이렇게 안 한다는 것이다. 이는 정보의 문제로 이어진다. 라이브러리 찾기도 힘들다. (이는 밑에서 다룬다.) 혼동을 피하기 위해 esp8266 01 모듈 자체를 esp8266이라 부르겠다. 보드( nodeMCU) 같은 거나 esp8266에 직접 올리는 경우는 편하게 할 수 있다. 특히 보드는 펌웨어 관련 문제에서도 편하며 라이브러리도 구하기 쉽다. 1. 펌웨어 및 라이브러리의 문제 우선 ESP8266 관련해 글을 찾아보면 보통 이렇다. 펌웨어 업데이트 AT 실습 나는 위 과정을 진행하는데 문제가 없었다. 다만 직접 AT명령어를 치지 않고, 라이브러리를 이용 방법에서 문제가 생겼다. 정확히는 mqtt 라이브러리 PubSubClient.h 를 사용하는데 문제됨 우선 ESP8266 의 라이브러리는 많다. 정확히는 직접 올려서 돌아가는 라이브러리가 많다. 위에서 언급한 보드 매니저를 통한 방법은 ESP8266에 직접 올릴 때 사용된다. 다만 이 라이브러리를 아두이노에 올리면 당연히 이상하게 돌아간다. ( 경험상 ) 하지만 내가 원하는 아두이노에서 시리얼 통신을 통해 esp8266을 조종하는 라이브러리는 찾기 힘들다. 예제도 딱히 없다. 다음과 같은 라이브러리가 있다. https://github.com/Diaoul/arduino-ESP8266 WiFiEsp 위 두 개의 라이브러리 중 WiFiEsp만 컴파일이 잘 됬다. 위의 라이브러리는 PubSubClient client(esp8266Client); 과정이 문제됬다. 하지만 컴파일 후에도 문제가 생겼다. 펌웨어 에러라는 메시지를 확인할 수 있었고, 명령어를 지원하지 않는 것 같았다. 혹은 Serial.println(“WiFi shield not present”); 가 계속 찍힌다. 코드를 살짝 뒤져보니 AT 보내고 응답을 못하는 것 같았다. 이에 제대로 된 업데이트가 필요하다. https://crystalcube.co.kr/215?category=913820 이 사람의 블로그를 참고하자. 설명이 잘 되어있다. 시리얼 모니터는 아두이노에 코드가 안 올라가도 잘 작동된다. 명령어 주고 받기 된다. 위의 블로그는 보드레이트가 맞춰져 있지 않다. 시리얼 모니터를 열고 밑의 블로그를 따라 명령어로 바꿔주자. AT+UART_DEF=9600,8,1,0,0 https://www.robotstory.co.kr/raspberry/?board_name=raspberry_bbs&amp;search_field=fn_title&amp;search_text=ESP&amp;lang=ko_KR&amp;vid=35 #include &lt;SoftwareSerial.h&gt;#include &lt;WiFiEsp.h&gt; #include &lt;WiFiEspClient.h&gt;#include &lt;WiFiEspUdp.h&gt;#include &lt;PubSubClient.h&gt;#include &lt;stdlib.h&gt;#include &lt;Wire.h&gt;IPAddress server(); //your mqtt server adresschar ssid[] = \"\"; // your network SSID (name)char pass[] = \"\"; // your network passwordint status = WL_IDLE_STATUS; // the Wifi radio's status//HDC1000 mySensor(0x41, 2) &lt;-- DRDYn enabled and connected to Arduino pin 2 (allows for faster measurements).WiFiEspClient esp8266Client;PubSubClient client(esp8266Client);SoftwareSerial esp8266(10, 11); // RX, TX to ESP-01void setup(){ Serial.begin(9600); esp8266.begin(9600); //software serial to ESP8266 WiFi.init(&amp;esp8266); //ESP8266 wifi //HDC1000 sensor // check for the presence of the shield if (WiFi.status() == WL_NO_SHIELD) { Serial.println(\"WiFi shield not present\"); // don't continue while (true); } // attempt to connect to WiFi network while ( status != WL_CONNECTED) { Serial.print(\"Attempting to connect to WPA SSID: \"); Serial.println(ssid); // Connect to WPA/WPA2 network status = WiFi.begin(ssid, pass); } // you're connected now, so print out the data Serial.println(\"You're connected to the network\"); //connect to MQTT server client.setServer(\"\",1883); //client.setCallback(callback);}void loop(){ Serial.print(\"Temperature: \"); Serial.print(\"온도프린트\"); Serial.print(\"C, Humidity: \"); Serial.print(\"습도프린트\"); Serial.println(\"%\"); // mqtt out if (!client.connected()) { Serial.print(\"Attempting MQTT connection...\"); client.connect(\"arduinoClient1\"); Serial.println(\"connected\"); delay (1000); client.publish(\"temperature\",\"온도1\"); delay (1000); client.publish(\"humidity\",\"습도1\"); delay (1000); } Serial.println(\"퍼블리싱중\"); client.publish(\"temperature\",\"1004\"); delay (1000); client.publish(\"humidity\",\"습도2\"); delay (1000); client.loop(); delay(3000);} 이제 위의 예제가 잘 돌아가는 모습을 볼 수 있다. 위의 예제는 아래 블로그를 참고했다. https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=hcheong&amp;logNo=221050736456 2. 트러블 슈팅 우선 선을 확인하자. 귀찮다고 선 대충 연결하면 피본다. 아두이노에 업로드하는 상태나 펌웨어 업데이트 통로로 쓰는 방법이나 다 선 연결이 다르다. 업데이트나 연결 잘 안되면 선 뽑고 다시 꼽자. 진리이다. MQTT 통신 https://randomnerdtutorials.com/raspberry-pi-publishing-mqtt-messages-to-esp8266/ 다음 예제를 따라했다. 잘된다. 이 사진은 라즈베리파이의 flask 서버 로그다. 이 사진은 아두이노 시리얼 모니터다. 설정 잘해야 안 깨진다. " }, { "title": "8월 공부 계획", "url": "/posts/8plan/", "categories": "Blogging, life", "tags": "plan, summer", "date": "2022-07-29 19:20:00 +0900", "snippet": "8월 공부 계획여름 방학이 한 달도 안 남았다os 공부는 멈춰두기로 했다.공부 계획남은 시간baro Ai 마무리baro Ai 실습 / 파이토치 써먹어보기밑바닥부터 만드는 컴퓨팅 시스템선형대수칸아카데미프리드버그" }, { "title": "RNN-1", "url": "/posts/rnn/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-07-28 19:30:00 +0900", "snippet": "딥러닝을 이용한 자연어 처리 입문의 그림을 가져왔다자세한 내용은 위 책을 참고하자.Sequence Modeling목적 : Probability over sequences, x~p(x1, x2, … xT)시계열 데이터 : 시간 순서로 배열된 데이터Feedforward Netyt=φ(Wyhht+by)\\bold{y}_t = \\varphi(\\bold W_{yh}\\bold h_t + \\bold b_y)yt​=φ(Wyh​ht​+by​)ht=φ(Wyhxt+by)\\bold{h}_t = \\varphi(\\bold W_{yh}\\bold x_t + \\bold b_y)ht​=φ(Wyh​xt​+by​)input data 가 들어올 때마다 독립적이다.Vanilla RNNyt=φ(Wyhht+by)\\bold{y}_t = \\varphi(\\bold W_{yh}\\bold h_t + \\bold b_y)yt​=φ(Wyh​ht​+by​)ht=φ(Wyhxt+Whhht−1+by)\\bold{h}_t = \\varphi(\\bold W_{yh}\\bold x_t +\\bold W_{hh}\\bold h_{t-1} + \\bold b_y)ht​=φ(Wyh​xt​+Whh​ht−1​+by​)이전 데이터의 h 값을 반영한다.이를 unfolding computational graph로 나타내면 다음과 같다.은닉층의 노드를 메모리 셀이라 부르기도 한다.이를 그림으로 나타내면 이해가 쉽다.여러 설계 방식용도에 따라 출력과 입력의 길이를 다르게 설계할 수 있다.many to many 에서는 Encoder-Decoder 방식도 있다.Backprop through Time그래디언트가 계산될 때는 각 모델의 output에도 영향을 받지만 그 다음 모델의 영향도 받는다.feed forward 에서는 w 값이 계속 곱해진다.반대로 backpropagation 과정에서는 wT\\bold w^TwT 가 곱해진다problemExploding gradientswhen largest singular value &gt; 1Vanishing gradientswhen largest singular value &lt; 1" }, { "title": "CNN-3", "url": "/posts/cnn3/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-07-26 21:10:00 +0900", "snippet": "Inception NetsGoing deeper with convolutions참고 영상Problem어떤 커널 사이즈를 적절히 선택해야 하나?overfitting 의 문제deeper networks의 문제이다.Solutions다른 사이즈의 커널을 여러 개 사용하자Auxiliary classifiersInception model다음과 같이 Inception 모델을 사용한다.나이브한 버전을 사용하면 계산 비용이 크다.채널의 수가 많으면 배로 늘어남1 x 1 convolutions 를 이용해서 채널을 낮춰 사용한다.풀링 층도 사용한다.성능이 좋았다고 한다.1 x 1로 채널 수를 맞춰준다.Architecture입력으로는 224x224 크기의 RGB 채널을 이용한다.depth는 convolution 층의 개수를 말한다.reduce가 붙은 것은 채널을 낮춘다는 의미이다.처음 Inception(3a)를 보면 output의 채널이 256이다.이는 64 + 128 + 32 + 32 의 합이다.즉 채널을 쌓는 방식이다.그림으로 나타내면 다음과 같다.Inception-V1 ~ V4버전이 많다.Inception-v1 / googLeNetInception-v2 / BN-InceptionInception-v3 / Factorization in convolutionInception-v4 / Inception-v4 + ResNet" }, { "title": "VM application with linux", "url": "/posts/vmAppWithLinux/", "categories": "CS, OS", "tags": "os, cs, summer, 실습과 그림으로 배우는 리눅스 구조", "date": "2022-07-25 19:55:00 +0900", "snippet": "파일 맵 MMF : 메모리 맵 파일이라 부른다. 파일을 다루는 방법 중 하나이다. 프로세스의 가상 메모리 주소 공간에 파일을 매핑하여 사용하는 방법이다. mmap( ) 함수를 특정한 방법으로 호출하면 파일의 내용을 메모리에 읽어, 가상 주소 공간에 매핑 할 수 있다. 입출력을 수행하지 않고, 메모리에 접근하듯 사용한다. 수정한 내용은 이후 저장 장치 내의 파일에 써진다. 실험 프로세스의 메모리 맵의 정보를 출력한다. testfile을 연다 mmap( ) 으로 메모리 공간에 매핑한다. 프로세스의 메모리 맵 정보 표시 매핑된 영역의 데이터를 읽는다. 매핑된 영역의 데이터를 덮어쓴다. 우선 testfile을 만든다.echo hello &gt;testfile 이후 코드를 짠다.#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/mman.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;err.h&gt;#define BUFFER_SIZE 1000#define ALLOC_SIZE (100*1024*1024)static char command[BUFFER_SIZE];static char file_contents[BUFFER_SIZE];static char overwrite_data[] = \"HELLO\";int main(void){ pid_t pid; pid = getpid(); snprintf(command, BUFFER_SIZE, \"cat /proc/%d/maps\", pid); puts(\"*** memory map before mapping file ***\"); fflush(stdout); system(command); int fd; fd = open(\"testfile\", O_RDWR); if (fd == -1) err(EXIT_FAILURE, \"open() failed\"); char * file_contents; file_contents = mmap(NULL, ALLOC_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); if (file_contents == (void *) -1) { warn(\"mmap() failed\"); goto close_file; } puts(\"\"); printf(\"*** succeeded to map file: address = %p; size = 0x%x ***\\n\", file_contents, ALLOC_SIZE); puts(\"\"); puts(\"*** memory map after mapping file ***\"); fflush(stdout); system(command); puts(\"\"); printf(\"*** file contents before overwrite mapped region: %s\", file_contents); memcpy(file_contents, overwrite_data, strlen(overwrite_data)); puts(\"\"); printf(\"*** overwritten mapped region with: %s\\n\", file_contents); if (munmap(file_contents, ALLOC_SIZE) == -1) warn(\"munmap() failed\");close_file: if (close(fd) == -1) warn(\"close() failed\"); exit(EXIT_SUCCESS);} 위의 결과를 확인 할 수 있다. 7f3fe6e55000-7f3fed255000 rw-s 00000000 08:05 8522195 /home/we/projects/os/testfile 줄을 보면 매핑 되었음을 확인 할 수 있다. 덮어 써짐도 확인 가능하다. write, fprintf 함수를 쓰지 않고 메모리 영역에 memcpy로 복사만 해도 파일의 내용이 바뀐 것을 확인할 수 있다. 디맨드 페이징 기존에 설명한 메모리 할당 방법은 메모리 낭비 문제가 있다. 커널이 필요한 메모리를 확보하고 페이지 테이블을 설정하여 가상 주소 공간을 물리 주소에 매핑한다. 확보한 메모리 중에는 프로세스가 종료할 때까지 사용하지 않는 영역들이 있기 때문이다. 프로그램의 사용하지 않는 코드와 데이터 영역 glibc가 확보한 메모리 맵 중 malloc으로 확보하지 않은 부분 이를 해결하기 위해 나온 방법이 디맨드 페이징이다.페이지의 상태 기존의 페이지 상태에 3번째 상태를 추가한다. 프로세스에 할당되지 않음 프로세스에 할당되었고 물리 메모리에도 할당됨 프로세스에는 할당되었으나 물리 메모리에는 할당되지 않음 프로세스가 생성되면 코드 영역이나 데이터 영역에 프로세스가 영역을 얻었음을 표시한다. 다만 물리 메모리는 할당되지 않았다. 엔트리 포인트로부터 실행이 시작되면 엔트리 포인트에 해당하는 페이지용 물리 메모리가 할당된다.처리 흐름 프로그램이 엔트리 포인트 접근 CPU가 테이블을 통해 가상 주소가 물리 주소에 아직 매핑되지 않음을 확인 CPU에 페이지 폴트 발생 커널의 페이지 폴트 핸들러가 물리 메모리를 해당 페이지에 할당 페이지 폴트 지워짐 사용자 모드로 돌아와서 프로세스가 실행 계속함 프로세스는 페이지 폴트가 발생한지 모른다. 프로세스가 mmap( ) 함수로 메모리를 확보하는 것을 “가상 메모리를 확보했음”이라 부른다. 가상 메모리가 물리 메모리를 확보해 연결되면 “물리 메모리를 획득했음”이라 부른다. mmap 의 성공과 상관없이 물리 메모리를 확보하려 할 때 충분하지 않으면 물리 메모리 부족이 발생한다.실험프로그램의 흐름 메모리 획득 전을 알림 메모리 획득함 메모리 획득 후를 알림 10mb씩 접근함 -&gt; 물리 메모리 할당#include &lt;unistd.h&gt;#include &lt;time.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;err.h&gt;#define BUFFER_SIZE (100 * 1024 * 1024)#define NCYCLE 10#define PAGE_SIZE 4096int main(void){ char *p; time_t t; char *s; t = time(NULL); s = ctime(&amp;t); printf(\"%.*s: before allocation, please press Enter key\\n\", (int)(strlen(s) - 1), s); getchar(); p = malloc(BUFFER_SIZE); if (p == NULL) err(EXIT_FAILURE, \"malloc() failed\"); t = time(NULL); s = ctime(&amp;t); printf(\"%.*s: allocated %dMB, please press Enter key\\n\", (int)(strlen(s) - 1), s, BUFFER_SIZE / (1024 * 1024)); getchar(); int i; for (i = 0; i &lt; BUFFER_SIZE; i += PAGE_SIZE) { p[i] = 0; int cycle = i / (BUFFER_SIZE / NCYCLE); if (cycle != 0 &amp;&amp; i % (BUFFER_SIZE / NCYCLE) == 0) { t = time(NULL); s = ctime(&amp;t); printf(\"%.*s: touched %dMB\\n\", (int) (strlen(s) - 1), s, i / (1024*1024)); sleep(1); } } t = time(NULL); s = ctime(&amp;t); printf(\"%.*s: touched %dMB, please press Enter key\\n\", (int) (strlen(s) - 1), s, BUFFER_SIZE / (1024 * 1024)); getchar(); exit(EXIT_SUCCESS);} 실행 시키면 다음과 같은 결과를 확인 할 수 있다. 동시에 다른 터미널에서 확인해보면 다음과 같은 결과를 확인 할 수 있다. 100mb가 할당 받은 상태에서는 kbmemused 값의 변화가 거의 없다 이후 10mb씩 접근하면 kbmemused 값이 10mb 씩 증가하는 모습을 볼 수 있다. 모든 접근이 종료되면 100mb 늘어난 것을 확인 할 수 있다. kbmemused : 시스템의 물리 메모리 사용량가상/물리 메모리 부족가상 메모리 부족 말 그대로 가상 메모리 공간을 모두 사용했을 때 추가 메모리를 요청하면 발생한다. 32비트 기준 4GB가 최대 공간인데 이를 넘어서면 발생한다. 물리 메모리의 상태와 상관이 없다.물리 메모리 부족 진짜 물리 메모리를 다 쓴 경우이다.Copy on Write fork ( ) 시스템 콜을 가상 메모리를 사용하여 고속화한다. fork 가 발생하면 페이지 테이블만 복사한다. PCB에 페이지 테이블이 포함된다. 사실 PCB를 복사한다. 이후 페이지 테이블의 쓰기 권한을 자식과 부모 모두 무효화 한다. 둘 다 쓰지 못한다. 이후 누군가 쓰려하면 다음의 흐름이 진행된다. 페이지에 쓰기는 허용하지 않아 CPU 페이지 폴트가 발생 커널의 페이지 폴트 핸들러 등장 접근한 페이지를 다른 장소에 복사하고, 쓰려한 프로세스에 할당해준다. 이후 내용을 작성한다. 페이지 테이블 엔트리를 업데이트한다. 공유 상황이 풀렸기에 쓰기를 둘 다 허용한다. 쓰기가 발생할 때 물리 메모리를 복사하므로 CoW라고 부른다. fork가 성공해도 이후에 물리 페이지가 필요할 때 물리 메모리 부족이 발생한다. " }, { "title": "CNN-2", "url": "/posts/cnn2/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-07-24 21:10:00 +0900", "snippet": "Semantic Segmentationpredict pixel-wise labels, given a pre-defined set of categories각각의 픽셀이 어느 카테고리에 해당하는가?does not differentiate instances, only case about pixelsFully Convolutional NetworksFully Convolutional Networks for Semantic Segmentation기존 cnn과 다른 점은 출력 층의 크기가 입력과 같아야 한다.upsampling 이 필요하다.Upsamplingupsampling 하는 방법을 알아보자Nearest NeighborBed of NailsMax pooling이전 pooling 과정에서 max값을 찾은 위치를 기억하고 upsampling할 때 그 위치로 값을 배치한다.Deconvolution or Transposed ConvolutionResNet출처 : Deep Residual Learning for Image Recognition모델들이 깊어질 수록 효과가 좋아진다 생각함얼마나 깊어져야 하는가?논문에 의하면 마냥 깊어진다고 좋아지지는 않는다.Residual block논문에서는 skip connection 방법을 제시한다.즉 하나 혹은 여러 개의 layer를 건너뛴다.직접 규제를 통해 F(x)를 조절하는 것보다 이 방법을 이용하는 것이 편하다.만약 x 연결 부분이 강해지면 레이어를 거의 스킵해버림Gradient cal∂J∂x=∂J∂H∂H∂x{\\partial \\mathcal{J} \\over \\partial x} = {\\partial \\mathcal{J} \\over \\partial H} {\\partial \\mathcal{H} \\over \\partial x} ∂x∂J​=∂H∂J​∂x∂H​=∂J∂H(∂F∂x+1) = {\\partial \\mathcal{J} \\over \\partial H} \\left( {\\partial \\mathcal{F} \\over \\partial x}+1 \\right)=∂H∂J​(∂x∂F​+1)=∂J∂H∂F∂x+∂J∂H = {\\partial \\mathcal{J} \\over \\partial H} {\\partial \\mathcal{F} \\over \\partial x}+{\\partial \\mathcal{J} \\over \\partial H} =∂H∂J​∂x∂F​+∂H∂J​∂J∂H{\\partial \\mathcal{J} \\over \\partial H}∂H∂J​ = gradient highwaymitigate vanishing gradients 역할을 함그래디언트 값을 직접적으로 이전 레이어에 전달Skip connectionsIdentitiy shortcuts : 차원이 같을 때 사용H(x)=F(x;θ)+xH(x) = F(x; \\theta) + \\bold xH(x)=F(x;θ)+x차원이 다르면zero entries padding을 통해 차원을 맞춘다.H(x)=F(x;θ)+WsxH(x) = F(x; \\theta) + \\bold W_s\\bold xH(x)=F(x;θ)+Ws​xDeep Residual Net3번 줄과 같은 아키텍쳐를 가진다.효과는 좋다고 한다" }, { "title": "Memory management with linux", "url": "/posts/virtualWithLinux/", "categories": "CS, OS", "tags": "os, cs, summer, 실습과 그림으로 배우는 리눅스 구조", "date": "2022-07-23 18:30:00 +0900", "snippet": "메모리 관리메모리의 통계 정보 시스템의 총 메모리의 양과 사용 중인 메모리의 양을 free 명령어로 볼 수 있다.free Mem 줄의 중요한 필드를 알아보자. total : 시스템에 탑재된 전체 메모리 용량 free : 표기상 이용하지 않는 메모리 buff / cache : 버퍼 캐시, 페이지 캐시가 사용하는 메모리다. 빈 메모리가 부족하면 커널이 해제한다. available : 실질적으로 사용 가능한 메모리다. free 필드 값과 메모리가 부족하면 해제되는 커널 내의 메모리 영역 사이즈를 더한 값이다. swap : swap area의 크기이다. 다음 명령어를 통해 메모리 관련 통계 정보를 얻을 수 있다.sar -r 1메모리 부족 메모리가 부족하면 해제 가능한 공간을 해제하여 메모리를 늘린다. 이후에도 계속 부족하면 OOM 상태가 된다. out of memory 이때는 적절한 프로세스를 선택해 강제로 종료 시킨다. OOM Killer 라는 기능이다. 참고 서버에서 프로세스가 강제 종료가 되면 문제를 발생 시킨다. sysctl 의 ‘vm.panic_on_oom’ 파라미터의 기본 값을 변경해 프로세스가 아닌 시스템을 강제 종료하는 방법도 있다.단순 메모리 할당 메모리를 할당하는 일은 두 타이밍에서 벌어진다. 프로세스를 생성할 때 프로세스를 생성한 뒤 추가로 동적 메모리를 할당할 때 동적 할당하는 부분을 이야기해보자. 프로세스가 추가 메모리를 요청한다. 메모리 확보용 시스템 콜을 호출한다. 커널은 필요한 사이즈만큼 빈 메모리에서 가져와 시작 주소를 반환해준다. 문제점 이런 방식에는 문제점이 있다. 메모리 단편화 다른 용도의 메모리에 접근 가능 여러 프로세스를 다루기 곤란 프로세스마다 주소를 겹치지 않게 프로그래밍 해야 된다. 가상 메모리 위에서 언급된 여러 문제점을 해결하기 위한 방법이다. 개념적인 내용은 이전 글 참고Page fault 만약 물리 메모리에 매핑되어 있지 않은 주소에 접근하면 ? page fault 라는 인터럽트가 발생한다. 실행 중인 명령이 중단되고 페이지 폴트 핸들러라는 인터럽트 핸들러가 동작한다. SIGSEGV 시그널을 프로세스에 통지하며, 프로세스는 강제 종료된다. 직접 이를 확인해보자실험#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(void){ int *p = NULL; puts(\"before invalid access\"); *p=0; puts(\"after invalid access\"); exit(EXIT_SUCCESS);}메모리 할당 프로세스를 생성할 때 실행 파일에서 여러 보조 정보를 얻는다. 이름 값 코드 영역의 파일상 오프셋 100 코드 영역 사이즈 100 코드 영역의 메모리 맵 시작 주소 0 데이터 영역의 파일상 오프셋 200 데이터 영역 사이즈 200 데이터 영역의 메모리 맵 시작주소 100 엔트리 포인트 0 프로그램을 실행하는데 필요한 메모리 사이즈는 “코드 영역 사이즈” + “데이터 영역 사이즈” 이다. 즉 표를 기준으로 300이 필요하다. 추가적인 메모리 할당 새 메모리를 요구하면 커널은 새로운 메모리를 할당하여 대응하는 페이지 테이블을 작성하고, 할당된 물리 주소에 대응하는 가상 주소를 프로세스에 반환한다.실험#include &lt;unistd.h&gt;#include &lt;sys/mman.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;err.h&gt;#define BUFFER_SIZE 1000#define ALLOC_SIZE (100*1024*1024)static char command[BUFFER_SIZE];int main(void){ pid_t pid; pid = getpid(); snprintf(command, BUFFER_SIZE, \"cat /proc/%d/maps\", pid); puts(\"___ memory map before memory allocation ___\"); fflush(stdout); system(command); void *new_memory; new_memory = mmap(NULL, ALLOC_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1,0); if(new_memory == (void*) -1) err(EXIT_FAILURE, \"mmap() failed\"); puts(\"\"); printf(\"___succeeded to allocate memeory : address = %p; size = 0x%x ___\\n\", new_memory, ALLOC_SIZE); puts(\"\"); puts(\"___memory map after memory allocation___\"); fflush(stdout); system(command); if(munmap(new_memory, ALLOC_SIZE) == -1) err(EXIT_FAILURE, \"MUNMAP() FAILED\"); exit(EXIT_SUCCESS);} mmap( ) 함수는 리눅스 커널에 새로운 메모리를 요구하는 시스템 콜을 호출한다. system( ) 함수는 첫 파라미터에 지정된 명령어를 리눅스 시스템에서 실행한다. 중간에 출력된 문장을 보면 새로 할당된 메모리의 주소를 확인 할 수 있다. 100MB 가 할당된 것을 확인 할 수 있다.고수준 레벨에서의 메모리 할당 C의 표준 라이브러리에 있는 malloc( ) 함수가 메모리 확보 함수이다. 내부적으로는 mmap( ) 함수를 호출한다. mmap( ) 함수는 페이지 단위로 메모리를 확보한다. malloc( ) 함수는 바이트 단위로 확보한다. glibc 에서는 사전에 mmap( )으로 메모리 풀을 만든다. 이후 malloc( )이 호출되면 메모리 풀에서 일부를 반환한다. 만약 부족하면 mmap( )으로 새로운 메모리를 확보한다. " }, { "title": "Virtual memory management", "url": "/posts/virtualM/", "categories": "CS, OS", "tags": "os, cs, summer", "date": "2022-07-23 15:20:00 +0900", "snippet": "Virtual memory개요가상 메모리는 프로세스가 어디에 위치하든 0번부터 시작되는 메모리 공간을 가진다.논리 주소와 차이점은 실제 물리 메모리에 비례하지 않는다는 점이다.가상 메모리는 각 프로세스마다 자신이 모든 메모리를 점유하는 것처럼 만든다.이론적으로는 무한이지만 물리 메모리의 최대 크기로 한정된다.프로세스마다 메모리를 모두 점유하여 사용하면 메모리 공간이 많이 필요하다.즉 4GB 메모리에서는 ( 프로세스 수 x 4 GB )의 공간이 필요하다.이를 가상 메모리에서는 스왑을 이용하여 해결한다.프로세스마다 가상 주소를 가지고 있고, 이는 실제 메모리에 연결되어야 한다.이런 작업을 동적 주소 변환 (DAT)이라 부른다.메모리 관리자가 물리 메모리를 나누고 프로세스들을 배치하는 작업등을 한다.메모리 분할 방식구분가상 메모리물리 메모리최대 메모리 크기cpu 비트 값에 의존cpu 비트 값에 의존메모리 분할 방식세그멘테이션가변 분할 방식페이징고정 분할 방식세그멘테이션 페이징 혼용주소 지정 방식가상 주소절대, 상대 주소Table메모리 관리자는 가상 메모리와 물리 메모리를 매핑 테이블을 이용해 관리한다.물리 메모리의 분할 방식에 따라 이름이 나뉜다.page mapping tablesegmentation mapping tablePaging구현고정 분할 방식을 이용한 방법이다.단위는 페이지와 프레임으로 구분된다.이때 페이지와 프레임의 크기는 같다.invalid는 페이지가 스왑 영역에 있다는 것이다.주소 변환 과정개념가상 주소를 VA = &lt;P, D&gt; 로 표현한다.page : 페이지 번호distance : 페이지의 처음 주소부터 해당 위치까지 거리offset이라 정의하기도 한다.물리 주소를 PA = &lt;F, D&gt;로 표현한다.frame이때 주소 변환을 다음과 같이 정의한다.VA&nbsp;=&nbsp;&lt;P,&nbsp;D&gt;→PA&nbsp;=&nbsp;&lt;F,&nbsp;D&gt;\\text{VA = &lt;P, D&gt;} \\rightarrow \\text{PA = &lt;F, D&gt;}VA&nbsp;=&nbsp;&lt;P,&nbsp;D&gt;→PA&nbsp;=&nbsp;&lt;F,&nbsp;D&gt;페이지 테이블의 한 줄을 PTE라고 부른다.page table entry16 bit CPU컴퓨터는 이진법을 사용하므로 페이지의 크기는 2의 n승이 된다.P, D 값을 정의해보자.P = 가상 주소 / 한 페이지의 크기D = 가상 주소 % 한 페이지의 크기16 비트 cpu에서 한 페이지의 크기가 2102^{10}210 일 때를 생각하자.가상 주소는 0~65535 만큼의 공간을 가진다.이때 페이지는 26−12^6-126−1개페이지 하나의 번지 수는 210−12^{10}-1210−1개가 존재한다.페이지 테이블 관리여러 프로세스들은 각자의 페이지 테이블을 가지고 있다.고로 페이지 테이블의 크기는 프로세스 수에 비례한다.문제는 테이블의 크기가 작지 않다는 것이다.만약 32bit, 512B 페이지 시스템이라면 테이블의 최대 크기는 24.11MB이다.프로세스가 40개만 올라와도 1GB 정도가 된다.페이지 테이블은 메모리의 운영체제 영역에 존재한다.페이지 테이블의 일부도 스왑 영역으로 옮겨 사용하기도 한다.페이지 테이블은 자주 접근해야 하는 자료구조이다.이에 레지스터를 이용해 페이지의 시작 주소(물리 주소)를 보관한다.Page Table Base Register : PTBR페이지 테이블 매핑 방식직접 매핑연관 매핑집합-연관 매핑역매핑 ( 찾아보자 )각 방법마다 가상 주소를 물리 주소로 변환하는 방법이 다르며, 테이블을 저장하는 방법도 다르다.직접 매핑테이블 전체가 물리 메모리에 올라와 있는 상태이다.바로 주소 변환이 가능하다.연관 매핑테이블 전체를 스왑 영역에서 관리한다.여유 공간이 작을 때 사용일부만 물리 메모리에 가지고 있는다.일부의 테이블을 다음과 같이 부른다.변환 색인 버퍼 / Translation look-aside buffer연관 레지스터 / associate register원하는 페이지가 물리 주소에 있다면 TLB 히트찾지 못한다면 TLB 미스라고 부른다.미스가 많이 발생하면 주소 변환이 느려진다.집합-연관 매핑TLB 미스의 단점을 개선하기 위한 방법이다.한 개의 테이블을 추가로 사용한다.가상 주소를 나타내는 방법은 다음과 같다.VA&nbsp;=&nbsp;&lt;P1,&nbsp;P2,&nbsp;D&gt;\\text{VA = &lt;P1, P2, D&gt;}VA&nbsp;=&nbsp;&lt;P1,&nbsp;P2,&nbsp;D&gt;1번 테이블을 디렉터리 테이블이라 부르며 테이블이 스왑 영역에 있는지 확인 할 수 있다.스왑 영역에 없다면 P2 값을 이용해 메모리에 접근한다.디렉토리 테이블 만들기기존에 있던 페이지를 일정 개수만큼 묶는다.이후 디렉토리 테이블에 연결 시킨다.예를 들면 5 묶음으로 페이지 테이블을 나누면 P&lt;7,D&gt; 는 P&lt;1, 2, D&gt;로 사용하게 된다.Segmentaion가변 분할 방식을 이용한 가상 메모리 관리 기법이다.페이징 방법과 같이 매핑 테이블을 사용한다.이를 Segmentation mapping table 이라 부른다.세그멘테이션 기법도 메모리가 부족하면 스왑 영역을 사용한다.세그멘테이션 테이블에는 limit가 있다.이는 가변적인 프로세스 크기를 다루기 위함이다.주어진 메모리 영역을 넘어가지 못하도록 제한한다.만약 사용자가 프로세스 A에 주어진 공간을 벗어나는 주소에 접근하려하면 Trap 인터럽트를 발생시킨다.Trap이 발생하면 OS는 segmentation fault 메시지를 사용자에게 보낸다.시그널로 프로세스를 중지시키는 것은 사용자가 의도한 인터럽트이다. ( ctrl+c)주소 변환 과정은 동일하다.기존의 가변 분할 방식의 장, 단점을 모두 가진다.장점프로세스 단위로 메모리를 관리해서 페이지 테이블이 작고 간단하다.단점외부 단편화로 인한 메모리 관리 복잡성segmentation-paging 혼용 기법참고paged segmentation 에 관한 이야기이다.두 기법은 장단점이 있다.이를 부분적으로 취한 기법이다.메모리 접근 권한 개념이 추가된다.https://www.youtube.com/watch?v=d_S2QGQ_rBo 참고하자.페이지 테이블에 권한 비트까지 추가되면 페이지 테이블의 크기가 커진다.반복되는 권한 비트 제거를 위해 세그멘테이션 테이블을 이용한다.이외에도 반복되는 정보를 세그멘테이션 테이블에서 관리할 수 있다.주소 변환 과정을 알아보자혼용 기법에서는 다음과 같이 주소를 나타낸다.VA&nbsp;=&nbsp;&lt;&nbsp;S,&nbsp;P,&nbsp;D&nbsp;&gt;\\text{VA = &lt; S, P, D &gt;}VA&nbsp;=&nbsp;&lt;&nbsp;S,&nbsp;P,&nbsp;D&nbsp;&gt;S : 세그먼트 번호P : 페이지 번호D : 페이지 처음 위치부터 거리변환 과정을 순서대로 알아보자.1 . 가상 주소를 구한다.2. 세그멘테이션 테이블에서 권한과 메모리 영역을 검사한다.3. 페이지 테이블에서 페이지가 어느 프레임에 연결되었는지 찾는다.4. 메모리에 있다면 접근한다.5. 없다면 스왑 영역에서 해당 페이지를 물리 메모리로 가져온다.6. D 만큼 떨어진 곳에 접근하여 데이터를 사용한다." }, { "title": "CNN-1", "url": "/posts/cnn1/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-07-20 18:35:00 +0900", "snippet": "Introconvolutional Neural Network합성곱 신경망why CNN so Successful?similar to simple and complex cells in V1 area of visual cortexdavid h.hubel, torsten wiesel 노벨상 탐feature extraction + classificationhierarchical representationsHonglak Lee and colleagues (2011) as published in “Unsupervised Learning of Hierarchical Representations with Convolutional Deep Belief Networks”레이어가 깊어질수록 전체의 특징을 보게됨Pre-Trained CNNsAlexNethttps://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdfVGGhttps://arxiv.org/abs/1409.1556GoogLeNethttps://arxiv.org/abs/1409.4842Deep Residual Nethttps://arxiv.org/abs/1512.03385?context=cs보통 만들어진 모델을 활용하여 사용한다.Transfer learning파라미터를 고정한 상태로 아웃 레이어만 수정함 ( 분류 크기 )Fine tuningbackpropagation을 통해 튜닝하여 사용함bayesian model베이지안 모델을 이용하여 모델을 정할 수 있다.위에서 무슨 모델을 사용할지 정하는 과정learning to select pre-trained deep representations with bayesian evidence framework 라는 논문을 참고해보자.CNNConvolutioncnn에서는 가중치를 공유해서 사용한다.이를 필터/커널이라 부른다.합성곱 연산은 다음과 같다.필터를 들어온 행렬에 원소끼리 곱해준다.그 값들을 더해서 출력 행렬에 값을 정한다.이동하여 반복한다.input M1×M2M_1 \\times M_2M1​×M2​과 filter f×ff \\times ff×f 의 결과 행렬은(N1−f+1)×(N2−f+1)(N_1-f+1) \\times(N_2-f+1)(N1​−f+1)×(N2​−f+1)https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1가중치는 필터가 적용된 후 나온 행렬의 모든 원소에 더한다.Padding합성곱을 진행하면 결과 값의 크기가 작아진다.만약 크기를 유지하고 싶다면 padding을 이용한다.보통 0으로 값을 채우는 zero padding을 사용한다.처음 5x5 행렬이 유지되는 것을 확인할 수 있다.Strided Convolution필터가 이동할 때 간격을 이야기한다.왼쪽은 stride 가 1일 때, 오른쪽은 2일 때이다.Multi-Channel기본적으로 이미지는 채널이 여러 개이다.기본적으로 rgb만 해도 3차원이다.합성곱을 계산하기 위해서는 필터 또한 채널 크기의 깊이를 가져야 한다.계산 과정은 아래의 이미지를 참고하자.https://towardsdatascience.com/만약 필터의 개수가 K개이면 결과 값이 K개의 채널을 가지게 된다.채널의 길이를 조정할 때는 1x1 Convolution을 사용한다.1 x 1 Convolution1x1 convolution은 기존 input의 크기를 그대로 출력한다.이에 필터의 개수를 조절하여 output의 channel 길이를 조절한다.Pooling합성곱 층 이후 풀링한다.특성 맵을 다운 샘플링하여 크기를 줄인다.두 가지 방법이 있다.max poolingaverage pooling주로 max pooling이 사용된다.그림처럼 최대 값을 취하는 방식이다.채널마다 독립적으로 수행된다.즉 채널 길이가 유지된다.LeNet-5 에 적용해보자http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf32 x 32 입력이 들어온다.합성곱필터 : 5x5 , s=1, 개수 = 6결과 : 28 x 28 x 6max pooling2 x 2결과 : 14 x 14 x 6합성곱필터 : 5 x 5, s=1, 개수 = 16결과 : 10 x 10 x 16max pooling2 x 2결과 : 5 x 5 x 16 = 400Full connection400 x 120 x 84 x 10 ( output )" }, { "title": "Physical memory management", "url": "/posts/memory/", "categories": "CS, OS", "tags": "os, cs, summer", "date": "2022-07-19 22:30:00 +0900", "snippet": "메모리 관리의 개요시작이전에는 하나의 프로그램만 실행시켜서 메모리 관리에 어려움이 크지 않았다.현재 시분할 시스템에서는 많은 프로세스들이 메모리에 올라와 실행된다. 이를 효휼적으로 관리할 방법이 필요하다.MMUmemory manage unit하드웨어이다.간단히 정리한다.역할가져오기프로세스와 데이터를 메모리로 가져온다.요청이 없어도 필요할 것 같은 데이터를 미리 가져온다.배치 작업가져온 프로세스와 데이터를 메모리에 적절히 배치한다.재배치 작업메모리가 가득 찬 상황이면 일부 프로세스를 하드로 옮기는 작업을 한다.정책가져오기 정책프로세스의 필요한 데이터를 언제 가져올지 결정하는 정책prefetch 를 하기도 한다.배치 정책paging : 메모리를 같은 크기로 자르는 것segmentation : 프로세스 크기에 맞게 자르는 것이런 기술을 이용해 효율적인 메모리 관리 정책을 만든다.재배치 정책replacement algorithm : 무슨 프로세스를 내보낼지 정한다.메모리 주소32bit / 64bit cpu메모리는 1byte마다 주소를 붙여 사용한다.이때 MAR(메모리 주소 레지스터)를 이용한다.32bit는 MAR의 크기가 32비트이다.64bit는 64비트여기서 cpu가 관리할 수 있는 메모리 공간의 사이즈를 알 수 있다.32bit : 2^32 byte = 4GB 정도64bit : 2^64 byte = 겁내 많음즉 32bit에 16GB RAM을 박는 것은 …메모리 주소는 다음과 같이 나눌 수 있다.Physical address space : 하드웨어 관점logical address space : 사용자 입장절대 주소와 상대 주소메모리 영역기본적으로 메모리는 운영체제 영역과 사용자 영역으로 나뉜다.이때 사용자 영역이 운영체제 영역을 침범하지 못하도록cpu의 경계 레지스터 값을 이용해 검사하고 막는다.문제점은 운영체제의 크기가 변한다면 사용자 프로그램의 주소가 변해야 한다.즉 프로그램을 짤 때는 360번지부터 400번지를 사용해서 프로그래밍하면, 후에 os가 바뀌면 문제가 발생한다.이렇게 직접 물리주소를 이용하는 것은 문제가 많다.절대 주소와 상대 주소메모리 관리자 입장에서는 실제 메모리의 주소를 사용한다.절대 주소는 실제 물리 주소를 가르킨다.하지만 사용자 프로세스 입장에서는 0번부터 생각한다.즉 운영체제와 mmu가 알아서 관리한다.이때 재배치 레지스터를 이용한다.이를 논리 주소 공간이라 부른다.단일 프로그래밍과 메모리 할당메모리 오버레이컴퓨터의 메인 메모리보다 큰 프로그램을 실행하도록 만드는 방법적당한 크기로 잘라서 메모리에 가져온다.module 단위로 나눈다.프로그램의 일부만 올라와서 실행된다.스왑module 단위로 나누어졌을 때 사용하지 않는 module은 어디에 보관될까?저장장치의 swap area에 보관된다. ( 공간을 마련함 )swap in : 스왑 영역에서 메모리로 데이터를 가져옴swap out : 메모리에서 스왑 영역으로 데이터를 내보냄이는 메모리 관리자가 관리한다.이때 사용자는 스왑 영역과 메모리 영역의 크기를 합쳐서 인식하게 된다.사진에서 사용자는 5GB 프로그램을 돌리는 것으로 인식한다.다중 프로그래밍과 메모리지금까지는 한 프로세스만 실행되는 상황을 다루었다.지금부터는 여러 프로세스들이 실행될 때 메모리 관리를 살펴보겠다.메모리 분할 방식메모리 배치 정책에 해당된다.여러 프로세스를 메모리에 어떻게 배치할 것인가?variable-size partitioning : 가변 분할 방식fixed-size partitioning : 고정 분할 방식variable-size partitioning프로세스의 크기에 맞게 메모리가 분할 된다.즉 메모리의 영역 크기가 모두 다르다.한 프로세스가 연속된 공간에 배치된다.contiguous memory allocation장점프로세스를 한 덩어리로 처리해서 연속적인 공간에 배치 가능단점메모리 관리가 복잡하다.fixed-size partitioning프로세스의 크기 상관없이 메모리가 같은 크기로 분할 된다.비연속 메모리 할당이라 부른다.noncontiguous memory allocation장점메모리 관리가 편하다.단점작은 프로세스가 올라오면 메모리 낭비가 발생한다.혹은 잘려서Variable-size partitioning외부 단편화만약 B와 D가 종료되고 E라는 프로그램이 메모리에 올라오는 상황을 생각해보자빈 공간보다 큰 공간을 필요로 하는 E는 올라가지 못한다.결국 E는 공간을 받을 수 있을 때까지 기다린다 ( 아사 )결국 작은 빈 공간이 생기게 된다.이 현상을 Fragmentation(단편화)이라 부른다.빈 공간을 external fragmentation이라 부른다.hole프로세스 밖에서 빈 공간(조각)이 발생하기 때문이다.이를 해결하기 위해memory placement strategy : 메모리 배치 방식조각이 발생하지 않도록 배치defragmentation : 조각 모음조각을 모아서 크게 만듬메모리 배치 방식대표적인 방법은 다음과 같다. (버디 시스템도 있다.)최초 배치적재 가능한 공간을 순서대로 탐색하다가 첫 번째 공간에 넣음빈 공간 전체 탐색이 필요 없다.다만 단편화가 잘 발생한다.최적 배치빈 공간을 모두 확인하고 가장 작은 공간에 배치한다.아주 작은 조각이 남게 된다.최악 배치빈 공간을 모두 확인하고 가장 큰 공간에 배치한다.남은 조각도 커서 재활용이 가능하다.다만 시간이 지나면 작은 조각이 남는다.조각 모음아무리 배치를 잘해도 단편화 현상이 발생한다.사용하지 못하는 작은 조각들을 모아 쓸모 있게 만들 필요가 있다.단계프로세스들 중단적당한 위치로 차곡차곡 옮긴다. ( 상대 주소 값 )프로세스 다시 시작많은 시간이 걸린다.Fixed-size partitioning가상 메모리에서는 고정 분할 방식을 paging이라 부른다.메모리를 같은 크기로 나누어 관리는 쉽지만 프로세스가 나눠 저장된다.내부 단편화기본적으로 가변 분할 방식보다는 고정 분할 방식을 기본으로 사용한다.이는 관리가 수월하기 때문이다.프로그램을 일정 단위로 나누기 때문에 외부 단편화는 발생하지 않는다.일정 단위를 페이지라 부른다. ( 가상 메모리 기준 )하지만 단위보다 작은 공간을 필요로 하면 내부 단편화가 발생한다.internal fragmentation이를 해결하는 방법은 없다.조각 모음이나 남는 공간을 다른 프로세스에게 넘길 수 없다.유일한 해결책은 단위의 크기를 조절하는 것이다." }, { "title": "Normalization", "url": "/posts/Normalization/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-07-18 23:10:00 +0900", "snippet": "Normalization종류Batch normalizationhttps://arxiv.org/abs/1502.03167CNNLayer normalizationhttps://arxiv.org/pdf/1607.06450.pdfRNN, TransformerInstance normalizationGroup normalizationNormalizationStandardization 표준화왜 할까?범위가 너무 넓어 step size를 정하기 어렵다.보수적으로 잡게 됨방법평균이 0, 분산이 1이도록 만든다.Batch Normalizationdata들이 whitened하면 Training converges 가 빠르게 진행된다.whitened : zero mean, unit variance, decorrelatedDeep Neural Networks 에 적용을 해보자!Internal Covariate Shift처음 input은 표준화 되어있다.그러나 다음 layer에서는 표준화 되어 있지 않다.h=∑wx+bh1=ϕ(h)h = \\sum wx + b \\\\ h_1 = \\phi(h)h=∑wx+bh1​=ϕ(h)보통 input distrubution 이 input과 output에서 같다고 생각한다.만약 다른 상황이라면 이를 Covariate shift라고 부른다.지금은 layer에서 벌어진 상황이기에 Internal Covariate shift라고 부른다.Batch Normalization이제 batch normalization에 대해 알아보자.우선 하나의 노드를 기준으로 생각한다.batch는 입력 데이터의 개수이다.입력 노드의 수가 아니다.batch가 10이라면 10번 feed foward가 발생한다.이때 h1이 된 값은 10개가 존재한다.이 값들을 가지고 normalization을 진행한다.M=size&nbsp;of&nbsp;mini-batchM = \\text{size of mini-batch}M=size&nbsp;of&nbsp;mini-batch 일때 수식으로 정리해보면 다음과 같다.z~i=hi−μiσi2+ϵ\\tilde z_i = {h_i - \\mu _i \\over \\sqrt{\\sigma_i^2+\\epsilon}}z~i​=σi2​+ϵ​hi​−μi​​μi=1M∑m=1Mai,m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;σi2=1M∑m=1M(ai,m−μi)2\\mu _i = {1\\over M}\\sum_{m=1}^M a_{i,m} \\ \\ \\ \\ \\ \\sigma_i^2 = {1\\over M}\\sum_{m=1}^M(a_{i,m}-\\mu_i)^2μi​=M1​m=1∑M​ai,m​&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;σi2​=M1​m=1∑M​(ai,m​−μi​)2이후에는 Scale 과 Shift 과정을 지난다.이는 하나의 layer가 추가된 것으로 볼 수 있다.zi=γiz~i+βi\\bold z_i = \\gamma_i \\tilde z_i+\\beta_izi​=γi​z~i​+βi​왜 scale과 shift 과정이 필요할까?다음 그림을 보며 이해해보자.우선 normalization 과정은 빨간 분포를 중앙의 파란 분포로 바꾸는 과정이다.이후 우리는 sigmoid 를 취하게 되는데 빨간색에 위치한 sigmoid의 경사는 파란색 분포보다 완만하다.만약 빨간색에서 계속 기울기가 계산된다면 매우 느리게 converge 할 것이다.gradient vanishing 문제이때 표준화 과정에서 항상 평균을 0으로 분산을 1로 하는 것이 의미가 있을까?우선 표준화 과정의 장점은 빠른 converge이다.gradient vanishing 해결하지만 모두 같은 기울기를 가지게 되고 , 이는 활성화 함수가 비선형 함수로써 의미가 없어지게 만든다.그래서 두 개의 변수를 추가해서 scale과 shift 과정을 만든다.랜덤성을 부여하는 것이다.중앙이 답이 아닐 수도 있으니까두 변수는 역전파 과정에서 학습된다. 즉 데이터가 정한다.BN in Inference phase학습 시에는 배치 크기 기준으로 학습을 했다.그렇다면 테스트 시에는 무엇을 기준으로 해야 될까?이때는 단순히 마지막 결과를 사용하는 것이 아닌 평균을 이용한다.즉 한번 배치를 돌 때마다 평균 값과 분산 값이 나오게 됨이 값들을 다시 평균 내서 입력 값을 표준화 하는데 사용한다.이후 학습된 γ와β\\gamma \\text{와} \\betaγ와β 값을 이용해 scale, shift 해준다.분산을 평균 낼 때는 MM−1M\\over M-1M−1M​을 곱한다. (편향)moving avg를 구한다.장점step size 를 증가시킬 수 있다.speed upremove dropoutreduce L2 weight regularizationLayer Normalizationrnn에는 BN이 잘 안 맞음시간의 흐름이 중요한데 배치마다 평균 내버림배치 사이즈가 작으면 BN의 문제가 있다.( 이유는 찾아보자 )LNaverage of node말 그대로 레이어 값들의 통계량을 이용한다.BN은 Batch를 기준으로 통계량을 만들어 이용했다면LN은 한 input에 대하여 작동하며, 같은 층의 노드들의 통계량을 사용한다.다음과 같은 결과가 나온다.이후 내용CNN을 배우고 오자!" }, { "title": "Dropout", "url": "/posts/Dropout/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-07-18 14:55:00 +0900", "snippet": "Dropouthttps://arxiv.org/abs/1207.0580https://jmlr.org/papers/v15/srivastava14a.htmlOverfitting in NNlayer 마다 L1, L2 regularization을 적용함그러나 이것으로는 부족하다!co-adaptationco-adaptation일부 노드들이 서로 상쇄되면서 아무 일도 안해버림즉 일부 뉴런들이 의존적으로 변해버림노드의 낭비와 컴퓨팅 파워, 메모리 낭비를 야기함dropout이를 풀기 위한 새로운 regularization하나의 모델이 다른 여러 모델을 시뮬레이션 하는 결과Dropoutz∼Bern(p)z \\sim \\text{Bern}(p)z∼Bern(p)hi(l+1)=σ(wi(l+1)⊤(hl⊙zl+bi(l+1)))h_i^{(l+1)} = \\sigma(\\bold w_i^{(l+1)\\top}(\\bold h^{l}\\odot\\bold z^l+b_i{(l+1)}))hi(l+1)​=σ(wi(l+1)⊤​(hl⊙zl+bi​(l+1)))0이 곱해지면 노드는 죽어버림평균적으로 반이 죽음scale down두번째 논문 3페이지 참고훈련 시와 테스트 시 노드 수의 차원이 다른 문제가 있다.크기 조정이 필요하다.테스트 시에는 drop training을 할 때 사용한 ppp 값을 가중치에 곱해서 사용한다.Understanding dropout논문 참고EN=12(y−∑jpjwjxj)2\\mathcal E_N = {1\\over2}(y-\\sum_jp_jw_jx_j)^2EN​=21​(y−j∑​pj​wj​xj​)2ED=12(y−∑jzjwjxj)2\\mathcal E_D = {1\\over2}(y-\\sum_jz_jw_jx_j)^2ED​=21​(y−j∑​zj​wj​xj​)2single linear layer with a regular network, dropout networkz∼Bern(p)z \\sim \\text{Bern}(p)z∼Bern(p)p=P(z=1)p = \\mathbb P(z = 1)p=P(z=1)그래디언트를 취하면∂ED∂wi=−yzixi+wizi2xi2+∑j≠iwjzjzixjxi{\\partial \\mathcal E_D\\over \\partial w_i } = -yz_ix_i + w_iz_i^2x_i^2+\\sum_{j\\ne i}w_jz_jz_ix_jx_i∂wi​∂ED​​=−yzi​xi​+wi​zi2​xi2​+j=i∑​wj​zj​zi​xj​xi​∂EN∂wi=−ypixi+wipi2xi2+∑j≠iwjpjpixjxi{\\partial \\mathcal E_N\\over \\partial w_i } = -yp_ix_i + w_ip_i^2x_i^2+\\sum_{j\\ne i}w_jp_jp_ix_jx_i∂wi​∂EN​​=−ypi​xi​+wi​pi2​xi2​+j=i∑​wj​pj​pi​xj​xi​평균을 취하면E[∂ED∂wi]=−ypixi+wipi2xi2+wivar(zi)xi2+∑j≠iwjpjpixjxi \\mathbb E \\left[ {\\partial \\mathcal E_D\\over \\partial w_i } \\right] = -yp_ix_i + w_ip_i^2x_i^2 + w_i \\text{var}(z_i)x_i^2 + \\sum_{j\\ne i}w_jp_jp_ix_jx_iE[∂wi​∂ED​​]=−ypi​xi​+wi​pi2​xi2​+wi​var(zi​)xi2​+j=i∑​wj​pj​pi​xj​xi​=∂EN∂wiwipi2xi2+wivar(zi)xi2= {\\partial \\mathcal E_N\\over \\partial w_i } w_ip_i^2x_i^2 + w_i \\text{var}(z_i)x_i^2=∂wi​∂EN​​wi​pi2​xi2​+wi​var(zi​)xi2​=∂EN∂wiwipi2xi2+wipi(1−pi)xi2= {\\partial \\mathcal E_N\\over \\partial w_i } w_ip_i^2x_i^2 + w_i p_i(1-p_i)x_i^2=∂wi​∂EN​​wi​pi2​xi2​+wi​pi​(1−pi​)xi2​이 식은 regularized network를 최소화한 것과 같다.즉 아래 식을 미분하면 위의 식이 나옴ER=12(y−∑jpjwjxj)2+12∑jpi(1−pi)wj2xi2\\mathcal E_R = {1\\over2}(y-\\sum_jp_jw_jx_j)^2 + {1\\over2}\\sum_j p_i(1-p_i)w_j^2x_i^2ER​=21​(y−j∑​pj​wj​xj​)2+21​j∑​pi​(1−pi​)wj2​xi2​Inverted Dropouttrain 에서 dropout을 하고 가중치에 rescale을 진행함wi(i)=wi(i)/&nbsp;p \\bold w_i^{(i)} = w_i^{(i)} / \\ pwi(i)​=wi(i)​/&nbsp;p즉 test에서 scale하지 않음etcdropout은 레이어마다 rate 값을 다르게 줄 수 있다.hyper param 이다.Fully connected layer에서는 잘 사용하지만cnn에서는 batch normalization이 나오고 잘 안쓰게됨" }, { "title": "Process synchronization", "url": "/posts/concu/", "categories": "CS, OS", "tags": "os, cs, summer", "date": "2022-07-17 00:25:00 +0900", "snippet": "Inter-Process Communication 프로세스 간 통신이다. 즉 프로세스들이 데이터를 주고 받는 행위와 경로, 방법을 논한다. IPC의 종류 프로세스 내부 데이터 통신 하나의 프로세스 내에 2개 이상 쓰레드가 존재할 때 전역변수나 파일을 이용 프로세스 간 데이터 통신 공용 파일 혹은 OS의 파이프를 이용한다. 네트워크를 이용한 데이터 통신 여러 컴퓨터가 네트워크로 연결된 경우 소켓을 이용한다. 네트워킹 : 소켓을 이용한 통신 한 컴퓨터 내 에서는 소켓보다는 다른 방법으로 통신한다.IPC의 분류통신 방향에 따른 분류 양방향 통신 양쪽으로 데이터를 동시에 전송 가능한 구조 소켓 방식이 있다. 반양방향 통신 양쪽으로 전송 가능하나 동시 전송이 불가능하다. 특정 시점에 한 방향으로만 전송 가능하다. 단방향 통신 한쪽으로만 전송 가능한 구조이다. 프로세스 간 통신에서는 전역 변수, 파이프가 해당한다. 전역변수는 양쪽에서 데이터를 지정할 때 하나만 적용된다.통신 구현 방식에 따른 분류busy waiting 받는 쪽에서 보낸 데이터가 있는 지 계속 확인하는 상태를 말한다. 무한 반복으로 수시로 변수 값을 확인한다. 오버헤드가 크다. synchronization 위 문제를 위해 데이터가 도착했음을 알려주는 동기화가 필요하다. 이는 대기가 있는 지에 따라 동기화 여부를 나눈다. 대기가 있는 통신 ( 동기화 ) 파이프, 소켓 대기가 없는 통신 ( 비 동기화 ) 전역 변수, 파일 IPC의 종류 기본적으로 쓰기, 읽기로 간소화 할 수 있다.전역 변수를 이용한 통신 직접적인 관련이 있는 프로세스에서 사용한다. 전역 변수를 이용해 읽고 쓰기를 진행한다. 다만 받는 입장에서는 전역변수가 바뀌었는지 계속 확인해야 한다. busy waiting 문제 파일을 이용한 통신 파일을 open, write, read, close 연산을 통해 사용한다. 부모 자식 간 통신에 많이 사용된다. OS가 동기화를 지원하지 않는다. 프로세스 수준에서 wait를 이용하여 동기화를 진행한다. 자식을 기다림 파이프를 이용한 통신 파이프 운영체제가 제공하는 동기화 통신 open, close 이용 단방향 통신 파이프의 종류 이름 없는 파이프 부모 자식 간, 형제 사이 등 관련 있는 프로세스 간 통신 이름 있는 파이프 FIFO라는 특수 파일 이용, 관련 없는 프로세스 간 통신 소켓을 이용한 통신 소켓을 이용한 통신은 네트워크를 통해 다른 컴퓨터와 연결 가능하다. 동기화를 지원하며 하나의 소켓으로 양방향 통신이 가능하다.Shared resource &amp; Critical SectionShared resource 여러 프로세스들이 함께 이용하는 자원을 말한다. 자원은 cpu가 될 수도 있고 메모리가 될 수도 있다. ( 이외 여러가지 )Race Condition 여러 프로세스가 동시에 자원에 접근해 경쟁 하는 상태를 race condition이라 부른다. 이는 예상치 못한 결과를 야기한다.Critical section 둘 이상의 프로세스(쓰레드)가 동시에 접근하면 안되는 공유 자원을 접근하는 코드의 일부를 이야기한다. 즉 병렬 실행 중 한 프로세스(쓰레드)만 유일하게 실행할 수 있는 코드 부분을 이야기한다.해결 조건 위와 같은 공유 자원을 동시에 접근하는 행위는 문제를 일으킨다. 왜 문제가 될까? 앞 뒤 글을 모두 읽고 코딩해보자. 이를 해결하는 여러 방법이 나왔고, 이때의 조건이 있다. mutual exclusion 한 프로세스가 임계구역에 들어가면 다른 프로세스는 들어가지 못한다. bounded waiting 무한 대기가 발생하면 안된다. 데드락 관련 문제 progress flexibility 한 프로세스가 다른 프로세스의 진행을 방해해서는 안된다. Solutions 이 부분부터 일부는 KUOCW 최린 교수님의 수업을 따라간다.H/W 하드웨어 수준에서 Mutual Exclusion을 해결하는 방법이다. 단순한 코드 한 줄을 실행하는 것도 여러 단계의 어셈블리 언어를 통해 작동된다. ( 위에 “왜 문제가 될까?” 글 참고 ) 이때 context change가 발생하면 문제가 생긴다. 그래서 이에 대한 해결책으로 기계어를 묶어버리는 것이다. 즉 원자성을 보장함 이를 ‘‘Special Instructions’’ 라고 부른다. 다음과 같은 명령어가 있다. test and set fetch and add compare and swap etc 이를 이용해서 Mutual Exclusion, semaphore를 구현할 수 있다. 문제점 busy waiting dead lock Compare and waitcompare_and_swap(int *word, int testval, int newval){\tint oldval;\toldval = *word;\tif(oldval == testval) *word = newval;\treturn oldval;} word 값이 testval 과 같으면 newval로 교체함 이를 이용해 mutual exclusion을 구현해보자. const int n = number of processesint bolt; //락 변수 void p (int i){\twhile(1){\t\twhile(compare_and_swap(&amp;bolt, 0, 1) == 1)\t\t\t/* do nothing */\t\t// critical section\t\tbolt = 0;\t\t// remainder\t}}void main(){\tbolt = 0;\tparbegin(p(1), p(2), ... p(n));} 하나의 프로세스에서만 while문을 통과한다. 이후 임계 구역을 지나고 다시 bolt를 0으로 수정한다. 이후 하나의 프로세스만 while문을 통과한다.Exchangevoid exchange(int *register, int* memory){\tint temp;\ttemp = *memory;\t*memory = *register;\t*register = temp} 이를 이용해 mutual exclusion을 구현해보자.const int n = number of processesint bolt; //락 변수 void p (int i){\tint keyi = 1;\twhile(1){\t\tdo exchange(&amp;keyi, &amp;bolt)\t\twhile(keyi != 0)\t\t\t\t// critical section\t\tbolt = 0;\t\t// remainder\t}}void main(){\tbolt = 0;\tparbegin(p(1), p(2), ... p(n));} 하나의 프로세스에서만 while문을 통과한다. 이후 임계 구역을 지나고 다시 bolt를 0으로 수정한다. 이후 하나의 프로세스만 while문을 통과한다.Special Instructions atomic instructions 장점 멀티 프로세스에서도 share resource가 가능하다. simple multiple 임계 구역을 지원한다. 여러 변수 이용 단점 busy working starvation dead lock 만약 p1이 임계 구역에 들어갔을 때 interrupted 당하고 p2가 우선순위가 높아 실행되어 버림 p2는 mutual exclusion 때문에 loop를 돌게됨 그러나 p1은 낮은 우선순위로 p2를 기다리게됨 Semaphore 뭔가 소프트웨어적 이상적인 구현 방법이 없을까? 다익스트라 등장! 추상적인 세마포어 변수를 이용한 알고리즘 V operation (‘signal’) increment the semaphore P operation (‘wait’) decrement the semaphore type of semaphore Binary semaphore 0, 1 (locked, unlocked) Counting semaphore 임의의 값 defstruct semaphore{\tint count; // 이때 count 값은 공유 가능한 자원의 수를 나타낸다. \tqueueType queue;};void semWait(semaphore s){\ts.count--;\tif(s.count &lt; 0){ // 남은 자원이 없음\t\t// place this process in s.queue\t\t// block this process\t}}void semSignal(semaphore s){\ts.count++;\tif(s.count &lt;=0 ){ // 남은 프로세스가 있음\t\t// remove a process P from s.queue\t\t// place process P on ready list\t}\t} 만약 프린터가 2개면 세마포어 값은 초기에 2이다. 양의 값을 남은 자원 음의 값을 대기 중인 프로세스라고 생각하면 편한 것 같다.Exmutual exclusion 이를 이용해 mutual exclusion을 구현해보자.const int n = number of processsemaphore s = 1;void P(int i){\twhile(1){\t\tsemWait(s);\t\t// critical section\t\tsemSignal(s);\t\t// remainder\t}}void main(){\tparbegin(P(1), P(2), ... P(n));} 세마포어는 하드웨어적으로 구현하기 불가능하다. 하지만 결국 구현 시 atomic instruction을 사용한다. semWait(s){\twhile(compare_and_swap(s.flag, 0, 1)==1){}\t// do nothing\ts.count--;\tif(s.count &lt; 0){\t\t// place this process in s.queue\t\t// block this process (must also set s.flag to 0)\t}}semSignal(s){\twhile(compare_and_swap(s.flag, 0, 1)==1){}\t//do nothing\ts.count++;\tif(s.count &lt;= 0){\t\t// remove a process p from s.queue\t\t// place process p on ready list\t}} 소프트 웨어 적으로는 피터슨과 테커 알고리즘으로 구현된다. 데커는 하드웨어 도움이 필요 없지만 피터슨은 필요로 한다.Producer/Consumer Problem 여러 문제 중 여러 명의 producer와 한 명의 consumer를 가정해보자. producer나 consumer 든 한 사람만이 특정 시간에 버퍼에 접근 가능하다. 빈 버퍼에서 가져오거나 가득 찼는데 채우는 문제를 고려해야 한다.programsemaphore n = 0, s = 1; // n은 물건 개수, s는 critical sectionvoid producer(){\twhile(true){\t\tproduce();\t\tsemWait(s);\t\tappend();\t\tsemSignal(s);\t\tsemSignal(n);\t}}void consumer(){\twhile(true){\t\tsemWait(n); // n이 0보다 크면 consume 가능\t\tsemWait(s);\t\ttake();\t\tsemSignal(s);\t\tconsume();\t}}void main(){\tparbegin(producer, consumer);} 두 개의 세마포어를 사용한다. 처음에는 n이 0개 이므로 consumer는 실행이 되지 않는다. 이후 생산자에서 n 시그널을 보낸다. consumer는 1차 벽을 통과하지만 만약 producer가 critical section에 있으면 wait한다. 이후 take한다.Quiz 만약 producer에서 semSignal의 s와 n의 순서를 바꾸면? 상관 없다. 만약 producer에서 semWait의 n과 s의 순서를 바꾸면? 데드락이 걸린다. consumer가 먼저 임계 구역에 들어감 하지만 n으로 인해 waiting 그러나 producer또한 s로 인해 waiting Monitorsemaphore의 단점 세마포어로는 프로그램을 개발하기 어렵다. 프로그래머의 실수로 임계 구역이 보호 받지 못할 수도 있다. 전체 프로그램을 파악하기 어렵다.monitor 프로그래밍 언어에서 제공하는 기능이다. semaphore 대체 가능하다. 사용자는 걱정을 안해도 된다. 모니터는 기본적으로 하나 혹은 이상의 procedures로 되어있다. 초기화 코드와 지역 변수도 있다. 한번에 하나의 프로세스만 모니터 안에서 실행 가능하다. mutual exclusion 모니터 안에 정의된 변수는 모니터 안에 지정된 procedures로만 접근 가능하다.condition variable-모니터는 동기화를 위해 상태 변수를 사용한다. 다음과 같은 함수로 계산된다. cwait( ) 프로세스를 대기 시킴 ( 특정 컨디션까지 ) csignal( ) blocked 된 프로세스를 깨움 ( 같은 컨디션에서 ) 만약 대기 중인 프로세스가 없으면 아무것도 안 함 코드를 보면 이해하기 좋다. 모니터의 코드 모니터 안의 함수를 사용하여 안에서 작업한다. 이 코드 실행은 하나의 프로세스만 가능함을 보장한다. 즉 wait가 걸리면 위 그림처럼 대기 타야 한다. monitor boundedbuffer; // 모니터 코드char buffer[N]; // space for N itemsint nextin, nextout; // buffer pointersint count; // number of items in buffercond notfull, notempty; // conditional var for synchvoid append(char x){\tif(count == N) cwait(notfull); // buffer is full?\t// full -&gt; notfull일때까지 wait\t\tbuffer[nextin] = x;\tnextin = (nextin+1)%N;\tcount++;\t// one more item in buffer\tcsignal(notempty); //resume any waiting consumer\t//누군가 notempty를 기다리면 wake up 시킴}void take(char x){\tif(count==0) cwait(notempty); // buffer is empty?\t//count==0 이면 notempty 까지 wait\tx = buffer[nextout];\tnextout = (nextout+1)%N;\tcount--;\tcsignal(notfull); // resume any waiting producer\tnextin = 0; nextout = 0; count = 0; // buffer initially empty} producer와 consumer의 코드void producer(){\tchar x;\twhile(1){\t\tproduce(x);\t\tappend(x);\t}}void consumer(){\tchar x;\twhile(1){\t\ttake(x);\t\tconsume(x);\t}}void main(){\tparbegin(producer, consumer);}Message passing 가장 일반적이고 쉽다! mutual exclusion synchronization communication 모두 가능 shared mem, distributed mem 모두 가능 Function send (dest, msg) receive (dest, msg)Communication 둘 간에 동기화가 된다는 것을 의미함 리시버는 다른 프로세스가 보내기 전까지 받지 못한다.Blocking, nonblocking sender, receiver blocking sender 받을 때까지 기다림 receiver 보낼 때까지 기다림 non sender 그냥 보내버림 receiver 그냥 포기해버림 보통 non send, blocking receive 사용한다.Addressing direct 명시해서 보내거나 받음 아무한테나 받아서 리턴함 indirect 메일 박스에 보내버림 ( 홀드 ) Mutual exclusionconst int n = number of processes;void p(int i){\tmessage msg;\twhile(ture){\t\treceive(box, msg); // 메시지는 하나만 받을 수 있음\t\t// critical section\t\tsend(box, msg);\t\t// remainder\t}}void main(){\tcreate mailbox box;\tsend(box, null);\tparbegin(p(1), p(2),...p(n));}Producer Consumer with msgconst int cap = buffering cap;const int null = empty msg;int i;void producer(){\tmessage pmsg;\twhile(1){\t\treceive(mayproduce, pmsg); // 못 받으면 blocking\t\tpmsg = produce();\t\tsend(mayconsume, pmsg);\t}}void consumer(){\tmessage cmsg;\twhile(1){\t\treceive(mayconsume, cmsg);\t\tconsume(cmsg);\t\tsend(mayproduce, null);\t}}void main(){\tcreate_mailbox (mayproduce);\tcreate_mailbox (mayconsume);\tfor(int i=1;i&lt;=cap;i++) send(mayproduce, null);\tparbegin(producer, consumer);}" }, { "title": "Schedule", "url": "/posts/scheduler/", "categories": "CS, OS", "tags": "os, cs, summer", "date": "2022-07-15 13:00:00 +0900", "snippet": "Process StateActive status프로세스의 상태를 정리해보자.생성, 준비, 실행, 대기, 완료 -&gt; 5가지 상태Readycpu 스케줄러의 호출을 기다리는 상태Runningcpu를 사용하고 있는 상태I/O 요청 시 cpu를 뺏김 -&gt; I/O까지 waittimeslice를 모두 소모하면 뺏김Waitingblocking status입출력이 완료될 때까지 기다리는 상태이다.입출력이 끝나면 인터럽트 발생해당 프로세스 준비 상태로 이동Zombiepcb만 남기고 다 지워짐이후 부모에게 신호를 보낸다. ( 회수 요청 )부모 프로세스는 wait 시스템 콜을 통해 자식 프로세스의 종료 상태를 읽어 들인다.부모가 os에게 자식이 종료되었는지 확인함이후 완전히 pcb까지 소멸된다.고아 프로세스부모가 wait 대신 그냥 종료되버림init을 부모로 삼는다. init은 주기적은 wait 요청으로 고아를 거둠특별한 상태휴식 상태pause status작업을 일시적으로 쉬고 있는 상태보류 상태suspend status메모리에서 잠시 쫓겨난 상태메모리가 꽉차서 밀려남오류 발생바이러스, 악의적 행동매우 긴 주기입출력 계속 지연메모리 밖인 swap area에 보관됨이후 보류 준비 상태를 지나 준비 상태로 이동한다.Process schedulercpu 스케줄러는 프로세스의 모든 상태 변화를 조정한다.목적은 찾아보자스케줄링 단계스케줄링은 3단계로 나뉜다.고수준 스케줄링저수준 스케줄링중간 수준 스케줄링High level scheduling작업 스케줄링 ( job )이라고도 부른다. 전체 작업 수를 조절한다.작업은 os의 가장 큰 일의 단위로 하나 혹은 여러 개의 프로세스로 이루어진다.작업이 시작되면 자원이 소모되기에 기존 작업에 영향이 간다.이에 작업을 승인할지 거부할지 결정한다.Admission scheduling 승인 스케줄링이라고도 부른다.동시에 실행 가능한 프로세스의 총 개수가 정해진다.Middle level schedulingsuspend와 active로 활성화된 프로세스 수를 조절한다.일부 프로세스를 suspend 상태로 돌려 나머지가 원활하게 만든다.고수준과 저수준 스케줄링 사이의 버퍼 역할Low level schedulingcpu에 프로세스를 배당하는 작업을 한다.빠르게 작동하여 short-term scheduling 이라도 부른다.Preemptive &amp; Non preemptive scheduling선점형 스케줄링운영체제가 강제로 cpu를 뺏을 수 있다.비 선점형 스케줄링운영체제가 강제로 뺏을 수 없다.Preemptive선점형 스케줄링은 인터럽트처럼 cpu를 뺏을 수 있다.문맥 교환 같은 낭비가 생긴다.시분할 시스템에 사용된다.사실상 대부분Non preemptive한 프로세스가 실행 상태에 들어가면 프로세스가 멈추지 않으면, cpu를 뺏을 수 없다.스케줄링이나 문맥 교환의 오버헤드가 낮다.다만 전체 시스템의 처리율이 떨어진다.과거 일괄 작업 시스템에서 사용되었다.Priority프로세스는 큐로 관리된다.이때 우선순위와 그 척도가 필요하다.기본적으로 커널 프로세스가 일반 프로세스보다 우선순위가 높다.임의로 사용자가 지정할 수 있다.전면 프로세스가 후면 프로세스보다 우선순위가 보통 높다.입출력 집중 프로세스가 cpu 집중 프로세스보다 보통 높다.입출력 집중 프로세스는 cpu를 잠깐 쓰고 넘기기 때문이다.Queuecpu 사용하는 프로세스들pcb를 연결한 큐가 있다.이때 우선순위에 따라 여러 큐를 만들어 multiple queue로 관리된다.모두 검색하는 오버헤드를 줄임이때 bitmap 배열을 이용해서 해당 우선순위의 큐가 pcb(task)를 가지고 있는지 확인한다.만약 1이라면 해당 큐를 순회하며 cpu를 할당한다.프로세스가 time slice를 모두 소모하면 expired array로 넘어간다.해당 우선순위에 맞게active array가 사용이 다 되면 expired 에 time slice를 배정하고 active array로 바꾼다.대기 상태의 프로세스들위에서 설명한 큐는 실행 상태를 다룬다.대기 상태의 프로세스도 큐를 가지고 있다.대기 상태 다단계 큐는 같은 입출력 장치끼리 모아 놓는다.입출력이 동시에 끝나면 여러 인터럽트가 한번에 처리된다.이를 위해 인터럽트 벡터를 사용하며 입출력이 완료된 pcb 들은 준비 상태로 이동한다.정리Scheduling algorithm스케줄링 알고리즘을 알아보자.종류구분종류비선점형FCFS, SJF, HRN선점형라운드 로빈, SRT, 다단계 큐, 다단계 피드백 큐둘 다 가능우선순위 스케줄링성능 기준대기 시간 : 프로세스 생성 후 실행까지 걸린 시간응답 시간 : 첫 작업을 시작한 후 첫 번째 반응까지 걸린 시간실행 시간 : 프로세스 작업이 시작된 후 종료되기까지 시간반환 시간 : 대기 시간을 포함하여 실행이 종료될 때까지의 시간기준보통 스케줄링 알고리즘 성능 비교에는 평균 대기 시간을 사용한다.모든 프로세스들이 실행되기까지 걸린 대기 시간의 평균다만 순서나 작업 패턴에 따라 역전되기도 한다.FCFS비선점형 방식first come first served선입선출 스케줄링큐가 하나라 모든 프로세스는 우선순위가 동일하다.즉 하나씩 순서대로 실행된다.일괄 작업 시스템단점convoy effect입출력 요청시 cpu가 놀게됨SJF비선점형 방식shortest job firstshortest process first, 최단 프로세스 우선 스케줄링실행 시간이 가장 짧은 작업부터 cpu를 할당convoy 효과를 완화함단점운영체제가 프로세스의 종료 시간을 정확히 예측하기 어렵다.즉 프로세스의 작업 길이를 알아야 스케줄을 하는데 길이를 모른다.현대 프로세스는 사용자와의 상호작용이 빈번하기 때문이다.고로 적용하기 어렵다.공평하지 않다.starvationinfinite blocking이를 완화하기 위한 방법으로 aging이 있으나 기준 선정의 한계가 있다.HRN비선점형highest response ratio nextSJF의 아사 현상을 해결하기 위한 알고리즘이다.HRN은 서비스를 받기 위해 기다린 시간과 cpu 사용 시간을 고려하여 스케줄링한다.즉 대기 시간을 고려해 아사를 완화한다.스케줄링에 에이징을 구현한 것우선순위=대기&nbsp;시간&nbsp;+&nbsp;CPU&nbsp;사용&nbsp;시간&nbsp;CPU&nbsp;사용시간&nbsp;\\text{우선순위} ={ \\text{대기 시간 + CPU 사용 시간 } \\over \\text{CPU 사용시간 }}우선순위=CPU&nbsp;사용시간&nbsp;대기&nbsp;시간&nbsp;+&nbsp;CPU&nbsp;사용&nbsp;시간&nbsp;​단점여전히 공평성이 위배되어 많이 사용되지 않는다.RR선점형 알고리즘 중 가장 단순하고 대표적인 방식round robin한 프로세스가 할당 받은 시간 동안만 작업하고 큐의 맨 뒤로 보내지는 알고리즘완료 될 때까지 계속 순환FCFS와 차이점은 time slice가 있다는 것이다.이는 convoy 효과를 완화한다.유의점문맥 교환에 대한 오버헤드를 생각해야 한다.이에 타임 슬라이스의 크기가 중요하다.타임 슬라이스가 너무 크면 FCFS와 다르지 않다.타임 슬라이스가 너무 작으면 문맥 교환 오버헤드가 커진다.SRTshortest remaining time최소 잔류 시간 우선 스케줄링SJF와 RR을 혼합한 방법기본적으로 RR 이다.다만 작업 시간이 가장 적은 프로세스를 선택하여 cpu를 할당한다.단점실행중인 프로세스와 큐의 프로세스들의 시간을 주기적으로 계산해야한다.문맥 교환 오버헤드프로세스의 종료 시간 예측 어려움, 아사 현상잘 안쓰임Priority중요도를 기준으로 우선 순위를 반영해 스케줄링한다.단점공평성 위배와 아사 현상MLQMultiLevel Queue Scheduling 다단계 큐 스케줄링우선 순위에 따라 준비 큐를 여러 개 사용하는 방식고정형 우선순위를 사용한다.프로세스가 시간을 소모하면 원래 큐로 돌아간다.상단의 큐의 모든 프로세스의 작업이 끝나야 다음 큐의 작업이 실행된다.선점형 방식으로 우선순위가 높은 프로세스가 먼저 작동한다.만약 하위 큐의 프로세스 진행 중 상위 단계 큐에 프로세스가 도착하면 뺏어버림각각의 큐에 대한 다른 스케줄링 알고리즘 적용가능하다.큐의 우선순위에 따라 타임 슬라이스를 조절할 수 있다.단점우선 순위가 높은 큐가 완료되어야 다음 큐가 실행된다.기아 현상MFQmultilevel feedback queue우선순위가 낮은 프로세스들의 문제를 보완한 방식cpu를 사용한 프로세스는 우선순위가 한 단계 낮아진다.즉 다음 단계 큐로 들어간다.우선순위에 따라 큐의 타임 슬라이스가 다르다.낮은 순위는 cpu를 얻을 확률이 상대적으로 낮다.그래서 오래 사용하도록 타임 슬라이스를 크게 만들어준다.마지막 큐의 타임 슬라이스는 무한대의 타임 슬라이스를 가지며 이는 FCFS 로 동작하는 것과 같다.MFQ는 오늘날의 운영체제가 사용하는 방식이다. 변동 우선순위 알고리즘의 전형적인 예이다.물론 커널 프로세스는 일반 프로세스의 큐로 삽입되지 않는다.룰짧은 작업에 우선권이 있다.입출력 관련 프로세스에 우선권을 준다." }, { "title": "Optimization", "url": "/posts/optimization/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-07-14 16:25:00 +0900", "snippet": "Problem목적은 loss, error function을 최소화하는 θ\\thetaθ값을 구하는 것이다.Gradient Descent간단한 정리역전파에서 간단히 다루었다.최적화 기법에서 가장 기본적이고 중요한 방법이다.제약 조건이 없는 convex, differentiable한 함수의 최적화 문제의 해결책이다.기준을 만족할 때까지 다음 식을 반복한다.xk+1=xk−tk∇f(xk) x^{k+1} = x^{k} - t_k\\nabla f(x^k)xk+1=xk−tk​∇f(xk)fff는 error function이다.Interpretation모두를 위한 컨벡스 최적화 참고gradient descent는 함수를 2차 식으로 근사한 뒤, 그 함수의 최소 위치를 다음 위치로 선택하는 방법이다.fff를 2차 Taylor로 전개한다.f(y)≈f(x)+∇f(x)⊤(y−x)+12∇2f(x)∣∣y−x∣∣22f(y) \\approx f(x) + \\nabla f(x)^\\top(y-x)+{1\\over2}\\nabla^2f(x) ||y-x||_2^2f(y)≈f(x)+∇f(x)⊤(y−x)+21​∇2f(x)∣∣y−x∣∣22​헤시안을 1t1\\over tt1​로 대체한다.t = step sizef(y)≈f(x)+∇f(x)⊤(y−x)+12t∣∣y−x∣∣22f(y) \\approx f(x) + \\nabla f(x)^\\top(y-x)+{1\\over2t}||y-x||_2^2f(y)≈f(x)+∇f(x)⊤(y−x)+2t1​∣∣y−x∣∣22​이때 12t∣∣y−x∣∣22{1\\over2t}||y-x||_2^22t1​∣∣y−x∣∣22​ 항은 x 에 대한 proximity term 이다.앞 식은 선형 근사로 볼 수 있다.proximity term은 얼마나 가까운가를 나타낸다.즉 현재 x 에서 크게 벗어나지 않도록 제한한다.이 식의 최소 값을 구한다. 이는 다음의 x값이 된다.xk+1=arg min⁡yf(xk)+∇f(xk)⊤(y−xk)+12t∣∣y−xk∣∣22x^{k+1} = \\argmin_y f(x^k) + \\nabla f(x^k)^\\top(y-x^k)+{1\\over2t}||y-x^k||_2^2xk+1=yargmin​f(xk)+∇f(xk)⊤(y−xk)+2t1​∣∣y−xk∣∣22​Stochastic Gradient Descent앞선 gradient descent방법으로 이야기해보자.에러 함수는 오차의 합으로 구성된 함수의 합이다.이를 gradient descent로 풀어내려면 함수들의 gradient를 합산하여 구한다.이후 업데이트한다.모두를 위한 컨벡스 최적화 참고x(k)=x(k−1)−tk⋅∑i=1m∇fi(x(k−1)), k=1,2,3,…x^{(k)} = x^{(k-1)} - t_k \\cdot \\sum_{i=1}^{m} \\nabla f_i (x^{(k-1)}), \\, k=1,2,3,\\dotsx(k)=x(k−1)−tk​⋅i=1∑m​∇fi​(x(k−1)),k=1,2,3,…그러나 이 방법에는 문제점이 있다.모든 데이터를 가지고 gradient를 구하는 것은 문제가 된다.요즘에는 거대한 데이터를 인풋으로 사용한다. 메모리에 올라가기도 힘들다.즉 계산 오버헤드가 크게 증가한다.gradient descent를 batch update라고 부른다.이를 해결하기 위해 다음과 같은 방식이 제안된다.Mini-Batch gradient descent이름 그대로 스텝이 진행될 때 모든 배치를 사용하지 않는다.두가지 방법으로 나눌 수 있다.mini-batch작은 개수의 샘플을 이용한다. ( 128, 256 …)stochastic gradient1개의 샘플만 이용한다.사실상 크게 이름을 구분하지 않고 혼용해서 쓴다.https://towardsdatascience.com/gradient-descent-algorithm-and-its-variants-10f652806a3Challengesstep size를 결정하는데 어려움이 있다.작다면 너무 느려진다.크다면 빠르나 끝에 가서 크게 요동친다.fluctuation in the object functionlearning rate를 스케줄 한다.처음에는 크게, 나중에는 작게local minima 나 saddle points에 걸리면 나오기 힘들다.Exponentially Weighted Moving Average기본 식전 스텝의 값과 새로운 값의 convex sum이다.vt=βvt−1+(1−β)θt\\bold v_t = \\beta \\bold v_{t-1} + (1-\\beta) \\theta_tvt​=βvt−1​+(1−β)θt​β\\betaβ 는 하이퍼 파라미터 (0 ~ 1)vt−1\\bold v_{t-1}vt−1​은 이전 Moving averageθ\\thetaθ는 현재 구해진 값정리v0\\bold v_0v0​부터 진행해보자.v1=βv0+(1−β)θ1=(1−β)θ1\\bold v_1 = \\beta \\bold v_{0} + (1-\\beta) \\theta_1 \\\\ = (1-\\beta) \\theta_1v1​=βv0​+(1−β)θ1​=(1−β)θ1​v2=βv1+(1−β)θ2=β(1−β)+(1−β)θ2=(1−β)(βθ1+θ2)\\bold v_2 = \\beta \\bold v_{1} + (1-\\beta) \\theta_2 \\\\ = \\beta (1-\\beta) + (1-\\beta) \\theta_2 \\\\ = (1-\\beta)(\\beta \\theta_1+\\theta_2)v2​=βv1​+(1−β)θ2​=β(1−β)+(1−β)θ2​=(1−β)(βθ1​+θ2​)계속 진행하면 다음과 같은 식으로 정리 가능하다.vt=(1−β)(βt−1θ1+βt−2θ1+⋯+θt)\\bold v_t = (1-\\beta)(\\beta ^{t-1}\\theta_1 +\\beta ^{t-2}\\theta_1 + \\cdots + \\theta_t )vt​=(1−β)(βt−1θ1​+βt−2θ1​+⋯+θt​)11−β1\\over{1-\\beta}1−β1​ 개의 샘플을 이용한 평균의 근사 값이다.오래된 데이터는 제곱 값이 매우 작아져 값이 빠르게 작아진다.Exponential decayBias Correction초기 값이 0부터 시작되어 bias가 발생한다.vt1−βt\\bold v_t \\over 1-\\beta^t1−βtvt​​를 vt\\bold v_tvt​대신 사용한다.자세한 설명 참고이 방법을 gradient descent에 적용한 것이 모멘텀이다.Momentumgradient의 moving avg를 이용해서 업데이트함vt+1=βvt+(1−β)[∇J(θt)]\\bold v_{t+1} = \\beta \\bold v_t + (1-\\beta)[\\nabla \\mathcal J(\\theta_t)]vt+1​=βvt​+(1−β)[∇J(θt​)]θt+1=θt−αvt+1\\theta_{t+1} = \\theta_t - \\alpha\\bold v_{t+1}θt+1​=θt​−αvt+1​이전 세대의 gradient값이 같은 방향을 계속 가르키면 가속화된다.장점모멘텀 최적화가 경사 하강법보다 빠르다.빠르게 평편한 지역을 탈출하게 만든다.지역 최적점을 건너 뛰는데 효과가 있다.안정되기 전까지 모멘텀 때문에 진동을 하기 때문이다.핸즈온 머신러닝 p.436RMSPropgradient 값의 제곱에 moving avg를 적용함RMSProp = Rprop + SGDadaptive individual learning rate for each weightalgorithmrt+1=βrt+(1−β)[∇J(θt)]2&nbsp;&nbsp;&nbsp;&nbsp;(element-wise&nbsp;square)\\bold r_{t+1} = \\beta \\bold r_t + (1-\\beta)[\\nabla \\mathcal J(\\theta_t)]^2 \\ \\ \\ \\ \\text{(element-wise square)}rt+1​=βrt​+(1−β)[∇J(θt​)]2&nbsp;&nbsp;&nbsp;&nbsp;(element-wise&nbsp;square)vt+1=∇J(θt)rt+1+ε&nbsp;&nbsp;&nbsp;&nbsp;(element-wise&nbsp;division)\\bold v_{t+1} = {\\nabla \\mathcal J(\\theta_t) \\over \\sqrt{ \\bold r_{t+1}+\\varepsilon}} \\ \\ \\ \\ \\text{(element-wise division)}vt+1​=rt+1​+ε​∇J(θt​)​&nbsp;&nbsp;&nbsp;&nbsp;(element-wise&nbsp;division)θt+1=θt−αvt+1\\theta_{t+1} = \\theta_t - \\alpha\\bold v_{t+1}θt+1​=θt​−αvt+1​만약에 gradient 값이 크면, 그만큼 나눠져서 값이 작아짐learning rate 값이 낮아지는 효과정리지수 가중 평균을 이용 -&gt; 경향성 반영루트로 나누어 학습에 제약을 둠 -&gt; adaptive learning rate불필요한 진동 감소 및 Gradient Exploding 막음ADAMADAM = momentum + bias correction + RMSPropadaptive 스텝 사이즈, 크기algorithmvt+1=βvt+(1−β)[∇J(θt)]\\bold v_{t+1} = \\beta \\bold v_t + (1-\\beta)[\\nabla \\mathcal J(\\theta_t)]vt+1​=βvt​+(1−β)[∇J(θt​)]rt+1=βrt+(1−β)[∇J(θt)]2&nbsp;&nbsp;&nbsp;&nbsp;(element-wise&nbsp;square)\\bold r_{t+1} = \\beta \\bold r_t + (1-\\beta)[\\nabla \\mathcal J(\\theta_t)]^2 \\ \\ \\ \\ \\text{(element-wise square)}rt+1​=βrt​+(1−β)[∇J(θt​)]2&nbsp;&nbsp;&nbsp;&nbsp;(element-wise&nbsp;square)vtbc=t1−β1t&nbsp;&nbsp;&nbsp;&nbsp;(bias&nbsp;correction)\\bold v_t^{bc} = {\\bold t \\over 1-\\beta_1^t} \\ \\ \\ \\ \\text{(bias correction)}vtbc​=1−β1t​t​&nbsp;&nbsp;&nbsp;&nbsp;(bias&nbsp;correction)rtbc=r1−β2t&nbsp;&nbsp;&nbsp;&nbsp;(bias&nbsp;correction)\\bold r_t^{bc} = {\\bold r \\over 1-\\beta_2^t} \\ \\ \\ \\ \\text{(bias correction)}rtbc​=1−β2t​r​&nbsp;&nbsp;&nbsp;&nbsp;(bias&nbsp;correction)θt+1=θt−αvtbcrtbc\\theta_{t+1} = \\theta_{t} - \\alpha{\\bold v_t^{bc} \\over \\sqrt{\\bold r_t^{bc}}}θt+1​=θt​−αrtbc​​vtbc​​여기서 αrtbc\\alpha \\over \\sqrt{\\bold r_t^{bc}}rtbc​​α​ 값이 adaptive learning rate이다.α\\alphaα 값은 상수정리adam은 가장 많이 사용되고 있는 옵티마이저이다.성능 또한 좋다.하이퍼 파라미터 지정에 대한 부담이 적다. -&gt; adaptive 특성중간 중간 빠진 옵티마이저는 다음 그림을 통해 살펴보자.Learning Rate Decaystep size를 step마다 줄여줌1 epoch는 한번 학습된 것이다. ( batch라면 전체 데이터를 한번 트레이닝함 )μ\\muμ = decay rate, Ω\\OmegaΩ =epoch num여러 방법들α=11+μΩα0\\alpha = {1\\over1+\\mu\\Omega}\\alpha_0α=1+μΩ1​α0​α=0.95Ωα0\\alpha = 0.95^\\Omega\\alpha_0α=0.95Ωα0​α=kΩα0\\alpha ={ k\\over \\sqrt{\\Omega}}\\alpha_0α=Ω​k​α0​α=ktα0\\alpha ={ k\\over \\sqrt{t}}\\alpha_0α=t​k​α0​" }, { "title": "Thread", "url": "/posts/thread/", "categories": "CS, OS", "tags": "os, cs, summer", "date": "2022-07-12 22:55:00 +0900", "snippet": "PCBConsistsPCB는 다음과 같이 c의 struct으로 만들어져 있다.6개로 나눌 수 있다.task basic infofiles : 프로세스가 오픈한 파일들의 정보fs : 접근중인 파일 정보tty : 사용중인 터미널 정보mm : 사용중인 메인 메모리 정보signalsPCB 구조체에서는 포인터를 이용해서 이들을 6조각으로 나누어 관리한다.보통 포인터를 사용하는 것은 overhead 문제이다.Reduce PCB Overheadfork를 하는 과정에서 모든 PCB를 복사하는 것은 생각보다 오버헤드가 크다.read &amp; writefiles, fs, tty, mm, signals 정보는 부모와 다르게 사용되지 않는다.어차피 같은 거면 포인터를 이용해 공유하자!Linux thread위에서 thread가 사용되었다. thread는 무엇일까?다음과 같이 PCB를 공유하는 자식이지만 모든 PCB를 복사하지 않는 프로세스 상태를 이야기한다.이때는\t clone 이라는 시스템 콜이 사용된다.비트를 이용해 복사할 정보를 고를 수 있다.clone의 설명은 다음을 참고하자. man clone여담으로 fork나 clone이나 do_fork로 작동된다 한다.http://rousalome.egloos.com/9984825Image overheadPCB를 복사하는 것 말고도 이미지를 복사할 때 오버헤드가 발생한다.왜 exec으로 코드를 밀어 버릴꺼면 굳이 fork를 사용할까?이전에는 실제로 그냥 복사하고 밀었었다.이를 막기위해 page table만 복사하기 시작했다.그리고 만약 메모리에 write를 한다면 그제서야 그 페이지 부분만 copy 한다.이를 copy on write라고 한다.하지만 이 방법에는 문제가 있었다.부모에서 자식으로 넘어가기전 어떤 작업 특히 write를 하게된다면 복사 이전의 메모리 정보가 달라지는 문제가 있다.즉 자식은 이전 상태에서 복사 되었는데(실제 복사는 안됐지만 이론적으로) 자식이 메모리에 접근하기 전 부모에서 메모리를 수정함그래서 이를 막기 위해 cow작업이 진행된다.허나 자식은 대부분 exec을 진행하기에 의미가 없는 작업이 된다.해결책그래서 리눅스에서는 이를 해결하기 위해서 fork가 발생하면 바로 cpu를 자식이 먼저 실행되도록 넘겨버린다.문제점하지만! 현재는 리눅스에서 실행하면 부모가 먼저 실행된다.직접 코딩해서 확인해보자.이 부분에 대해 여러 글을 뒤졌지만 완벽한 이유를 찾지 못했다. 뭔가 바뀌긴 했다.https://stackoverflow.com/questions/8494732/who-executes-first-after-fork-parent-or-the-child이 글의 마지막 답글을 보면 힌트가 있다.아마도 기본적으로 부모가 실행되고 자식이 실행된다고 생각하기 때문에 이런 직관과 충돌하여 여러 오류를 내는 것 같다.https://karatus.tistory.com/m/189관련해 정리가 잘된 블로그이다. 하지만 나는 정확한 이유는 이해하지 못했다.리눅스 쓰레드 모델의 진화아직은 완벽히 이해하지 못했으나 미래를 위해 삽질한 걸 남겨둔다.쓰레드 탄생프로세스는 운영체제가 설계될 당시 만들어졌지만 쓰레드는 한참 뒤에 만들어진다.초기에는 작업의 단위가 프로세스 하나였다.이후 cpu가 발전하며, 여러 코어를 가진 cpu가 멀티쓰레드를 지원하기 시작했다.그래서 프로세스를 쪼개어 코어에 배분할 필요가 생겼다.레벨쓰레드는 유저레벨 쓰레드와 커널 레벨 쓰레드가 존재한다.유저 레벨운영체제가 멀티쓰레드를 지원하지 않을 때 사용함, 초기 쓰레드 시스템라이브러리를 통해 구현됨커널 쓰레드와 사용자 쓰레드가 1대 N으로 연결된다.커널 레벨커널이 멀티쓰레드를 지원함1대 1로 연결된다.멀티 레벨M대 N으로 연결된다.Linux Thread history다음 글을 읽어보자.https://dataonair.or.kr/db-tech-reference/d-lounge/technical-data/?mod=document&amp;uid=237711https://en.wikipedia.org/wiki/Native_POSIX_Thread_Library리눅스 버전 https://elixir.bootlin.com/2.6 버전으로 크게 바뀐 것 같다.2.6.0 버전에는 남아있었다.2.6.9.rc2 버전에서 사라졌다!" }, { "title": "Backpropagation", "url": "/posts/back/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-07-11 20:40:00 +0900", "snippet": "BackpropagationGradient Descent최적화 기법에서 가장 기본적이고 중요한 방법이다.제약 조건이 없는 convex, differentiable한 함수의 최적화 문제의 해결책이다.기준을 만족할 때까지 다음 식을 반복한다.xk+1=xk−tk∇f(xk) x^{k+1} = x^{k} - t_k\\nabla f(x^k)xk+1=xk−tk​∇f(xk)fff는 error function이다.문제점출력 층과 바로 그 전 은닉층은 직접적인 관계가 있다.하지만 다른 은닉층들의 www값과의 관계는 쉽게 구할 수 없다.즉 업데이트를 하기 어렵다.많은 연구자들은 다층 퍼셉트론을 훈련할 방법을 찾기위해 오랫동안 연구했다. 그러나 성공하지 못했다.1986년 루멜하트, 힌턴, 윌리엄스가 역전파 훈련 알고리즘을 소개했다.1985 Learning internal Representations by Error Propagation1986 Learning representations by back-propagating errors / nature자동 미분 : 자동으로 그레디언트를 계산하는 것역전파에서는 후진 모드 자동 미분을 사용한다.이는 미분할 함수가 변수가 많고 출력이 적은 경우 잘 맞는다.Backpropagation알고리즘은 간단하다.정방향 계산을 한다.forward pass오차 측정 값을 구한다.각 출력 연결이 오차에 기여하는 정도를 계산한다. (역방향 계산)연쇄 법칙이 이용된다.모든 연결 가중치에 대한 오차 그레디언트를 구하면 모든 연결 가중치를 업데이트한다. ( 경사 하강법 )역방향 계산각 가중치들이 오차 값에 영향을 미치는 정도를 구하기 위해서는 변화율을 구하면 된다.∂E∂wn\\partial E\\over \\partial w_n∂wn​∂E​하지만 출력 층으로부터 멀리 떨어진 가중치의 오차 함수에 대한 변화율을 구하기는 어렵다.이를 해결하는 방법은 연쇄법칙이다.돌아오면서 뒤로 전해진 변화율에 해당 노드에서의 변화율을 곱해주면 된다.이를 그래프를 이용해 적용해보자.Computational Graphs다음과 같은 상황의 역방향 계산을 진행해보자.f(w,x)=11+e−(w1x1+w2x2+w0)f(w,x) = {1\\over1+e^{-(w_1x_1+w_2x_2+w_0)}}f(w,x)=1+e−(w1​x1​+w2​x2​+w0​)1​다음과 같이 계산 할 수 있다.파랑 -&gt; 정방향빨강 -&gt; 역방향곱셈 관계에서는 역방향 계산시 가중치를 바꿔서 곱해준다.단순 덧셈은 그대로 지나간다.나머지는 차근하게 미분을 해보면 이해할 수 있다.만약 x1노드가 다른 노드에도 연결되었다면, 값은 들어온 값들의 평균으로 정해진다.참고 https://www.youtube.com/watch?v=tIeHLnjs5U8Application핸즈온 머신러닝 2판 p.366 설명 참고회귀 MLP의 전형적인 구조하이퍼 파라미터일반적인 값입력 뉴런 수특성마다 하나은닉층 수문제에 따라 다름, 일반적으로 1~5사이은닉층의 뉴런 수문제에 따라 다름, 일반적으로 10에서 100사이출력 뉴런 수예측 차원마다 하나은닉층의 활성화 함수ReLU 또는 SeLU출력층의 활성화 함수없음, 양수이면 ReLU/sorfplus, 범위 제한 목적이면 Logistic/tanh손실 함수MSE, 이상치 있다면 MAE, Huber분류 MLP의 전형적인 구조하이퍼파라미터이진분류다중 레이블 분류다중 분류입력층과 은닉층회귀와 동일회귀와 동일회귀와 동일출력 뉴런 수1개레이블마다 1개클래스마다 1개출력층의 활성화 함수로지스틱 함수로지스틱 함수소프트맥스 함수손실 함수크로스 엔트로피크로스 엔트로피크로스 엔트로피" }, { "title": "MLP", "url": "/posts/multiple/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-07-11 13:55:00 +0900", "snippet": "Multi-Layer Perceptron (MLP)XOR 문제앞서 이야기했던 XOR문제를 어떻게 풀어야 할까?해답은 그림 그대로 선을 하나 더 긋는 것이다.두 직선 안과 밖으로 나눌 수 있게 된다.이를 신경망으로 다음과 같이 나타낼 수 있다.이를 이용해 xor 문제를 풀어보면xor문제를 해결할 수 있다.Nand, Or 방법으로 풀수도 있다.초록색을 기준으로 나누고, 파란색으로 나누고다시 이를 조합해 나눈다.다층 퍼셉트론MLP는 입력층과 1개 이상의 은닉층, 출력층으로 구성된다.MLP는 은닉층을 이용해서 단순 선형 분류 문제가 아닌 고차원의 문제도 풀 수 있다.차원을 비튼다는 느낌이 있다. 위 xor문제도 평면을 접어 푼다고 생각 할 수 있다.hidden layer를 적용하는 방법의 이해를 시각적으로 할 수 있다.Linear Model vs Neural Network선형 모델은 다음과 같다.y=w1ϕ1(x)+w2ϕ2(x)+…y = w_1\\phi_1(x)+w_2\\phi_2(x) + \\dotsy=w1​ϕ1​(x)+w2​ϕ2​(x)+…뉴럴 네트워크 모델은 다음과 같다.은닉층 1개y=v1ϕ1(w1⊤x)+v2ϕ2(w2⊤x)+…y = v_1\\phi_1(\\bold w_1^\\top x) + v_2\\phi_2(\\bold w_2^\\top x) + \\dotsy=v1​ϕ1​(w1⊤​x)+v2​ϕ2​(w2⊤​x)+…vvv 값은 은닉층의 가중치이다.두 모델의 차이점은 다음과 같다.선형 모델 : Basis fixed뉴럴 모델 : Adaptive basis즉 선형 모델은 basis fuction이 고정되어 있지만뉴럴 모델은 은닉층을 통과하면서 basis function이 바뀌게 된다.Activation Functions사용 이유활성화 함수를 이용해 선형성을 비 선형으로 꼬아준다.만약 이 작업이 없다면 하나의 큰 선형 모델과 다르지 않다.즉 층 사이에 비 선형성을 넣어주지 않으면, 아무리 층이 깊어도 하나의 층과 다르지 않다.비 선형 활성화 함수가 있는 심층 신경망은 어떤 연속 함수도 근사 가능하다.ReLU장점많이 사용된다.compute cost가 적다.Converges fasterSparsely activated단점Dying ReLU : 특정 뉴런이 죽어버린다.음의 값은 항상 0으로 출력해버리는 문제ReLU에서 0 점인 경우는 Sub Gradient를 사용해야 한다.not differentiable" }, { "title": "Perceptron", "url": "/posts/perceptrons/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-07-09 23:45:00 +0900", "snippet": "Artificial Neuron매컬러와 피츠가 제안한 매우 단순한 신경망 모델입력이 일정 개수만큼 활성화되면 출력을 내보냄논문에서 어떤 논리 명제도 계산할 수 있다는 것을 증명함MCP뉴런이라 부른다.뉴런은 행렬 계산의 일부이다. 특별하거나 심오한걸로 생각하지 말자.Perceptron1957년 로젠블라트(Frank Rosenblatt)가 제안TLU : threshold logic unit, LTU : linear threshold unit이라 불리는 형태의 인공 뉴런 기반입력과 출력이 이진이 아닌 숫자이다.작동 과정입력의 가중치 합을 계산z=w1x1+w2x2+⋯+wnxn=w⊤xz = w_1 x_1+w_2x_2+ \\dots+ w_nx_n =\\bold w^\\top \\bold xz=w1​x1​+w2​x2​+⋯+wn​xn​=w⊤x계단 함수 ( step function )을 적용헤비사이드 계단 함수heaviside(z)={0z&lt;01z≥0\\text{heaviside}(z) =\\begin{cases}0 &amp; z &lt; 0\\\\1 &amp; z \\ge 0\\end{cases}heaviside(z)={01​z&lt;0z≥0​부호 함수sgn(z)={−1z&lt;00z=0+1z&gt;0\\text{sgn(z)} = \\begin{cases} -1 &amp; z &lt; 0 \\\\0 &amp; z = 0 \\\\+1 &amp; z &gt; 0\\end{cases}sgn(z)=⎩⎨⎧​−10+1​z&lt;0z=0z&gt;0​출력계단 함수는 TLU인 경우의 활성화 함수이다 .행렬을 이용한 수식 계산y=ϕ(w⊤x+b)y = \\phi(\\bold w^\\top\\bold x + b )y=ϕ(w⊤x+b)ϕ\\phiϕ는 활성화 함수Linearly Separable선형적으로 분류가 가능한 패턴은 linear hyperplane을 통해 나누어질 수 있다.로젠블라트는 퍼셉트론 알고리즘으로 선형 분류 문제를 해결할 수 있음을 증명했다.Perceptron convergence theoremPerceptron Criterion분류를 잘 했다면 아래의 식이 성립한다.예측 값이 양수이면 yyy 또한 1이고 음수이면 yyy 값이 -1이기 때문이다.w⊤xnyn&gt;0&nbsp;&nbsp;∀xn\\bold w ^\\top\\bold x_n \\bold y_n &gt; 0 \\ \\ \\forall \\bold x_nw⊤xn​yn​&gt;0&nbsp;&nbsp;∀xn​object functionperceptron criterion은 다음과 같은 목적 함수를 유도한다.E(w)=−∑xn∈Mw⊤xnyn\\mathcal E(w) = -\\sum_{x_n \\in \\mathcal M}\\bold w^\\top \\bold x_ny_nE(w)=−xn​∈M∑​w⊤xn​yn​이때 M\\mathcal MM은 misclassified된 xn\\bold x_nxn​의 set이다.misclassified 되면 w⊤xnyn\\bold w ^\\top\\bold x_n \\bold y_nw⊤xn​yn​값이 음수이다.즉 위 목적 함수의 값을 최소화하는 것이 학습 목표가 된다.그레디언트를 구하자.∂E∂w=−∑xn∈Mxnyn{\\partial \\mathcal E \\over \\partial w} = - \\sum_{x_n \\in \\mathcal M} \\bold x_n y_n∂w∂E​=−xn​∈M∑​xn​yn​Learning다음과 같이 www를 업데이트 할 수 있다.Δw=α∑xn∈Mxnyn\\Delta \\bold w = \\alpha \\sum_{x_n \\in \\mathcal M} \\bold x_n y_nΔw=αxn​∈M∑​xn​yn​Algorithm outlinetraining sample을 준비한다.misclassified를 찾는다.2.1. correctly하면 넘어간다 .2.2. incorrectly하면 www를 업데이트 한다.wk+1=wk+αxnyn\\bold w_{k+1} = w_{k} + \\alpha \\bold x_ny_nwk+1​=wk​+αxn​yn​수렴할 때까지1, 2를 반복한다.Logistic regression차이점이 뭘까?단일 퍼셉트론은 로지스틱 회귀와 크게 다른 점이 없다.다만 결과에 있어 차이점이 있다.로지스틱 회귀는 클래스의 확률을 제공한다.다만 퍼셉트론은 고정된 임계 값을 기준으로 예측 값을 만든다.LimitXOR만약 데이터가 선형적으로 분류 가능하면 유한한 시도 안에 수렴하는 hyperplane을 구할 수 있다.그러나 선형적으로 분류 가능하지 않은 문제에서는 한계가 있었다.1969년 “Perceptrons:An Introduction to Computational Geometry”, Minsky and Papert 에서 단순한 배타적 논리합 분류 문제를 풀 수 없는 것을 증명했다.이후 첫 ai winter가 찾아온다…아래 사진처럼 xor문제를 푸는 초평면을 구할 수 없다." }, { "title": "Loss & Cost Function", "url": "/posts/loss/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-07-09 10:30:00 +0900", "snippet": "손실함수와 비용함수개념Loss function은 모델이 실제 값과 어느 정도 차이가 나는지 수치화하는 함수이다.차이를 손실이라 부른다.Cost function은 Loss function과 달리 데이터 셋 전체를 대상으로 손실을 구한다.Loss function은 특정 데이터에 대해 손실을 구한다.L1 손실함수L1&nbsp;Loss=∑∣ytrue−ypredict∣\\text{L1 Loss} = \\sum |y_\\text{true}-y_\\text{predict}|L1&nbsp;Loss=∑∣ytrue​−ypredict​∣실제 값과 예측 값의 차이의 기대 값이다.관련 비용함수는 Mean Absolute Error가 있다.MAE=1n∑n=1n∣yi−y^i∣\\text{MAE} = {1\\over n} \\sum_{n=1}^n |y_\\text{i}- \\hat y_\\text{i}|MAE=n1​n=1∑n​∣yi​−y^​i​∣L2 손실함수L2&nbsp;Loss=∑(ytrue−ypredict)2\\text{L2 Loss} = \\sum (y_\\text{true}-y_\\text{predict})^2L2&nbsp;Loss=∑(ytrue​−ypredict​)2실제 값과 예측 값의 차이의 제곱의 기대 값이다.관련 비용함수는 Mean Squared Error, Root Mean Squared Error가 있다.MSE=1n∑(yi−y^i)2\\text{MSE} = {1\\over n} \\sum (y_\\text{i}-\\hat y_\\text{i})^2MSE=n1​∑(yi​−y^​i​)2RMSE=MSE\\text{RMSE} = \\sqrt \\text{MSE}RMSE=MSE​MSE는 제곱으로 인해 이상치에 민감하다.MAE, RMSE는 이상치와 상관없이 안정된 값을 보여준다.엔트로피정보 이론에서 사용되는 개념이다.확률 변수의 불확실성 정도를 측정하기 위해 사용된다.엔트로피의사 결정 트리에서 사용됨Entropy(P)=−∑P(x)logP(x)=−E(logP(x))\\text{Entropy}(P) = - \\sum P(x)log P(x) = -E(logP(x))Entropy(P)=−∑P(x)logP(x)=−E(logP(x))크로스-엔트로피다중 분류에서 사용된다.CrossEntropy(P,Q)=−∑P(x)logQ(x)=−Ep(logQ(x))\\text{CrossEntropy}(P,Q) = -\\sum P(x)logQ(x) = -E_p(logQ(x))CrossEntropy(P,Q)=−∑P(x)logQ(x)=−Ep​(logQ(x))P(x)P(x)P(x)는 실제 값이다.Q(x)Q(x)Q(x)는 추정 값이다.만약 어떤 모델이 다음과 같이 예측했다면y^=[0.70.20.1]&nbsp;y=[100]\\hat y = \\begin{bmatrix} 0.7 \\\\ 0.2 \\\\ 0.1\\end{bmatrix} \\ y = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0\\end{bmatrix}y^​=⎣⎡​0.70.20.1​⎦⎤​&nbsp;y=⎣⎡​100​⎦⎤​CE=−1log⁡0.7−0−0\\text{CE} = -1\\log0.7 - 0 - 0CE=−1log0.7−0−0CE 값은 0으로 만드는 것이 최적의 상태이다." }, { "title": "Logistic Regression", "url": "/posts/logistic/", "categories": "CS, AI", "tags": "cs, AI, ML, summer", "date": "2022-07-08 17:00:00 +0900", "snippet": "Logistic RegressionClassificationLinear regression은 값을 예측하는 모델이다.추정 값이 −∞&lt;y^&lt;∞-\\infin &lt; \\hat y &lt;\\infin−∞&lt;y^​&lt;∞ 의 범위를 가진다.Logistic Regression은 이진 분류 모델이다.추정 값이 0 혹은 1이다.결과 값을 제한하기 위해 시그모이드 함수인 로지스틱 함수가 사용된다.시그모이드 함수는 S자형 곡선을 갖는 수학 함수를 말한다.로지스틱 회귀에서는 로지스틱 함수가 사용된다.S(x)=11+e−xS(x) = {1\\over{1+e^{-x}}} S(x)=1+e−x1​Logistic Regression로지스틱 회귀는 conditional Bernoulli distribution을 가정한다.E[yn∣xn]=P(yn=1∣xn)=σ(W⊤xn)E[y_n|\\bold x_n] = P(y_n = 1 | \\bold x_n) = \\sigma(\\bold W^\\top \\bold x_n) E[yn​∣xn​]=P(yn​=1∣xn​)=σ(W⊤xn​)σ(t)=11+e−t \\sigma(t) = {1\\over{1+e^{-t}}} σ(t)=1+e−t1​Logistic FunctionOdds성공 확률이 실패 확률보다 몇 배 더 높은가승산 비odds&nbsp;ratio=p(y=1∣x)1−p(y=1∣x)\\text{odds ratio} = {p(y=1|x)\\over1-p(y=1|x)}odds&nbsp;ratio=1−p(y=1∣x)p(y=1∣x)​로짓 변환 &amp; 로짓 함수 ( Logit Function )odds에 로그를 취함입력 값의 범위 [0,1][0,1][0,1] -&gt; 출력 값의 범위 [−∞,∞][-\\infin,\\infin][−∞,∞]logit(p)=logp1−p\\text{logit}(p) = log{p\\over1-p}logit(p)=log1−pp​Logistic function로짓 함수의 역함수logitstic(p)=11+e−p\\text{logitstic}(p) = {1\\over{1+e^{-p}}} logitstic(p)=1+e−p1​MLEMaximum Likelihood Estimation로지스틱 회귀의 w\\bold ww값은 최대 우도법으로 구할 수 있다.p(y∣X,w)=∏n=1Np(yn=1∣xn)yn(1−p(yn=1∣xn))1−yn=∏n=1Nσ(w⊤xn)yn(1−σ(w⊤xn))1−ynp(\\bold y|\\bold X,\\bold w) = \\prod_{n=1}^Np(y_n=1|\\bold x_n)^{y_n}(1-p(y_n=1|\\bold x_n))^{1-y_n} \\\\= \\prod_{n=1}^N\\sigma(\\bold w^\\top\\bold x_n)^{y_n}(1-\\sigma(\\bold w^\\top\\bold x_n))^{1-y_n}p(y∣X,w)=n=1∏N​p(yn​=1∣xn​)yn​(1−p(yn​=1∣xn​))1−yn​=n=1∏N​σ(w⊤xn​)yn​(1−σ(w⊤xn​))1−yn​로그를 취해 log-likelihood를 만든다.L=∑n=1Nlog&nbsp;p(yn∣xn)=∑n=1N(ynlog&nbsp;y^+(1−yn)log(1−y^n))y^n=σ(w⊤xn)\\mathcal L = \\sum_{n=1}^Nlog \\ p(y_n|\\bold x_n) \\\\= \\sum_{n=1}^N(y_nlog\\ \\hat y + (1-y_n)log(1-\\hat y _n)) \\\\\\hat y_n = \\sigma(\\bold w^\\top \\bold x_n)L=n=1∑N​log&nbsp;p(yn​∣xn​)=n=1∑N​(yn​log&nbsp;y^​+(1−yn​)log(1−y^​n​))y^​n​=σ(w⊤xn​)위 식은 −cross&nbsp;entropy&nbsp;error-\\text{cross entropy error}−cross&nbsp;entropy&nbsp;error 와 같다.즉 위 식을 최대화하는 것은 크로스 엔트로피 값을 줄이는 것과 같다 .이후 그레디언트 벡터가 0벡터가 되는 값을 찾는다.이때의 값이 log-likelihood 값이 최대화한다.하지만 그레디언트 벡터 수식이 www에 대해 nonlinear function이다.즉 closed form이 아니다.해를 구하는 해석적인 방법이 없다.numerical optimization을 통해 반복적으로 값을 구해야 함OptimizationNewton’s methodNewton’s method는 두 번 미분가능한 함수에 대하여 second-order Taylor expansion으로 함수를 근사한 뒤, 근사 함수의 최솟값을 찾으며 해에 접근하는 방법이다.from 모두를 위한 컨벡스 최적화다음과 같은 식을 통해 www를 업데이트한다.w(new)=w(old)−(∇2L)−1∇Lw^{\\text(new)} = w^{\\text(old)} - (\\nabla^2 \\mathcal L)^{-1}\\nabla \\mathcal Lw(new)=w(old)−(∇2L)−1∇L1차 그레디언트를 구해보자.∂L∂w=∑n=1N[yny^n′y^nxn+(1−yn)−y^n′1−y^n]=∑n=1N[yny^n(1−y^n)y^n−(1−yn)y^n(1−yn)1−y^n]xn=∑n=1N[yn(1−y^n)−(1−yn)y^n]xn=∑n=1N(yn−y^n)xn{\\partial \\mathcal L\\over \\partial \\bold w } = \\sum_{n=1}^N[y_n{\\hat y_n'\\over \\hat y_n}\\bold x_n + (1-y_n){-\\hat y_n'\\over 1- \\hat y_n}]\\\\=\\sum_{n=1}^N[y_n{\\hat y_n(1-\\hat y_n)\\over \\hat y_n} - (1-y_n){\\hat y_n(1-y_n)\\over 1- \\hat y_n}]\\bold x_n \\\\=\\sum_{n=1}^N[y_n{(1-\\hat y_n)} - (1-y_n)\\hat y_n]\\bold x_n \\\\= \\sum_{n=1}^N(y_n-\\hat y_n)\\bold x_n∂w∂L​=n=1∑N​[yn​y^​n​y^​n′​​xn​+(1−yn​)1−y^​n​−y^​n′​​]=n=1∑N​[yn​y^​n​y^​n​(1−y^​n​)​−(1−yn​)1−y^​n​y^​n​(1−yn​)​]xn​=n=1∑N​[yn​(1−y^​n​)−(1−yn​)y^​n​]xn​=n=1∑N​(yn​−y^​n​)xn​로지스틱 함수를 미분하면 σ(1−σ)\\sigma(1-\\sigma)σ(1−σ)∂L∂w=∑n=1N[yn−σ(w⊤xn)]xn{\\partial \\mathcal L\\over \\partial \\bold w } = \\sum_{n=1}^N[y_n-\\sigma(\\bold w^\\top\\bold x_n)]\\bold x_n ∂w∂L​=n=1∑N​[yn​−σ(w⊤xn​)]xn​위와 같이 열벡터를 얻을 수 있다.한번 더 그레디언트를 취하면hessian을 구한다 .∇2L=∂∂w[∇L]⊤\\nabla^2 \\mathcal L ={ \\partial \\over \\partial \\bold w}[\\nabla \\mathcal L] ^\\top∇2L=∂w∂​[∇L]⊤=∂∂w[∑n=1N(yn−y^n)xn⊤]=∑n=1N−y^n(1−y^n)xnxn⊤={ \\partial \\over \\partial \\bold w}[\\sum_{n=1}^N(y_n -\\hat y_n)\\bold x_n^\\top ] \\\\= \\sum_{n=1}^N -\\hat y_n(1-\\hat y_n)\\bold x_n \\bold x_n^\\top=∂w∂​[n=1∑N​(yn​−y^​n​)xn⊤​]=n=1∑N​−y^​n​(1−y^​n​)xn​xn⊤​IRLS위 결과를 통해 newton’s update를 다음과 같이 나타낼 수 있다.Δw=−(∇2L)−1∇L\\Delta\\bold w = -(\\nabla^2 \\mathcal L)^{-1}\\nabla \\mathcal LΔw=−(∇2L)−1∇L=[∑n=1Ny^n(1−y^n)xnxn⊤]−1[∑n=1N[yn−y^n]xn] = \\left [ \\sum_{n=1}^N \\hat y_n(1-\\hat y_n)\\bold x_n \\bold x_n^\\top \\right ]^{-1} \\left [ \\sum_{n=1}^N[y_n-\\hat y_n]\\bold x_n \\right ]=[n=1∑N​y^​n​(1−y^​n​)xn​xn⊤​]−1[n=1∑N​[yn​−y^​n​]xn​]점진적으로 www가 감소하게 된다.위 식은 다음과 같이 나타낼 수 있다.w=w+(XSX⊤)−1XSb\\bold w = \\bold w + (\\bold X \\bold S\\bold X^\\top)^{-1}\\bold X\\bold Sbw=w+(XSX⊤)−1XSbS=[y^1(1−y^n)⋯0⋮⋱00⋯y^n(1−y^n)]\\bold S =\\begin{bmatrix}\\hat y_1(1-\\hat y_n) &amp; \\cdots &amp; 0 \\\\\\vdots &amp; \\ddots &amp; 0 \\\\0 &amp; \\cdots &amp; \\hat y_n(1-\\hat y_n)\\end{bmatrix}S=⎣⎡​y^​1​(1−y^​n​)⋮0​⋯⋱⋯​00y^​n​(1−y^​n​)​⎦⎤​b=[y1−y^1y^1(1−y^1)⋮yN−y^Ny^N(1−y^N)]\\bold b =\\begin{bmatrix}y_1 - \\hat y_1 \\over \\hat y_1(1-\\hat y_1) \\\\\\vdots \\\\ y_N - \\hat y_N \\over \\hat y_N(1-\\hat y_N) \\end{bmatrix}b=⎣⎡​y^​1​(1−y^​1​)y1​−y^​1​​⋮y^​N​(1−y^​N​)yN​−y^​N​​​⎦⎤​Softmax Regression이진 분류가 아닌 다중 분류를 해보자.p(yn=k∣xn)=softmax(θk)p(y_n = k | \\bold x_n) = softmax(\\theta_k) p(yn​=k∣xn​)=softmax(θk​)=ewk⊤xn∑j=1Kewj⊤xn = {e^{\\bold w_k^\\top \\bold x_n} \\over \\sum_{j=1}^K e^{\\bold w_j^\\top \\bold x_n}}=∑j=1K​ewj⊤​xn​ewk⊤​xn​​여러 개의 로지스틱 회귀를 만든 뒤에 softmax를 통해 높은 확률을 취한다.Categorical distribution 관련해 알아보길" }, { "title": "Regularization", "url": "/posts/regular/", "categories": "CS, AI", "tags": "cs, AI, ML", "date": "2022-07-08 17:00:00 +0900", "snippet": "RegularizationOverfitting좋은 모델의 조건학습 데이터를 잘 설명하는 모델미래 데이터 또한 잘 예측하는 모델만약 위 사진처럼 과적합이 된다면학습 데이터를 잘 설명하지만 실제 데이터에서는 오차가 증가하게 된다.고로 generalization이 필요하다.Concept어떻게 규제할 것인가?www 값에 제한을 둔다.일정 크기보다 작게 제한https://www.youtube.com/watch?v=pJCcGK5omhE&amp;t=21s 출처이유차수를 낮추는 방법차수가 높아지면 모델이 오버피팅된다.www값을 0으로 근사시켜 차수를 줄인다.영향력을 줄인다.제한이 없다면 www값이 무한히 커질 수 있다.이는 분산이 커지는 문제가 있다.Ridge RegressionForm릿지는 다음과 같이 www를 제한한다.L2 제약이라 부른다 .min⁡w12∣∣y−ϕ⊤w∣∣22&nbsp;,&nbsp;&nbsp;s.t&nbsp;∣∣w∣∣22&nbsp;≤B\t\\min_w {1\\over 2}|| \\boldsymbol y- \\boldsymbol \\phi^\\top \\boldsymbol w||_2^2 \\ \\text{, \\ s.t} \\ ||\\boldsymbol w||_2^2 \\ \\le B wmin​21​∣∣y−ϕ⊤w∣∣22​&nbsp;,&nbsp;&nbsp;s.t&nbsp;∣∣w∣∣22​&nbsp;≤BSol이를 풀어내려면 Lagrange form으로 나타내야 한다.Lagrange Multiplier Method 는 제약식이 있는 최적화 문제를 푸는 방법이다.Lagrange Multiplier를 식에 더해 제약이 없는 문제로 바꿀 수 있다.Lp=(y−ϕ⊤w)⊤(y−ϕ⊤w)+λ(∣∣w∣∣22−B)L_p = (\\bold y-\\boldsymbol \\phi^\\top \\bold w)^\\top( \\bold y-\\boldsymbol \\phi ^\\top \\bold w ) + \\lambda(||\\bold w||_2^2-B)Lp​=(y−ϕ⊤w)⊤(y−ϕ⊤w)+λ(∣∣w∣∣22​−B)LpL_pLp​ : Lagrange primal functionλ(∣∣w∣∣22−B)\\lambda(||\\bold w||_2^2-B)λ(∣∣w∣∣22​−B) : regularizer이제 미분을 해서 www값을 구한다.최소 값을 가지게 만드는 www를 찾음∂∂w[(y−ϕ⊤w)⊤(y−ϕ⊤w)+λ(∣∣w∣∣22−B)]=0{ \\partial \\over \\partial w } [(\\bold y-\\boldsymbol \\phi^\\top \\bold w)^\\top( \\bold y-\\boldsymbol \\phi ^\\top \\bold w ) + \\lambda(||\\bold w||_2^2-B)] = 0∂w∂​[(y−ϕ⊤w)⊤(y−ϕ⊤w)+λ(∣∣w∣∣22​−B)]=0wLS=(ϕϕ⊤+λIn)−1ϕyw_{LS} = (\\boldsymbol \\phi\\boldsymbol \\phi^\\top + \\lambda I_n ) ^{-1} \\boldsymbol \\phi \\boldsymbol y wLS​=(ϕϕ⊤+λIn​)−1ϕyIII : Identity matrix특징λ\\lambdaλ의 값에 따라 www 값이 변한다.λ\\lambdaλ를 shrinkage parameter라고 부른다.λ\\lambdaλ가 0이면 규제가 없는 상태다.λ\\lambdaλ가 무한에 가까워지면 www값은 0에 근사한다.https://www.youtube.com/watch?v=pJCcGK5omhE&amp;t=21sRasso RegressionForm라쏘는 다음과 같이 www를 제한한다.L1 제약이라 부른다 .min⁡w12∣∣y−ϕ⊤w∣∣22&nbsp;,&nbsp;&nbsp;s.t&nbsp;∣w∣&nbsp;≤B\t\\min_w {1\\over 2}|| \\boldsymbol y- \\boldsymbol \\phi^\\top \\boldsymbol w||_2^2 \\ \\text{, \\ s.t} \\ |\\boldsymbol w| \\ \\le B wmin​21​∣∣y−ϕ⊤w∣∣22​&nbsp;,&nbsp;&nbsp;s.t&nbsp;∣w∣&nbsp;≤BSolLagrange primal function 형태로 나타내자.Lp=(y−ϕ⊤w)⊤(y−ϕ⊤w)+λ(∣w∣−B)L_p = (\\bold y-\\boldsymbol \\phi^\\top \\bold w)^\\top( \\bold y-\\boldsymbol \\phi ^\\top \\bold w ) + \\lambda(|\\bold w|-B)Lp​=(y−ϕ⊤w)⊤(y−ϕ⊤w)+λ(∣w∣−B)arg min⁡w[(y−ϕ⊤w)⊤(y−ϕ⊤w)+λ(∣w∣−B)]{ \\argmin_w} [(\\bold y-\\boldsymbol \\phi^\\top \\bold w)^\\top( \\bold y-\\boldsymbol \\phi ^\\top \\bold w ) + \\lambda(|\\bold w|-B)] wargmin​[(y−ϕ⊤w)⊤(y−ϕ⊤w)+λ(∣w∣−B)]www의 추청 값을 구하는 정규 방정식은 존재하지 않는다.closed form solutionwww 값이 1이상이면 미분 불가능하다.0이면 Subgradient 사용 가능특징어떤 관점에서 라쏘는 변수 선택에 사용된다.선형대수와 ~ 머신러닝 p.184다음 그림에서 보이듯 L1-norm 에서 축이 0이 된다." }, { "title": "linear model", "url": "/posts/linear/", "categories": "CS, AI", "tags": "cs, AI, ML", "date": "2022-07-08 14:20:00 +0900", "snippet": "Linear modelsLinear regressionlinear equationsm = equationsn = unkownsm &gt; nover-determined : 부정식under complete주로 Lidge를 사용한다함거의 대부분의 머신러닝 문제m = n흔히 학교에서 풀었던 방정식uniquem &lt; nover complete해가 무수히 존재함under-determined주로 Lasso를 사용한다함선형회귀의 목적오차를 최소화하는 것오차 ?y1≈W1x1+W0y2≈W2x2+W0y3≈W3x3+W0y_1 \\approx W_1 x_1 + W_0 \\\\y_2 \\approx W_2 x_2 + W_0 \\\\y_3 \\approx W_3 x_3 + W_0y1​≈W1​x1​+W0​y2​≈W2​x2​+W0​y3​≈W3​x3​+W0​Define an errore1=y1−W1x1−W0e2=y2−W2x2−W0e3=y3−W3x3−W0e_1 = y_1 - W_1x_1 - W_0 \\\\e_2 = y_2 - W_2x_2 - W_0 \\\\e_3 = y_3 - W_3x_3 - W_0 \\\\e1​=y1​−W1​x1​−W0​e2​=y2​−W2​x2​−W0​e3​=y3​−W3​x3​−W0​이때 e12+e22+e32{e_1}^2+{e_2}^2+{e_3}^2e1​2+e2​2+e3​2을 최소화하는 www값을 구한다.least squares methodLinear regressionf(x0)=∑j=1Mwjϕj(xn)+w0ϕ0(x)=w⊤ϕ(xn)\tf(x_0) = \\sum_{j=1}^{M}{w_j\\phi_j(x_n)+w_0\\phi_0(x)} = w^{\\top}\\phi(x_n) f(x0​)=j=1∑M​wj​ϕj​(xn​)+w0​ϕ0​(x)=w⊤ϕ(xn​)ϕj(xn)\\phi_j(x_n)ϕj​(xn​)는 basis function 라고 불린다.w,ϕ(xn)∈ℜM+1w, \\phi(x_n) \\in \\real^{M+1}w,ϕ(xn​)∈ℜM+1w=[w0+w1...wM]⊤w = [w_0 + w_1 ... w_M]^\\topw=[w0​+w1​...wM​]⊤ϕ(xn)=[ϕ0(xn),ϕ1(xn)...ϕM(xn)]⊤\\phi(x_n) = [\\phi_0(x_n), \\phi_1(x_n)...\\phi_M(x_n)]^\\topϕ(xn​)=[ϕ0​(xn​),ϕ1​(xn​)...ϕM​(xn​)]⊤nonlinear한 basis function을 이용해 input이 vector xnx_nxn​인 f(x)를 nonlinear하게 할 수 있다. ( 연결 관계를 없앤다. )LSMleast squares method, 최소제곱법, 최소자승법오차의 제곱의 합이 최소가 되는 해를 구하는 방법training data(xn,yn)n=1N{(\\bold x_n, y_n)}_{n=1}^N(xn​,yn​)n=1N​목적식12N∑n=1N(yn−w⊤ϕ(xn))2=12N∣∣y−ϕ⊤w∣∣22\t{1\\over2N}\\sum_{n=1}^N(y_n-w^\\top\\phi(\\bold x_n))^2 = \t{1\\over2N} ||\\bold y-\\boldsymbol{ \\phi^\\top w}||_2^22N1​n=1∑N​(yn​−w⊤ϕ(xn​))2=2N1​∣∣y−ϕ⊤w∣∣22​ϕ⊤w=[ϕ0(x1)ϕ1(x1)⋯ϕM(x1)ϕ0(x2)ϕ1(x2)⋯ϕM(x2)⋮⋮⋱⋮ϕ0(xN)ϕ1(xN)⋯ϕM(xN)][wow1⋮wM]\\boldsymbol{ \\phi^\\top }w = \t \\begin{bmatrix}\t \\phi_0(x_1) &amp; \\phi_1(x_1) &amp; \\cdots &amp; \\phi_M(x_1) \\\\\t\\phi_0(x_2) &amp; \\phi_1(x_2) &amp; \\cdots &amp; \\phi_M(x_2) \\\\\t\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\\t\\phi_0(x_N) &amp; \\phi_1(x_N) &amp; \\cdots &amp; \\phi_M(x_N) \\end{bmatrix} \\begin{bmatrix}w_o \\\\ w_1 \\\\ \\vdots \\\\ w_M\\end{bmatrix}ϕ⊤w=⎣⎡​ϕ0​(x1​)ϕ0​(x2​)⋮ϕ0​(xN​)​ϕ1​(x1​)ϕ1​(x2​)⋮ϕ1​(xN​)​⋯⋯⋱⋯​ϕM​(x1​)ϕM​(x2​)⋮ϕM​(xN​)​⎦⎤​⎣⎡​wo​w1​⋮wM​​⎦⎤​변환∣∣y−ϕ⊤w∣∣22=(y−ϕ⊤w)⊤(y−ϕ⊤w)||\\bold y-\\boldsymbol{ \\phi^\\top w}||_2^2 = (y-\\phi^\\top w)^\\top(y-\\phi ^\\top w ) ∣∣y−ϕ⊤w∣∣22​=(y−ϕ⊤w)⊤(y−ϕ⊤w)y, ϕ\\phiϕ 는 주어진 값이다. 식을 최소화하는 www ?wLS=arg min⁡w12N∣∣y−ϕ⊤w∣∣22 w_{LS} = \\argmin_w{1\\over2N} ||\\bold y-\\boldsymbol{ \\phi^\\top w}||_2^2wLS​=wargmin​2N1​∣∣y−ϕ⊤w∣∣22​정규 방정식을 구한다. ( 해석적인 방법 )∂∂w(12N∣∣y−ϕ⊤w∣∣22)=0&nbsp;&nbsp;for&nbsp;w {\\partial \\over \\partial w } ({1\\over 2N}||\\bold y-\\boldsymbol{ \\phi^\\top w}||_2^2 ) = 0 \\ \\ \\text{for} \\ w∂w∂​(2N1​∣∣y−ϕ⊤w∣∣22​)=0&nbsp;&nbsp;for&nbsp;w12N(y−ϕ⊤w)⊤(y−ϕ⊤w)=12N(y⊤y−w⊤ϕy−y⊤ϕ⊤w+w⊤ϕϕ⊤w){1\\over 2N} (\\bold y-\\boldsymbol \\phi^\\top \\bold w)^\\top( \\bold y-\\boldsymbol \\phi ^\\top \\bold w ) \\\\ = {1\\over 2N}(\\bold y^\\top\\bold y - \\bold w^\\top \\boldsymbol \\phi \\bold y - \\bold y^\\top \\boldsymbol \\phi ^ \\top \\bold w + \\bold w ^\\top \\boldsymbol \\phi\\boldsymbol \\phi ^ \\top \\bold w )2N1​(y−ϕ⊤w)⊤(y−ϕ⊤w)=2N1​(y⊤y−w⊤ϕy−y⊤ϕ⊤w+w⊤ϕϕ⊤w)(&nbsp;)⊤( ~ )^\\top(&nbsp;)⊤에서 T를 분배하고 곱미분한다.∂∂w(y⊤y−w⊤ϕy−y⊤ϕ⊤w+w⊤ϕϕ⊤w)=2ϕϕ⊤w−ϕy{ \\partial \\over \\partial w }(\\bold y^\\top\\bold y - \\bold w^\\top \\boldsymbol \\phi \\bold y - \\bold y^\\top \\boldsymbol \\phi ^ \\top \\bold w + \\bold w ^\\top \\boldsymbol \\phi\\boldsymbol \\phi ^ \\top \\bold w ) = 2\\boldsymbol \\phi\\boldsymbol \\phi^\\top w - \\boldsymbol \\phi \\boldsymbol y ∂w∂​(y⊤y−w⊤ϕy−y⊤ϕ⊤w+w⊤ϕϕ⊤w)=2ϕϕ⊤w−ϕy해를 구한다.wLS=(ϕϕ⊤)−1ϕy=ϕ†yw_{LS} = (\\boldsymbol \\phi\\boldsymbol \\phi^\\top ) ^{-1} \\boldsymbol \\phi \\boldsymbol y = \\boldsymbol \\phi ^\\dagger \\boldsymbol y wLS​=(ϕϕ⊤)−1ϕy=ϕ†yϕ†\\boldsymbol \\phi ^\\daggerϕ† : moore penrose pseudo inversePolynomial Regression다항회귀 multiple regression다중의 독립변수가 있는 것다중회귀독립변수의 차수를 높인 것f(xn)=∑j=0Mwjxnjf(x_n) = \\sum_{j=0}^M w_j{x_n}^jf(xn​)=∑j=0M​wj​xn​j" }, { "title": "intro of AI", "url": "/posts/introai/", "categories": "CS, AI", "tags": "cs, AI, ML", "date": "2022-07-08 10:00:00 +0900", "snippet": "Deep learning공부 계획7월 이론8월 실습참고 자료Baro ai deep learning advanced핸즈온 머신러닝선형대수와 통계학으로 배우는 머신러닝밑바닥부터 시작하는 딥러닝" }, { "title": "Process & Switch", "url": "/posts/process/", "categories": "CS, OS", "tags": "os, cs, summer", "date": "2022-07-05 22:25:00 +0900", "snippet": "ProcessProcess하나의 작업 단위program과 processprogram은 저장장치에 저장된 정적인 상태process는 실행을 위해 메모리에 올라온 동적 상태Program 실행과 Process 관리program을 실행하면 process가 메모리에 올라온다.이때 PCB ( 프로세스 제어 블록 ) 이 커널 영역에 올라온다.커널은 PCB Data Structure 을 이용해 process를 관리한다.커널은 하드웨어 정보 또한 Data Structure 로 관리한다.PCB나 하드웨어 자료구조를 메타데이터라 부른다.PCBPCB에는 무슨 정보가 있을까?중요한 것들을 보자.프로세스 구분자 : PID메모리 정보 : 프로세스의 위치 정보state vector save area : 각종 레지스터 정보context change가 발생하면 자신의 상태를 저장해야 한다.PCB는 위와 같이 사용된다.Forkprocess를 복사하는 시스템 콜이다.복제가 아닌 process를 만드는 것은 많은 자원이 소모된다.https://kldp.org/node/57233https://www.bell-labs.com/usr/dmr/www/hist.html장점프로세스 생성 속도가 빠르다.하드디스크에서 프로그램을 새로 가져오지 않고, 기존 메모리에서 복사하기 때문에 생성 속도가 빠르다.추가 작업 없이 자원을 상속할 수 있다.부모가 사용하던 모든 자원을 추가 작업 없이 자식에게 상속 가능하다.시스템 관리를 효율적으로 할 수 있다.부모와 자식 관계를 가지기 때문에 자식이 죽으면, 자식이 사용한 자원을 부모가 정리하게 된다.단점복사에 많은 비용이 든다.child process를 만들자부모의 PCB 복사한다.부모의 리소스를 자식과 공유한다.PID는 바뀐다.PPID, CPID가 바뀐다.자식은 CPID = -1child process의 메모리 공간을 확보한다.메모리 관련 정보가 변한다.디스크에서 이미지를 긁어온다.기존 부모의 이미지에 overlay한 뒤, 시작 지점부터 실행된다.fork 코드의 이해fork( )는 두 번 반환된다. ( ? )한번은 부모로, 한번은 자식으로fork를 하면 프로세스가 복사되고, state vector가 복사되므로 자식 프로세스 또한 fork ( ) 반환부터 진행된다.즉 자식 프로세스는 fork( ) 위의 코드를 진행하지 않는다.두 번째 코드는 wait( ) 시스템 콜로 인해 자식이 먼저 실행된다.cpu를 뺏기고 큐에 다시 들어간다.Execfork는 부모 프로세스를 복사하는 과정이다.복사한 뒤 새로운 프로세스를 overlay 할 때 사용되는 시스템 콜이다.즉 내용을 바꿔버리는 것이다.이유 ?프로세스의 구조체를 재활용하기 위함이다.만약 새로운 프로세스를 만들려면 제어 블록을 만들고 메모리 확보 과정이 필요하다. 게다가 메모리 청소를 위해 부모, 자식 관계를 만들어야 한다.exec ( )은 복사한 뒤 코드 영역만 바꾼다.동작 과정기존 코드 영역을 지우고 새로운 코드로 바꾼다.데이터 영역이 새로운 변수로 채워지고 스택 영역이 리셋된다.각종 레지스터 값과 사용한 파일 정보가 리셋된다.부모 프로세스 구분자, 자식 프로세스 구분자, 메모리 관련 사항은 변하지 않는다.Wait 과 Exitwaitwait는 자식 프로세스가 종료될 때까지 대기 상태에 빠진다 .커널 모드로 갔다가 돌아오지 않고 cpu를 넘긴다.exit프로세스가 종료된다.이후 좀비 상태가 되고 부모에게 signal을 보내 회수되길 기다린다.system call summaryforkcreate a child(copy)execoverlay new image, analogous to gotowaitsleep until child is doneexitfrees all the resources, notify parentContext Switch프로세스마다 할당된 cpu 사용 시간이 있고, 만약 시간을 다 쓴다면 cpu를 넘겨야 한다. 이때 Context Switch가 발생한다.이때 PCB가 사용된다. PCB는 다음에 정리하도록 하자.우선 사용자가 터미널을 킨다.shell이 만들어진다.“ls” 명령어 입력하면 fork가 발생한다.복사된 child가 ready queue에 담긴다.wait으로 인해 부모는 cpu를 뺏긴다 .자식은 exec을 실행하고 디스크에서 코드를 불러와 오버레이한다.ls 실행 후 exit 실행된다.커널이 부모를 dispatches 하고, 실행된다.커널 모드와 유저 모드의 흐름이다.조금 더…커널에서 프로세스를 관리할 때 pcb를 이용한다.wait 시스템 콜이 발생하면 context switch가 시작된다.커널모드로 전환되고, 현재의 cpu state vector를 진행 중이었던 pcd에 저장을 한다. 이후 현 프로세스는 ready 상태로 바뀌고 cpu를 뺏긴다.ready queue에서 우선순위가 높은 프로세스를 찾아 실행한다.이때 해당 프로세스의 pcb를 cpu에 로딩한다.해당 프로세스의 주소로 PC가 이동한다.wait( ) 콜이 아닌 때에도 시스템 콜은 발생한다.즉 내부적으로 context switch를 해주는 시스템 콜이 존재한다.schedule ( )이 그 역할을 한다.wait -&gt; schedule -&gt; context switch정리Context switchProcessContextDemon데몬은 백그라운드 프로세스이다.메모리에 상주하며 대기타는 프로세스이다.즉 루프를 돈다.init 프로세스가 실행하며 데몬 관련 프로그램 명령어는 d로 끝난다.서비스라 부르기도 한다.일부 리눅스 배포판에서는 init이 systemd로 대체된다.이때 -d 는 데몬을 나타낸다.pstree 명령어를 치면 트리를 볼 수 있다.모든 프로세스는 systemd에서 fork된다.밑 사진은 우분투 20.04 기준이다.쉘을 찾아보자.ssh를 이용해 원격 접속을 하고있다.이때는 SSHD(Secure Shell Daemon)를 이용한다.ssh 연결을 받기 위해 대기 타는 것이다.pstree 실행 중임을 알 수 있다.열심히 돌고 있는 mysql 데몬도 볼 수 있다." }, { "title": "System Call with linux", "url": "/posts/systemcall2/", "categories": "CS, OS", "tags": "os, cs, summer, 실습과 그림으로 배우는 리눅스 구조", "date": "2022-07-05 16:19:00 +0900", "snippet": "System Call with Linuxsystem call 확인하기간단한 hello world 예제이다.strace를 이용해 요청한 시스템 콜을 알아보자.strace 각각의 줄은 1개의 시스템 콜이다.write( ) 시스템 콜을 확인할 수 있다.이외에도 많은 시스템 콜이 호출되었다.대부분 main( ) 함수 앞뒤로 실행된 것들이며 프로그램의 시작과 종료 처리 중 호출된 것이다.system call의 소요 시간 확인하기strace -T 옵션을 이용시스템 콜 처리에 걸린 시간을 측정 가능하다.system 점유율이 높을 때 이 기능을 통해 부하를 찾아낸다.실험CPU 정보 확인하는 법sar -P ALL 1명령어를 통해 cpu 의 모드를 확인할 수 있다.idlekernel, user mode가 아닌 상태user, niceuser mode인 상태systemkernel mode인 상태실험 1loop를 걸어서 확인해보자.#include &lt;stdio.h&gt;int main(){\tfor(;;);}user mode에서 계속 돌아가는 것을 볼 수 있다.cpu 3번실험 2이번에는 getppid( ) 시스템 콜을 이용해보자.#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;int main(){\tfor(;;)\t\tgetppid();}일정 비율로 kernel과 user mode가 실행되었음을 알 수 있다.즉 사용자 모드 -&gt; 커널 모드 -&gt; 사용자 모드 …system call의 wrapper 함수system call은 보통 C언어 같은 고급 언어에서 직접 호출이 불가능하다.아키텍처에 의존하는 어셈블리 코드를 사용해 호출된다.getppid( ) 시스템 콜은 x86_64 아키텍처에서 다음과 같이 호출된다.mov $0x6e, %eax // 시스템 콜 번호를 eax 레지스터에 대입syscall만약 wrapper 함수가 없었다면 어셈블리 언어를 사용해서 system call을 호출했을 것이다.이는 이식성이 매우 낮으며 프로그램 작성 시 오래 걸린다.고급언어로 작성된 사용자 프로그램은 단순히 시스템 콜의 wrapper 함수를 호출하면 된다.wrapper 함수는 단순하게 시스템 콜을 요청하는 함수이다.trap이 걸리면 eax레지스터를 참조해 커널 모드로 함수가 실행됨.표준 C 라이브러리c 언어에는 표준 라이브러리가 있다.glibc 를 사용한다.glibc는 system call의 wrapper 함수를 포함한다.posix 규격에 정의된 함수도 제공ldd 명령을 통해 링크하는 라이브러리를 볼 수 있다.libc / 표준 C 라이브러리를 링크하고 있다.참고로 파이썬도 내부적으로는 C 라이브러리를 사용한다.이해가 안 간다면 다음 글을 참고해보자." }, { "title": "System Call", "url": "/posts/systemcall/", "categories": "CS, OS", "tags": "os, cs, summer", "date": "2022-07-05 14:30:00 +0900", "snippet": "SystemCallsystem call은 커널에게 I/O 작업을 요청하는 것이다.하드웨어의 mode bit 를 사용하여 커널모드와 유저모드로 나눈다.cpu의 mode bit 가 0이면 kernel mode 이며, cpu는 어떤 메모리의 영역이든 접근할 수 있다.mode bit이 1이면 user mode로 cpu는 파일에 영향을 주는 명령은 사용이 불가능하다.특권 명령과 일반 명령이라도 부른다.mode bit을 검사하는 과정을 알아보자.우선 PC레지스터로 명령어의 주소를 보낸다.이때 MMU를 통과한다.요청된 명령어의 주소가 로컬 범위 밖이라면 cpu를 빼앗긴다.Decode 단계에서 명령어를 파악 및 검사한다.만약 권한을 넘어서면 빼앗긴다.사용자 입장 / Source code컴파일우리가 코드를 짤 때는 I/O 코드를 짠다.사실 컴파일 과정에서 컴파일러가 chmodk 명령을 집어 넣는다.그리고 I/O statements는 바이너리( a.out )에서 보이지 않고 커널에서 존재하게 된다.change mode (protection) kernel실행chmodk는 privilieged 명령이다.즉 user_mode에서 실행이 불가능하다.이때 cpu 뺏기며 HW trap이 걸리게 된다.Cpu state vector를 저장해둔다.trap handler가 작동하며 kernel mode로 바뀐다.trap handler는 trap을 일으킨 정보를 통해 kernel 함수를 실행한다.이후 cpu 모드를 user_mode로 돌리고, 저장된 state vector 복구한다.interrupted 된 address로 복귀한다,모든 프로그램은 두 개의 스택이 필요하다.커널용, 유저용함수 호출 시 사용된다.System call 흐름 정리System call 자세히…system call 흐름printf를 하면 라이브러리로 달려간다.라이브러리에서 system call wrapper 함수를 부름 ( write(2) )write( ) 에서 system call number를 넘김, 그리고 trap을 발생시킴system call number는 정해져 있다. 컴파일러마다 다르다.여기까지 컴파일러 / 이후 OSsys_call()에서 number를 이용해 system call table에서 sys_write( )를 찾아 실행함정보는 어떻게 교환하는가kernel 모드로 변경되면 이때 발생하는 I/O 정보는 어떻게 user 에게 전달 될까?kernel 은 user와 달리 모든 메모리에 접근 할 수 있다.즉 kernel은 user의 정보를 얻거나 전달할 수 있다.다음과 같은 함수들을 통해 구현된다." }, { "title": "intro of OS", "url": "/posts/intro/", "categories": "CS, OS", "tags": "os, cs, summer", "date": "2022-07-05 11:39:00 +0900", "snippet": "OS운영체제는 사용자와 컴퓨터 사이에서 하드웨어 사이에서 작동하는 시스템이다. 운영체제의 목표는 다음과 같다.OS자원관리자원 보호하드웨어 인터페이스사용자 인터페이스효휼성안정성확장성편리성PerformanceThroughput — jobs/secUtilization — % of time busyResponse time — sec / jobos는 크게 3개로 나누어진다.OSkernelshellutilitykernelmemory resident part of OS, just plain C programutilitycommand, disk resident part of OS (loaded on demand )job유저가 요청하면 메모리에 올라감shell (CLI / GUI)A special utility. It’s mission is Job Controlread keyboard input &amp; excute command (interpreter)UNIX interface to user. Shell prompt &amp; commandFileSequence of bytes, no other restrictionsI/O devices are treated as files in Unix, Linux ( /dev )Kernel - Shell - Utilities처음 컴퓨터가 부팅되면 kernel이 메모리에 올라온다.유저가 터미널을 켜면 shell 이 메모리에 올라온다.커맨드가 입력되면 utility가 메모리에 올라와 실행된다.Multi-user리눅스는 윈도우와 달리 multi-user 시스템이다.이로 인해 리눅스는 자원을 최소화하는 형태를 보인다. 예로 CUI를 들 수 있다. 또한 유저 간 간섭이 되지 않도록 protection 이 중요해진다.Protection &amp; SystemCall사용자 A의 프로그램이 B의 허용되지 않은 메모리에 접근하여 read, write를 못하게 막아야한다.이를 해결하는 방법으로 응용프로그램 / utility 가 직접 I/O 를 못하게 만들었다.즉 I/O instruction은 커널이 담당하며, systemcall이라는 요청을 통해 수행된다.이때 kernel은 I/O 명령을 검사한 뒤에 실행한다.응용프로그램과 커널 사이 인터페이스를 systemcall ,커널과 하드웨어 사이 인터페이스는 driver가 담당한다." }, { "title": "운영체제 공부 정리", "url": "/posts/start/", "categories": "CS, OS", "tags": "os, cs, summer", "date": "2022-07-05 10:00:00 +0900", "snippet": "운영체제 공부 정리2학년 여름 방학 운영체제에 대해 공부하려 한다. 7월 20일까지 공부 계획 중…공부 자료 / 출처OS쉽게 배우는 운영체제 조성호널널한 개발자 - 운영체제 강의Kernel of linux 고건 교수님실습과 그림으로 배우는 리눅스 구조" }, { "title": "open", "url": "/posts/open/", "categories": "Blogging, life", "tags": "writing", "date": "2022-07-04 12:00:00 +0900", "snippet": "start blog…summer studyOS / KERNELDeep LearningLinear Algebra" } ]
